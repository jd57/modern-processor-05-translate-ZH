# The PowerPC 620



## 6.1 Introduction



## 6.2 Experimental Framework



## 6.3 Instruction Fetching



## 6.4 Instruction Dispatching



## 6.5 Instruction Execution



## 6.6 Instruction Completion



## 6.7 Conclusions and Observations



## 6.8 Bridging to the IBM POWER3 and POWER4



## 6.9 Summary
References
Homework Problems

The PowerPC family of microprocessors includes the 64-bit PowerPC 620 microprocessor. The 620 was the first 64-bit superscalar processor to employ true out-oforder execution, aggressive branch prediction, distributed multientry reservation stations, dynamic renaming for all register files, six pipelined execution units, and a completion buffer to ensure precise exceptions. Most of these features had not been previously implemented in a single-chip microprocessor. Their actual effectiveness is of great interest to both academic researchers as well as industry designers. This chapter presents an instruction-level, or machine-cycle level, performance evaluation of the 620 microarchitecture using a VMW -generated performance simulator of the 620 (VMW is the Visualization-based Microarchitecture Workbench from Carnegie Mellon University) [Levitan et aI., 1995; Diep et aI., 1995].

We also describe the IBM POWER3 and POWER4 designs, and we highlight how they differ from the predecessor PowerPC 620. While they are fundamentally similar in that they aggressively extract instruction-level parallelism from sequential code, the differences between the 620, the POWER3, and the POWER4 designs help to highlight recent trends in processor implementation: increased memory bandwidth through aggressive cache hierarchies, better branch prediction, more execution resources, and deeper pipelining.




## 6.1 Introduction

The PowerPC Architecture is the result of the PowerPC alliance among IBM, Motorola, and Apple [May et aI., 1994]. It is based on the Performance Optimized with Enhanced RISC (POWER) Architecture, designed to facilitate parallel instruction execution and to scale well with advancing technology. The PowerPC alliance has released and announced a number of chips . The first, which provided a transition from the POWER Architecture to the PowerPC Architecture, was the PowerPC 601 microprocessor [IBM Corp., 1993]. The second, a low-power chip, was the PowerPC 603 microprocessor [Motorola, Inc., 2002]. Subsequently, a more advanced chip for desktop systems, the PowerPC 604 microprocessor, has been shipped [IBM Corp., 1994]. The fourth chip was the 64-bit 620 [Levitan et aI., 1995; Diep et aI., 1995].

More recently, Motorola and IBM have pursued independent development of general-purpose PowerPC-compatible parts. Motorola has focused on 32-bit desktop chips for Apple, while IBM has concentrated on server parts for its Unix (AIX) and business (OS/400) systems. Recent 32-bit Motorola designs, not detailed here, are the PowerPC 03 and 04 designs [Motorola, Inc., 2001; 2003]. These are 32-bit parts derived from the PowerPC 603, with short pipelines, limited execution resources, but very low cost. IBM's server parts have included the in-order multithreaded Star series (Northstar, Pulsar, S-Star [Storino et aI. , 1998]), as well as the out-of-order POWER3 [O' Connell and White,2000] and POWER4 [Tendler et aI., 2001]. In addition, both Motorola and IBM have developed various PowerPC cores for the embedded marketplace. Our focus in this chapter is on the PowerPC 620 and its heirs at the high-performance end of the marketplace, the POWER3 and the POWER4.

The PowerPC Architecture has 32 general-purpose registers (GPRs) and 32 floating-point registers (FPRs). It also has a condition register which can be addressed as one 32-bit register (CR), as a register file of 8 four-bit fields (CRFs), or as 32 single-bit fields. The architecture has a count register (CTR) and a link register (LR), both primarily used for branch instructions, and an integer exception register (XER) and a floating-point status and control register (FPSCR), which are used to record the exception status of the appropriate instruction types. The PowerPC instructions are typical RISC instructions, with the addition of floating-point fused multiply-add (FMA) instructions, load/store instructions with addressing modes that update the effective address, and instructions to set, manipulate, and branch off of the condition register bits.

The 620 is a four-wide superscalar machine. It uses aggressive branch prediction to fetch instructions as early as possible and a dispatch policy to distribute thoseCompletion buffer instructions to the execution units. The 620 uses six parallel execution units: two simple (single-cycle) integer units, one complex (muIticycle) integer unit, one floating-point unit (three stages), one load/store unit (two stages), and a branch unit. The 620 uses distributed reservation stations and register renaming to implement out-of-order execution. The block diagram of the 620 is shown in Figure 6.1.

The 620 processes instructions in five major stages, namely the fetch, dispatch, execute, complete, and writeback stages. Some of these stages are separated by buffers to take up slack in the dynamic variation of available paraIIelism. These buffers are the instruction buffer, the reservation stations, and the completion buffer. The pipeline stages and their buffers are shown in Figure 6.2. Some of the units in the execute stage are actually multistage pipelines.


Fetch Stage. The fetch unit accesses the instruction cache to fetch up to four instructions per cycle into the instruction buffer. The end of a cache line or a taken branch can prevent the fetch unit from fetching four useful instructions in a cycle.
A mispredicted branch can waste cycles while fetching from the wrong path. During the fetch stage, a preliminary branch prediction is made using the branch target address cache (BT AC) to obtain the target address for fetching in the next cycle.
Instruction Buffer. The instruction buffer holds instructions between the fetch and dispatch stages. If the dispatch unit cannot keep up with the fetch unit, instructions are buffered until the dispatch unit can process them. A maximum of eightInstruction buffer instructions can be buffered at a time. Instructions are buffered and shifted in groups of two to simplify the logic.
Dispatch Stage. The dispatch unit decodes instructions in the instruction buffer and checks whether they can be dispatched to the reservation stations. If all dispatch conditions are fulfilled for an instruction, the dispatch stage will allocate a reservation station entry, a completion buffer entry, and an entry in the rename buffer for the destination, if needed. Each of the six execution units can accept at most one instruction per cycle. Certain infrequent serialization constraints can also stall instruction dispatch. Up to four instructions can be dispatched in program order per cycle.

There are eight integer register rename buffers, eight floating-point register rename buffers, and 16 condition regi ster field rename buffers. The count register and the link register have one shadow register each, which is used for renaming.
During dispatch, the appropriate buffers are allocated. Any source operands which have been renamed by previous instructions are marked with the tags of the associated rename buffers. If the source operand is not available when the instruction is dispatched, the appropriate result busses for forwarding results are watched to obtain the operand data. Source operands which have not been renamed by previous instructions are read from the architected register files.

If a branch is being dispatched, resolution of the branch is attempted immediately. If resolution is still pending, that is, the branch depends on an operand that is not yet available, it is predicted using the branch history table (BHT). If the prediction made by the BHT disagrees with the prediction made earlier by the BTAC in the fetch stage, the BT AC-based prediction is discarded and fetching proceeds along the direction predicted by the BHT.

Reservation Stations. Each execution unit in the execute stage has an associated reservation station. Each execution unit's reservation station holds those instructions waiting to execute there. A reservation station can hold two to four instruction entries, depending on the execution unit. Each dispatched instruction waits in a reservation station until all its source operands have been read or forwarded and the execution unit is available. Instructions can leave reservation stations and be issued into the execution units out of order [except for FPU and branch unit (BRU)].

Execute Stage. This major stage can require multiple cycles to produce its results, depending on the type of instruction being executed. The load/store unit is a two-stage pipeline, and the floating-point unit is a three-stage pipeline. At the end of execution, the instruction results are sent to the destination rename buffers and forwarded to any waiting instructions.

Completion Buffer. The 16-entry completion buffer records the state of the inflight instructions until they are architecturally complete. An entry is allocated for each instruction during the dispatch stage. The execute stage then marks an instruction as finished when the unit is done executing the instruction. Once an instruction is finished, it is eligible for completion.

Complete Stage. During the completion stage, finished instructions are removed from the completion buffer in order, up to four at a time, and passed to the writeback stage. Fewer instructions will complete in a cycle if there are an insufficient number of write ports to the architected register files. By holding instructions in the completion buffer until writeback, the 620 guarantees that the architected registers hold the correct state up to the most recently completed instruction. Hence, precise exception is maintained even with aggressive out-of-order execution.

Writeback Stage. During this stage, the writeback logic retires those instructions completed in the previous cycle by committing their results from the rename buffers to the architected register files.



## 6.2 Experimental Framework

The performance simulator for the 620 was implemented using the VMW framework developed at Carnegie Mellon University. The five machine specification files for the 620 were generated based on design documents provided and periodically updated by the 620 design team. Correct interpretation of the design documents was checked by a member of the design team through a series of refinement cycles as the 620 design was finalized.

Instruction and data traces are generated on an existing PowerPC 601 microprocessor via software instrumentation. Traces for several SPEC 92 benchmarks, four integer and three floating-point, are generated. The benchmarks and their dynamic instruction mixes are shown in Table 6.1. Most integer benchmarks have similar instruction mixes; li contains more multicycle instructions than the rest.

Most of these instructions move values to and from special-purpose registers.
There is greater diversity among the floating-point benchmarks. Hydro2d uses more nonpipelined floating-point instructions. These instructions are all floatingpoint divides, which require 18 cycles on the 620.


## 3.2 'Values given are percentages.

Trace-driven performance simulation is used. With trace-driven simulation, instructions with variable latency such as integer multiply/divide and floatingpoint divide cannot be simulated accurately. For these instructions, we assume the minimum latency. The frequency of these operations and the amount of variance in the latencies are both quite low. Furthermore, the traces only contain those instructions that are actually executed. No speculative instructions that are later discarded due to misprediction are included in the simulation runs. Both I-cache and D-cache activities are included in the simulation. The caches are 32K bytes and 8-way set-associative. The D-cache is two-way interleaved. Cache miss latency of eight cycles and a perfect unified L2 cache are also assumed.

Table 6.2 presents the total number of instructions simulated for each benchmark and the total number of 620 machine cycles required. The sustained average number of instructions per cycle (IPC) achieved by the 620 for each benchmark is also shown. The IPC rating reflects the overall degree of instruction-level parallelism achieved by the 620 microarchitecture, the detailed analysis of which is presented in Sections 6.3 to 6.6.




## 6.3 Instruction Fetching

Provided that the instruction buffer is not saturated, the 620's fetch unit is capable of fetching four instructions in every cycle. If the fetch unit were to wait for branch resolution before continuing to fetch nonspeculatively, or if it were to bias naively for branch-not-taken, machine execution would be drastically slowed by the bottleneck in fetching down taken branches. Hence, accurate branch prediction is crucial in keeping a wide superscalar processor busy.



### 6.3.1  Branch Prediction
Branch prediction in the 620 takes place in two phases. The first prediction, done in the fetch stage, uses the BTAC to provide a preliminary guess of the target address when a branch is encountered during instruction fetch. The second, and more accurate, prediction is done in the dispatch stage using the BHT, which contains branch history and makes predictions based on the two history bits.

During the dispatch stage, the 620 attempts to resolve immediately a branch based on available information. If the branch is unconditional, or if the condition register has the appropriate bits ready, then no branch prediction is necessary. The branch is executed immediately. On the other hand, if the source condition register bits are unavailable because the instruction generating them is not finished, then branch prediction is made using the BHT. The BHT contains two history bits per entry that are accessed during the dispatch stage to predict whether the branch will be taken or not taken. Upon resolution of the predicted branch, the actual direction of the branch is updated to the BHT. The 2048-entry BHT is a direct-mapped table, unlike the BT AC, which is an associative cache. There is no concept of a2048 instructions apart, i.e., aliased, they will affect each other's predictions.

The 620 can resolve or predict a branch at the dispatch stage, but even that can incur one cycle delay until the new target of the branch can be fetched. For this reason, the 620 makes a preliminary prediction during the fetch stage, based solely on the address of the instruction that it is currently fetching. If one of these addresses hits in the BTAC, the target address stored in the BT AC is used as the fetch address in the next cycle. The BT AC, which is smaller than the BHT, has 256 entries and is two-way set-associative. It holds only the targets of those branches that are predicted taken. Branches that are predicted not taken (fall through) are not stored in the BTAC. Only unconditional and PC-relative conditional branches use the BT AC. Branches to the count register or the link register have unpredictable target addresses and are never stored in the BTAC. Effectively, these branches are always predicted not taken by the BTAC in the fetch stage. A link register stack, which stores the addresses of subroutine returns, is used for predicting conditional return instructions. The link register stack is not modeled in the simulator.

There are four possible cases in the BT AC prediction: a BT AC miss for which the branch is not taken (correct prediction), a BTAC miss for which the branch is taken (incorrect prediction), a BTAC hit for a taken branch (correct prediction), and a BT AC hit for a not-taken branch (incorrect prediction). The BTAC can never hit on a taken branch and get the wrong target address; only PC-relative branches can hit in the BT AC and therefore must always use the same target address. Two predictions are made for each branch, once by the BTAC in the fetch stage, and another by the BHT in the dispatch stage. If the BHT prediction disagrees with the BTAC prediction, the BHT prediction is used, while the BTAC prediction is discarded. If the predictions agree and are correct, all instructions that are speculatively fetched are used and no penalty is incurred.

In combining the possible predictions and resolutions of the BHT and BT AC, there are six possible outcomes. In general, the predictions made by the BTAC and BHT are strongly correlated. There is a small fraction of the time that the wrong prediction made by the BTAC is corrected by the right prediction of the BHT.

There is the unusual possibility of the correct prediction made by the BTAC being undone by the incorrect prediction of the BHT. However, such cases are quite rare; see Table 6.3. The BTAC makes an early prediction without using branch history.
A hit in the BTAC effectively implies that the branch is predicted taken. A miss in the BTAC implicitly means a not-taken prediction. The BHT prediction is based on branch history and is more accurate but can potentially incur a one-cycle penalty if its prediction differs from that made by the BTAC. The BHT tracks the branch history and updates the entries in the BTAC. This is the reason for the strong correlation between the two predictions.

Table 6.3 summarizes the branch prediction statistics for the benchmarks. The BTAC prediction accuracy for the integer benchmarks ranges from 75% to 84%.
For the floating-point benchmarks it ranges from 88% to 94%. For these correct predictions by the BTAC, no branch penalty is incurred if they are likewise predicted Table 6.3

## 6.6 BHT prediction
Resolved Overall branch prediction accuracy correctly by the BHT. The overall branch prediction accuracy is determined by the BHT. For the integer benchmarks, about 17% to 29% of the branches are resolved by the time they reach the dispatch stage. For the floating-point benchmarks, this range is 17% to 45%. The overall misprediction rate for the integer benchmarks ranges from 8.7% to 11.4%; whereas for the floating-point benchmarks it ranges from 0.9% to 5.8%. The existing branch prediction mechanisms work quite well for the floating-point benchmarks. There is still room for improvement in the integer benchmarks.




### 6.3.2  Fetching and Speculation
The main purpose for branch prediction is to sustain a high instruction fetch bandwidth, which in turn keeps the rest of the superscalar machine busy. Misprediction translates into wasted fetch cycles and reduces the effective instruction fetch bandwidth. Another source of fetch bandwidth loss is due to I-cache misses. The effects of these two impediments on fetch bandwidth for the benchmarks are shown in Table 6.4. Again, for the integer benchmarks, significant percentages (6.7% to 11.8%) of the fetch cycles are lost due to misprediction. For all the benchmarks, the I-cache misses resulted in the loss of less than 1% of the fetch cycles.

Branch prediction is a form of speculation. When speculation is done effectively, it can increase the performance of the machine by alleviating the constraints imposed by control dependences. The 620 can speculate past up to four predicted branches before stalling the fifth branch at the dispatch stage. Speculative instructions are allowed to move down the pipeline stages until the branches are resolved, at which time if the speculation proves to be incorrect, the speculated instructions are canceled. Speculative instructions can potentially finish execution and reach the completion stage prior to branch resolution. However, they are not allowed to complete until the resolution of the branch.

Table 6.S displays the frequency of bypassing specific numbers of branches, which reflects the degree of speculation sustained. The average number of branches bypassed is determined by obtaining the number of correctly predicted branches that are bypassed in each cycle. Once a branch is determined to be mispredicted, speculation of instructions beyond that branch is not simulated. For the integer benchmarks, in 34% to 51 % of the cycles, the 620 is speculatively executing beyond one or more branches. For floating-point benchmarks, the degree of speculation is lower. The frequency of misprediction, shown in Table 6.4, is related to the combination of the average number of branches bypassed, provided in Table 6.5, and the prediction accuracy, provided in Table 6.3.




## 6.4  Instruction Dispatching
The primary objective of the dispatch stage is to advance instructions from the instruction buffer to the reservation stations. The 620 uses an in-order dispatch policy.



### 6.4.1  Instruction Buffer
The eight-entry instruction buffer sits between the fetch stage and the dispatch stage.
The fetch stage is responsible for filling the instruction buffer. The dispatch stage examines the first four entries of the instruction buffer and attempts to dispatch them to the reservation stations. As instructions are dispatched, the remaining instructions in the instruction buffer are shifted in groups of two to fill the vacated entries.

Figure 6.3(a) shows the utilization of the instruction buffer by profiling the frequencies of having specific numbers of instructions in the instruction buffer. The instruction buffer decouples the fetch stage and the dispatch stage and moderates the temporal variations of and differences between the fetching and dispatching parallelisms. The frequency of having zero instructions in the instruction buffer is significantly lower in the floating-point benchmarks than in the integer benchmarks.

This frequency is directly related to the rnisprediction frequency shown in Table 6.4.
At the other end of the spectrum, instruction buffer saturation can cause fetch stalls.


### 6.4.2  Dispatch Stalls
The 620 dispatches instructions by checking in parallel for all conditions that can cause dispatch to stall. This list of conditions is described in the following in greater detail. During simulation, the conditions in the list are checked one at a time and in the order listed. Once a condition that causes the dispatch of an instruction to stall is identified, checking of the rest of the conditions is aborted, and only that condition is identified as the source of the stall.

Serialization Constraints. Certain instructions cause single-instruction serialization. All previously dispatched instructions must complete before the serializing instruction can begin execution, and all subsequent instructions must wait until the serializing instruction is finished before they can dispatch. This condition, though extremely disruptive to performance, is quite rare.

Branch Wait for mtspr. Some forms of branch instructions access the count register during the dispatch stage. A move to special-purpose register (mtspr) instruction that writes to the count register will cause subsequent dependent branch instructions to delay dispatching until it is finished. This condition is also rare.

Register Read Port Saturation. There are seven read ports for the generalpurpose register file and four read ports for the floating-point register file. Occasionally, saturation of the read ports occurs when a read port is needed but none is available. There are enough condition register field read ports (three) that saturation cannot occur.is placed into the reservation station of the instruction's associated execution unit.

The instruction remains in the reservation station until it is issued. There is one reservation station per execution unit, and each reservation station has multiple entries, depending on the execution unit. Reservation station saturation occurs when an instruction can be dispatched to a reservation station but that reservation station has no more empty entries.

Rename Buffer Saturation. As each instruction is dispatched, its destination register is renamed into the appropriate rename buffer files . There are three rename buffer files, for general-purpose registers, floating-point registers, and condition register fields. Both the general-purpose register file and the floatingpoint register file have eight rename buffers. The condition register field file has 16 rename buffers.

Completion Buffer Saturation. Completion buffer entries are also allocated during the dispatch stage. They are kept until the instruction has completed. The 620 has 16 completion buffer entries; no more than 16 instructions can be in flight at the same time. Attempted dispatch beyond 16 in-flight instructions will cause a stall. Figure 6.3(b) illustrates the utilization profiles of the completion buffer for the benchmarks.

Another Dispatched to Same Unit. Although a reservation station has multiple entries, each reservation station can receive at most one instruction per cycle even when there are multiple available entries in a reservation station. Essentially, this constraint is due to the fact that each of the reservation stations has only one write port.



### 6.4.3  Dispatch Effectiveness
The average utilization of all the buffers is provided in Table 6.6. Utilization of the load/store unit's three reservation station entries averages 1.36 to 1.73 entries for integer benchmarks and 0.98 to 2.26 entries for floating-point benchmarks. Unlike the other execution units, the load/store unit does not deallocate a reservation station entry as soon as an instruction is issued. The reservation station entry is held until the instruction is finished, usually two cycles after the instruction is issued.

This is due to the potential miss in the D-cache or the TLB . The reservation station entries in the floating-point unit are more utilized than those in the integer units.
The in-order issue constraint of the floating-point unit and the nonpipelining of some floating-point instructions prevent some ready instructions from issuing. The average utilization of the completion buffer ranges from 9 to 14 for the benchmarks and corresponds with the average number of instructions that are in flight.

Sources of dispatch stalls are summarized in Table 6.7 for all benchmarks.
The data in the table are percentages of all the cycles executed by each of the benchmarks. For example, in 24.35% of the compress execution cycles, no dispatch stalls occurred; i.e., all instructions in the dispatch buffer (first four entries of the instruction buffer) are dispatched. A common and significant source of bottleneckSummary of averag e number of buffers used 


## 6.3 'Values given are percentages.

for all the benchmarks is the saturation of reservation stations, especially in the load/store unit. For the other sources of dispatch stalls, the degrees of various bottlenecks vary among the different benchmarks. Saturation of the rename buffers is significant for compress and tomcatv, even though on average their renameaivinn, which has the highest frequency of having all 16 entries utilized; see Figure 6.3(b). Contention for the single write port to each reservation station is also a serious bottleneck for many benchmarks.

Figure 6.4(a) displays the distribution of dispatching parallelism (the number of instructions dispatched per cycle). The number of instructions dispatched in each cycle can range from 0 to 4. The distribution indicates the frequency (averaged across the entire trace) of dispatching n instructions in a cycle, where n = 0, 1, 2,3,4.

In all benchmarks, at least one instruction is dispatched per cycle for over one-half of the execution cycles.ion Parallelisms.
Instruction Execution

The 620 widens in the execute stage. While the fetch , dispatch, complete, and writeback stages all are four wide, i.e., can advance up to four instructions per cycle, the execute stage contains six execution units and can issue and finish up to six instructions per cycle. Furthermore, unlike the other stages, the execute stage processes instructions out of order to achieve maximum throughput.




### 6.5.1  Issue Stalls
Once instructions have been dispatched to reservation stations, they must wait for their source operands to become available, and then begin execution. There are a few other constraints, however. The full list of issuing hazards is described here.
Out of Order Disallowed. Although out-of-order execution is usually allowed from reservation stations, it is sometimes the case that certain instructions may not proceed past a prior instruction in the reservation station. This is the case in the branch unit and the floating-point unit, where instructions must be issued in order.

Serialization Constraints. Instructions which read or write non-renamed registers (such as XER), which read or write renamed registers in a non-renamed fashion (such as load/store multiple instructions), or which change or synchronize machine state (such as the eieio instruction, which enforces in-order execution of I/O) must wait for all prior instructions to complete before executing. These instructions stall in the reservation stations until their serialization constraints are satisfied.

Waiting for Source Operand. The primary purpose of reservation stations is to hold instructions until all their source operands are ready. If an instruction requires a source that is not available, it must stall here until the operand is forwarded to it.
Waiting for Execution Unit. Occasionally, two or more instructions will be ready to begin execution in the same cycle. In this case, the first will be issued, but the second must wait. This condition also applies when an instruction is executing in the MC-FXU (a nonpipelined unit) or when a floating-point divide instruction puts the FPU into non pipe lined mode.

The frequency of occurrence for each of the four issue stall types is summarized in Table 6.8. The data are tabulated for all execution units except the branch unit. Thus, the in-order issuing restriction only concerns the floating-point unit.
The number of issue serialization stalls is roughly proportional to the number of multi cycle integer instructions in the benchmark's instruction mix. Most of these multicycle instructions access the special-purpose registers or the entire condition register as a non-renamed unit, which requires serialization. Most issue stalls due to waiting for an execution unit occur in the load/store unit. More load/store instructions are ready to execute than the load/store execution unit can accommodate.

Across all benchmarks, in significant percentages of the cycles, no issuing stalls are encountered.

### 6.5.2 Execution Parallelism

Here we examine the propagation of instructions through issuing, execution, and finish. Figure 6.4(b) shows the distribution of issuing parallelism (the number of instructions issued per cycle). The maximum number of instructions that can be issued in each cycle is six, the number of execution units. Although the issuing parallelism and the dispatch parallelism distributions must have the same average value, issuing is less centralized and has fewer constraints and can therefore achieve a more consistent rate of issuing. In most cycles, the number of issued instructions is close to the overall sustained IPC, while the dispatch parallelism has more extremes in its distribution.

We expected the distribution of finishing parallelism, shown in Figure 6.4(c), to look like the distribution of issuing parallelism because an instruction after it is issued must finish a certain number of cycles later. Yet this is not always the case as can be seen in the issuing and finishing parallelism distributions of the eqntott, alvinn, and hydro2d benchmarks. The difference comes from the high frequency of load/store and floating-point instructions. Since these instructions do not take the same amount of time to finish after issuing as the integer instructions, they tend to shift the issuing parallelism distribution. The integer benchmarks, with their more consistent instruction execution latencies, generally have more similarity between their issuing and finishing parallelism distributions.



### 6.5.3 Execution Latency

It is of interest to examine the average latency encountered by an instruction from dispatch until finish. If all the issuing constraints are satisfied and the execution unit is available, an instruction can be dispatched from the dispatch buffer to a reservation station, and then issued into the execution unit in the next cycle. This is the best case. Frequently, instructions must wait in the reservation stations. Hence, the overall execution latency includes the waiting time in the reservation station and the actual latency of the execution units. Table 6.9 shows the average overall execution latency encountered by the benchmarks in each of the six execution units.Average execution latency (in cycles) in each of the six execution units for the benchmarks Execution Units 



## 6.6 Instruction Completion

Once instructions finish execution, they enter the completion buffer for in-order completion and writeback. The completion buffer functions as a reorder buffer to reorder the out-of-order execution in the execute stage back to the sequential order for in-order retiring of instructions.


### 6.6.1  Completion Parallelism
The distributions of completion parallelism for all the benchmarks are shown in Figure 6.4(d). Again, similar to dispatching, up to four instructions can be completed per cycle. An average value can be computed for each of the parallelism distributions. In fact, for each benchmark, the average completion parallelism should be exactly equal to the average dispatching, issuing, and finishing parallelisms, which are all equal to the sustained IPC for the benchmark. In the case of instruction completion, while instructions are allowed to finish out of order, they can only complete in order. This means that occasionally the completion buffer will have to wait for one slow instruction to finish, but then will be able to retire its maximum of four instructions at once. On some occasions, the completion buffer can saturate and cause the stalling at the dispatch stage; see Figure 6.3(b).

The integer benchmarks with their more consistent execution latencies usually have one instruction completed per cycle. Hy dro2d completes zero instructions in a large percentage of cycles because it must wait for floating-point divide instructions to finish. Usually, instructions cannot complete because they, or instructions preceding them, are not finished yet. However, occasionally there are other reasons.

The 620 has four integer and two floating-point writeback ports. It is rare to run out of integer register file write ports. However, floating-point write port saturation occurs occasionally.


### 6.6.2  Cache Effects
The D-cache behavior has a direct impact on the CPU performance. Cache misses can cause additional stall cycles in the execute and complete stages. The D-cache in the 620 is interleaved in two banks, each with an address port. A load or store instruction can use either port. The cache can service at most one load and one store at the same time. A load instruction and a store instruction can access the cache in the same cycle if the accesses are made to different banks. The cache is nonblocking, only for the port with a load access. When a load cache miss is encountered and while a cache line is being filled, a subsequent load instruction can proceed to access the cache. If this access results in a cache hit, the instruction can proceed without being blocked by the earlier miss. Otherwise, the instruction is returned to the reservation station. The multiple entries in the load/ store reservation station and the out-of-order issuing of instructions allow the servicing of a load with a cache hit past up to three outstanding load cache misses.

The sequential consistency model for main memory imposes the constraint that all memory instructions must appear to execute in order. However, if all memory instructions are to execute in sequential order, a significant amount of performance can be lost. The 620 executes all store instructions, which access the cache after the complete stage (using the physical address), in order; however, it allows load instructions, which access the cache in the execute stage (using the virtual address), to bypass store instructions. Such relaxation is possible due to the weak memory consistency model specified by the PowerPC ISA [May et ai., 1994].

When a store is being completed, aliasing of its address with that of loads that have bypassed and finished is checked. If aliasing is detected, the machine is flushed when the next load instruction is examined for completion, and refetching of that load instruction is carried out. No forwarding of data is made from a pending store instruction to a dependent load instruction. The weak ordering of memory accesses can eliminate some unnecessary stall cycles. Most load instructions are at the beginning of dependence chains, and their earliest possible execution can make available other instructions for earlier execution.

Table 6.10 summarizes the nonblocking cache effect and the weak ordering of load/store instructions. The first line in the table gives the D-cache hit rate for all the benchmarks. The hit rate ranges from 94.2% to 99.9%. Because of the nonblocking feature of the cache, a load can bypass another load if the trailing load is a cache hit at the time that the leading load is being serviced for a cache miss. The percentage (as percentage of all load instructions) of all such trailing loads that actually bypass a missed load is given in the second line of Table 6.10. When a store is completed, it enters the complete store queue, waits there until the store writes to the cache, and then exits the queue. During the time that a pending store is in the queue, a load can potentially access the cache and bypass the store.

The third line of Table 6.10 gives the percentage of all loads that, at the time of the load cache access, bypass at least one pending store. Some of these loads have addresses that alias with the addresses of the pending stores. The percentage of all loads that bypass a pending store and alias with any of the pending store addresses is given in the fourth line of the table. Most of the benchmarks have an insignificant number of aliasing occurrences. The fifth line of the table gives the average number of pending stores, or the number of stores in the store complete queue, in each cycle.



## 6.7 Conclusions and Observations

The most interesting parts of the 620 microarchitecture are the branch prediction mechanisms, the out-of-order execution engine, and the weak ordering of memory accesses. The 620 does reasonably well on branch prediction. For the floating-point benchmarks, about 94% to 99% of the branches are resolved or correctly predicted, incurring little or no penalty cycles. Integer benchmarks yield another story. The range drops down to 89% to 91 %. More sophisticated prediction algorithms, for example, those using more history information, can increase prediction accuracy.

It is also clear that floating-point and integer benchmarks exhibit significantly different branching behaviors. Perhaps separate and different branch prediction schemes can be employed for dealing with the two types of benchmarks.
Even with having to support precise exceptions, the out-of-order execution engine in the 620 is still able to achieve a reasonable degree of instruction-level parallelism, with sustained IPe ranging from 0.99 to 1.44 for integer benchmarks and from 0.96 to 1.77 for floating-point benchmarks. One hot spot is the load/store unit. The number of load/store reservation station entries and/or the number of load/store units needs to be increased. Although the difficulties of designing a system with multiple load/store units are myriad, the load/store bottleneck in the 620 is evident. Having only one floating-point unit for three integer units is also a source of bottleneck. The integer benchmarks rarely stall on the integer units, but the floating-point benchmarks do stall while waiting for floating-point resources.

The single dispatch to each reservation station in a cycle is also a source of dispatch stalls, which can reduce the number of instructions available for out-of-order execution. One interesting tradeoff involves the choice of implementing distributed reservation stations, as in the 620, versus one centralized reservation station, as in the Intel P6. The former approach permits simpler hardware since there are onlyand the reservation station entries among different instruction types.

Allowing weak-ordering memory accesses is essential in achieving high performance in modem wide superscalar processors. The 620 allows loads to bypass stores and other loads; however, it does not provide forwarding from pending stores to dependent loads. The 620 allows loads to bypass stores but does not check for aliasing until completing the store. This store-centric approach makes forwarding difficult and requires that the machine be flushed from the point of the dependent load when aliasing occurs. The 620 does implement the D-cache as two interleaved banks, and permits the concurrent processing of one load and one store in the same cycle if there is no bank conflict. Using the standard rule of thumb for dynamic instruction mix, there is a clear imbalance with the processing of load/ store instructions in current superscalar processors. Increasing the throughput of load/store instructions is currently the most critical challenge. As future superscalar processors get wider and their clock speeds increase, the memory bottleneck problem will be further exacerbated. Furthermore, commercial applications such as transaction processing (not characterized by the SPEC benchmarks) put even greater pressure on the memory and chip I/O bottleneck.

It is interesting to examine superscalar introductions contemporaneous to the 620 by different companies, and how different microprocessor families have evolved; see Figure 6.5 . The PowerPC microprocessors and the Alpha AXP microprocessors represent two different approaches to achieving high performance in superscalar machines. The two approaches have been respectively dubbed "brainiacs vs. speed demons." The PowerPC microprocessors attempt to achieve the highest level of IPC possible without overly compromising the clock speed.
On the other hand, the Alpha AXP microprocessors go for the highest possible clock speed while achieving a reasonable level of IPC. Of course, future versions of PowerPC chips will get faster and future Alpha AXP chips will achieve higher IPC. The key issue is, which should take precedence, IPC or MHz? Which approach will yield an easier path to get to the next level of performance? Although these versions of the PowerPC 620 microprocessor and the Alpha AXP 21164 microprocessor seem to indicate that the speed demons are winning, there is no strong consensus on the answer for the future . In an interesting way, the two rivaling approaches resemble, and perhaps are a reincamation of, the CISC vs.

RISC debate of a decade earlier [Colwell et aI., 1985].
The announcement of the P6 from Intel presents another interesting case. The P6 is comparable to the 620 in terms of its microarchitectural aggressiveness in achieving high IPC. On the other hand the P6 is somewhat similar to the 21164 in that they both are more "superpipelined" than the 620. The P6 represents yet a third, and perhaps hybrid, approach to achieving high performance. Figure 6.5 reflects the landscape that existed circa the mid-1990s. Since then the landscape has shifted significantly to the right. Today we are no longer using SPECInt92 benchmarks but SPECInt2000, and we are dealing with frequencies in the multiple-gigahertz range.




## 6.8 Bridging to the IBM POWER3 and POWER4

The PowerPC 620 was intended as the initial high-end 64-bit implementation of the PowerPC architecture that would satisfy the needs of the server and highperformance workstation market. However, because of numerous difficulties in finishing the design in a timely fashion , the part was delayed by several years and ended up only being used in a few server systems developed by Groupe Bull. In the meantime, IBM was able to satisfy its need in the server product line with the Star series and POWER2 microprocessors, which were developed by independent design teams and differed substantially from the PowerPC 620.

However, the IBM POWER3 processor, released in 1998, was heavily influenced by the PowerPC 620 design and reused its overall pipeline structure and many of its functional blocks [O ' Connell and White, 2000]. Table 6.11 summarizes some of the key differences between the 620 and the POWER3 processors.

Design optimization combined with several years of advances in semiconductor technology resulted in nearly tripling the processor frequency, even with a similar pipeline structure, resulting in noticeable performance improvement.
The POWER3 addressed some of the shortcomings of the PowerPC 620 design by substantially improving both instruction execution bandwidth as well as memory bandwidth. Although the front and back ends of the pipeline remained the same width, the POWER3 increased the peak issue rate to eight instructions per cycle by providing two load/store units and two fully pipelined floating-point units. The effective window size was also doubled by increasing the completion buffer to 32 entries and by doubling the number of integer rename registers and tripling the number of floating-point rename registers. Memory bandwidth was further enhanced with a novel 128-way set-associative cache design that embeds tag match hardware directly into the tag arrays of both L 1 caches, significantly reducing the miss rates, and by doubling the overall size of the data cache. The L2 cache size also increased substantially, as did available bandwidth to the off-chip L2 cache. Memory latency was also effectively decreased by incorporating an aggressive hardware prefetch engine that can detect up to four independent reference streams and prefetch them from memory. This prefetching scheme works extremely well for floating-point workloads with regular, predictable access patterns.

Finally, support for multiple outstanding cache misses was added by providing two miss-status handling registers (MSHRs) for the instruction cache and four MSHRs for the data cache.
The next new high-performance processor in the PowerPC family was the POWER4 processor, introduced in 2001 [Tendler et aI., 2001]. Key attributes of this entirely new core design are summarized in Table 6.11. IBM achieved yet another tripling of processor frequency, this time by employing a substantially deeper pipeline in conjunction with major advances in process technology (i.e., reduced feature sizes, copper interconnects, and silicon-on-insulator technology).

The POWER4 pipeline is illustrated in Figure 6.6 and extends to 15 stages for the best case of single-cycle integer ALU instructions. To keep this pipeline fed with useful instructions, the POWER4 employs an advanced combining branch predictor that uses a 16K entry selector table to choose between a 16K entry bimodal predictor and a 16K entry gshare predictor. Each entry in each of the three tables is only I bit, Branch redirects
Source: Tendler et aI., 2001.

rather than a 2-bit up-down counter, since studies showed that 16K I-bit entries performed better than 8K 2-bit entries. This indicates that for the server workloads the POWER4 is optimized for, branch predictor capacity misses are more important than the hysteresis provided by 2-bit counters.
The POWER4 matches the POWER3 in execution bandwidth, but provides substantially more rename registers (now in the form of a single physical register file) and supports up to 200 in-flight instructions in its pipeline. As in the POWER3, memory bandwidth and latency were important considerations, and multiple load! store units, support for up to eight outstanding cache misses, a very-high-bandwidth interface to the on-chip L2, and support for a massive off-chip L3 cache, all play an integral role in improving overall performance. The POWER4 also packs two complete processor cores sharing an L2 cache on a single chip in a chip multiprocessor configuration. More details on this arrangement are discussed in Chapter II .




## 6.9 Summary

The PowerPC 620 is an interesting first-generation out-of-order superscalar processor design that exemplifies the short pipelines, aggressive support for extracting instruction-level parallelism, and support for weak ordering of memory references that are typical for other processors of a similar vintage (for example, the HP PA8000 [Gwennap, 1994] and the MIPS RlOOOO [Yeager, 1996]). Its evolution into the IBM POWER3 part illustrates the natural extension of execution resources to extract even greater parallelism while also tackling the memory bandwidth and latency bottlenecks. Finally, the recent POWER4 design highlights the seemingly heroic efforts of microprocessors today to tolerate memory bandwidth and latency with aggressive on- and off-chip cache hierarchies, stream-based hardware prefetching, and very large instruction windows. At the same time, the POWER4 illustrates the trend toward higher and higher clock frequency through extremely deep pipe lining, which can only be sustained as a result of increasingly accurate branch predictors that keep such pipelines filled with useful instructions.


## REFERENCES
Colwell, R., C. Hitchcock, E. Jensen, H. B. Sprunt, and C. Kollar: " Instructions sets and beyond: Computers, complexity, and controversy," IEEE Computer, 18,9,1985, pp. 8-19.

Diep, T. A., C. Nelson, and J. P. Shen: "Performance evaluation of the PowerPC 620 microarchitecture," Proc. 22nd Int. Symposium on Computer Architecture, Santa Margherita Ligure, Italy, 1995.

Gwennap, L.: "PA-8000 combines complexity and speed," Microprocessor Report, 8, 15, 1994, pp. 6-9.

IBM Corp.: PowerPC 60J RISC Microprocessor User's Manual. IBM Microelectronics Division, 1993.

IBM Corp.: PowerPC 604 RISC Microprocessor User's Manual. IBM Microelectronics Division, 1994.

Levitan, D., T. Thomas, and P. Tu: "The PowerPC 620 microprocessor: A high performance superscalar RISC processor," Proc. of CaMP CON 95, 1995, pp. 285-291.

May, C., E. Silha, R. Simpson, and H. Warren: The PowerPC Architecture: A Specification for a New Family of RISC Processors, 2nd ed. San Francisco, CA, Morgan Kauffman, 1994.

Motorola, Inc.: MPC750 RISC Microprocessor Family User's Manual. Motorola, Inc., 2001.

Motorola, Inc.: MPC603e RISC Microprocessor User's Manual. Motorola, Inc., 2002.

Motorola, Inc.: MPC7450 RISC Microprocessor Family User's Manual. Motorola, Inc., 2003 .

O'Connell, F., and S. White: "POWER3: the next generation of PowerPC processors," IBM Journal of Research and Development, 44, 6, 2000, pp. 873-884.

Storino, S., A. Aipperspach, J. Borkenhagen, R. Eickemeyer, S. Kunkel, S. Levenstein, and G. Uhlmann: "A commercial multi-threaded RISC processor," Int. Solid-State Circuits Conferenc e, 1998.

Tendler, J. M., S. Dodson, S. Fields, and B. Sinharoy: "IBM eserver POWER4 system microarchitecture," IBM Whitepaper, 200 I.

Yeager, K.: "The MIPS RlOOOO superscalar microprocessor," IEEE Micro, 16, 2, 1996, pp.28-40.




