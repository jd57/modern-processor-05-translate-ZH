Survey of Superscalar Processors
CHAPTER OUTLINE


## 8.1 Development of Superscalar Processors



## 8.2 A Classification of Recent Designs



## 8.3 Processor Descriptions



## 8.4 Verification of Superscalar Processors



## 8.5 Acknowledgments
References
Homework Problems

The 1990s was the decade in which superscalar processor design blossomed.
However, the idea of decoding and issuing multiple instructions per cycle from a single instruction stream dates back 25 years before that. In this chapter we review the history of superscalar design and examine a number of selected designs.



## 8.1 Development of Superscalar Processors

This section reviews the history of superscalar design, beginning with the IBM Stretch and its direct superscalar descendant, the Advanced Computer System (ACS), and follows developments up through current processors.



### 8.1.1 Early Advances in Uniprocessor Parallelism: The IBM Stretch 
architecture in the I 990s), it is appropriate to review the Stretch, also known as the IBM 7030 [Buchholz, 1962].
The Stretch design started in 1955 when IBM lost a bid on a high-performance decimal computer system for the University of California Radiation Laboratory (Livermore Lab). Univac, IBM's competitor and the dominant computer manufacturer at the time, won the contract to build the Livermore Automatic Research Computer (LARC) by promising delivery of the requested machine in 29 months [Bashe et aI., 1986] . IBM had been more aggressive, and its bid was based on a renegotiation clause for a machine that was four to five times faster than requested and cost $3.5 million rather than the requested $2.5 million.

In the following year, IBM bid a binary computer of "speed at least 100 times greater than that of existing machines" to the Los Alamos Scientific Laboratory and won a contract for what would become the Stretch. Delivery was slated for 1960. Stephen Dunwell was chosen to head the project, and among those he recruited for the design effort were Gerrit Blaauw, Fred Brooks, John Cocke, and Harwood Kolsky. While Blaauw and Brooks investigated instruction set design ideas, which would later serve them as they worked on the IBM S/360, Cocke and Kolsky constructed a crucial simulator that would help the team explore organization options. Erich Bloch, later to become chief scientist at IBM, was named engineering manager in 1958 and led the implementation efforts on prototype units in that year and on an engineering model in 1959.

Five test programs were selected for the simulation to help determine machine parameters: a hydrodynamics mesh problem, a Monte Carlo neutron-diffusion code, the inner loop of a second neutron diffusion code, a polynomial evaluation routine, and the inner loop of a matrix inversion routine. Several Stretch 'instructions intended for scientific computation of this kind, such as a branch-on-count and multiply-andadd (called cumulative multiply in Stretch and later known as fused multiply and add), would become important to RS/6000 performance some 30 years later.

Instructions in Stretch flowed through two processing elements: an indexing and instruction unit that fetched, pre-decoded, and partially executed the instruction stream, and an arithmetic unit that executed the remainder of the instructions.
Stretch also partitioned its registers according to this organization; a set of sixteen 64-bit index registers was associated with the indexing and instruction unit, and a set of 64-bit accumulators and other registers was associated with the arithmetic unit. Partitioned register sets also appear on the ACS and the RS/6000.

The indexing and instruction unit (see Figure 8.1) of Stretch fetched 64-bit memory words into a two-word instruction buffer. Instructions could be either 32 or 64 bits in length, so up to four instructions could be buffered. The indexing and instruction unit directly executed indexing instructions and prepared arithmetic instructions by calculating effective addresses (i.e., adding index register contents to address fields) and starting memory operand fetches. The unit was itself pipelined and decoded instructions in parallel with execution. One interesting feature of the instruction fetch logic was the addition of pre-decoding bits to all instructions; this was done one word at a time, so two half-word instructions could be predecoded in parallel.

Unconditional branches and conditional branches that depended on the state of the index registers, such as the branch-on-count instruction, could be fully executed in the indexing and instruction unit (compare with the branch unit on RS/6000).
Conditional branches that depended on the state of the arithmetic registers were predicted untaken, and the untaken path was speculatively executed.

All instructions, either fully executed or prepared, were placed into a novel form of buffering called a lookahead unit, which was at that time also called a virtual memory but which we would view today as a combination of a completion buffer and a history buffer. A fully executed indexing instruction would be placed into one of the four levels of lookahead along with its instruction address and the previous value of any index register that had been modified. This history of old values provided a way for the lookahead levels to be rolled back and thus restore the contents of index registers on a mispredicted branch, interrupt, or exception. A prepared arithmetic instruction would also be placed into a lookahead level along with its instruction address, and there it would wait for the completion of its memory operand fetch. A feature that foreshadows many current processors is that some of the more complex Stretch instructions had to be broken down into separate parts and stored into multiple lookahead levels.

An arithmetic instruction would be executed by the arithmetic unit whenever its lookahead level became the oldest and its memory operand was available.
Arithmetic exceptions were made precise by causing a rollback of the lookahead levels, just as would be done in the case of a mispredicted branch. A store instruction was also executed when its lookahead level became the oldest. While the store was in the lookahead, store forwarding was implemented by checking the memory address of each subsequent load placed in the lookahead. If the address to be read matched the address to be stored, the load was canceled, and the store value wasOnly one outstanding store at a time was allowed in the lookahead. Also, because of potential instruction modification, the store address was compared to each of the instruction addresses in the lookahead levels.

Stretch was implemented with 169,100 transistors and 96K 64-bit words of core memory. The clock cycle time was 300 ns (up from the initial estimates of 100 ns) for the indexing unit and lookahead unit, while the clock cycle time for the variable-length field unit and parallel arithmetic unit was 600 ns. Twenty-three levels of logic were allowed in a path, and a connection of approximately 15 feet (ft) was counted as one-half level. The parallel arithmetic unit performed one floatingpoint add each 1.5 J..ls and one floating-point multiply every 2.4 J..ls. The processing units dissipated 21 kilowatts (kW). The CPU alone (without its memory banks) measured 30 ft by 6 ft by 5 ft.

As the clock cycle change indicates, Stretch did not live up to its initial performance promises, which had ranged from 60 to 100 times the performance of a 704. In 1960, product planners set a price of $13 .5 million for the commercial form of Stretch, the 7030. They estimated that its performance would be eight times the performance of a 7090, which was itself eight times the performance of a 704. This estimation was heavily based on arithmetic operation timings.

When Stretch became operational in 1961, benchmarks indicated that it was only four times faster than a 7090. This difference was in large part due to the store latency and the branch misprediction recovery time, since both cases stalled the arithmetic unit. Even though Stretch was the fastest computer in the world (and remained so until the introduction of the CDC 6600 in 1964), the performance shortfall caused considerable embarrassment for IBM. In May 1961, Tom Watson announced a price cut of the 7030s under negotiation to $7.78 million and immediately withdrew the product from further sales.

While Stretch turned out to be slower than expected and was delivered a year later than planned, it provided IBM with enormous advances in transistor design and computer organization principles. Work on Stretch circuits allowed IBM to deliver the first of the popular 7090 series 13 months after the initial contract in 1958; and, multiprogramming, memory protection, generalized interrupts, the 8-bit byte, and other ideas that originated in Stretch were subsequently used in the very successful S/360. Stretch also pioneered techniques in uniprocessor parallelism, including decoupled access-execute execution, speculative execution, branch misprediction recovery, and precise exceptions. It was also the first machine to use memory interleaving and the first to buffer store values and provide forwarding to subsequent loads. Stretch provided a wonderful training ground for John Cocke and others who would later propose and investigate the idea of parallel decoding of multiple instructions in follow-on designs.




### 8.1.2  First Superscalar Design: 
The IBM Advanced Computer System In 1961, IBM started planning for two high-performance projects to exceed the capabilities of Stretch. Project X had a goal of 10 to 30 times the performance of Stretch, and this led to the announcement of the IBM S/360 Model 91 in 1964 and its delivery in 1967. The Model 91's floating-point unit is famous for executing instructions out-of-order, according to an algorithm devised by Robert Tomasulo.

The initial cycle time goal for Project X was 50 ns, and the Model 91 shipped at a 60-ns cycle time. Mike Flynn was the project manager for the IBM S/360 Model 91 up until he left IBM in 1966.
The second project, named Project Y, had a goal of building a machine that was 100 times faster than Stretch. Project Y started in 1961 at IBM Watson Research Center. However, because of Watson's overly critical assessment of Stretch, Project Y languished until the 1963 announcement of the CDC 6600 (which combined scalar instruction issue with out-of-order instruction execution among its 10 execution units and ran with a 100-ns cycle time; see Figure 4.6). Project Y was then assigned to Jack Bertram' s experimental computers and programming group; and John Cocke, Brian Randell, and Herb Schorr began playing major roles in defining the circuit technology, instruction set, and compiler technology.

In late 1964, sales of the CDC 6600 and the announcement of a 25-ns cycle time 6800 (later redesigned and renamed the 7600) added urgency to the Project Y effort.
Watson decided to "go for broke on a very advanced machine" (memo dated May 17, 1965 [Pugh, 1991]), and in May 1965, a supercomputer laboratory was established in Menlo Park, California, under the direction of Max Paley and Jack Bertram. The architecture team was led by Herb Schorr, the circuits team by Bob Domenico, the compiler team by Fran Allen, and the engineering team by Russ Robelen. John Cocke arrived in California to work on the compilers in 1966. The design became known as the Advanced Computer System 1 (ACS-l) [Sussenguth, 1990].

The initial clock cycle time goal for ACS-l was 10 ns, and a more aggressive goal was embraced of 1000 times the performance of a 7090. To reach the cycle time goal, the ACS-l pipeline was designed with a target of five gate levels of logic per stage. The overall plan was ambitious and included an optimizing compiler as well as a new operating system, streamlined I/O channels, and multiheaded disks as integral parts of the system. Delivery was at first anticipated for 1968 to expected customers such as Livermore and Los Alamos. However, in late 1965, the target introduction date was moved back to the 1970 time frame.

Like the CDC 6600 and modem RISC architectures, most ACS-l instructions were defined with three register specifiers. There were thirty-one 24-bit index registers and thirty-one 48-bit arithmetic registers. Because it was targeted to numbercrunching at the national labs, the single-precision floating-point data used a 48-bit format and double-precision data used 96 bits. The ACS-l also used 31 backup registers, each one being paired with a corresponding arithmetic register. This provided a form of register renaming, so that a load or write back could occur to the backup register whenever a dependency on the previous register value was still outstanding.

Parallel decoding of multiple instructions and dispatch to two reservation stations, one of which provided out-of-order issue, were proposed for the processor (see Figure 8.2). Schorr wrote in his 1971 paper on the ACS-l that "multiple decoding was a new function examined by this project." Cocke in a 1994 interview stated that he arrived at the idea of multiple instruction decoding for ACS-l in response to an IBM internal report written by Gene Amdahl in the early 1960s system in which Amdahl postulated one instruction decode per cycle as one of the fundamental limits on obtainable performance. Cocke wanted to test each supposed fundamental limitation and decided that multiple decoding was feasible. (See also Flynn [1966] for a discussion of this limit and the difficulty of multiple decoding.) Although Cocke had made some early proposals for methods of multiple instruction issue, in late 1965 Lynn Conway made the contribution of the generalized scheme for dynamic instruction scheduling that was used in the design. She described a contender stack that scheduled instructions in terms of source and destination scheduling matrices and a busy vector. Instruction decoding and filling of the matrices would stop on the appearance of a conditional branch and resume only when that branch was resolved. The matrices were also scanned in reverse order to give priority to the issue of the conditional branch.

The resulting ACS-l processor design had six function units for index operations: compare, shift, add, branch address calculation, and two effective address adders. It had seven function units for arithmetic operations: compare, shift, logic, add, divide/integer multiply, floating-point add, and floating-point mUltiply. Up to seven instructions could be issued per cycle: three index operations (two of which could be load/stores), three arithmetic operations, and one branch. The eight-entry load/store/index instruction buffer could issue up to three instructions in order. The eight-entry arithmetic instruction buffer would search for up to three ready instructions and could issue these instructions out of order. (See U.S. Patent 3,718,912.) Loads were sent to both instruction buffers to maintain instruction ordering.

Recognizing that they could lose half or more of the design's performance on branching, the designers adopted several aggressive techniques to reduce the number of branches and to speed up the processing of those branches and other transfers of control that remained:
* Ed Sussenguth and Herb Schorr divided the actions of a conditional branch into three separate categories: branch target address calculation, taken! untaken determination, and PC update. The ACS-l combined the first two actions in a prepare-to-branch instruction and used an exit instruction to perform the last action. This allowed a variable number of branch delay slots to be filled (called anticipating a branch); but, more importantly, it provided for multi way branch specification. That is, multiple prepare-tobranch instructions could be executed and thereby set up an internal table of multiple branch conditions and associated target addresses, only one of which (the first one that evaluated to true) would be used by the exit instruction. Thus only one redirection of the instruction fetch stream would be required. (See U.S. Patent 3,577,189.)

* A set of 24 condition code registers allowed precalculation of branch conditions and also allowed a single prepare-to-branch instruction to specify a logical expression involving any two of the condition codes. This is similar in concept to the eight independent condition codes in the RS/6000.
* To handle the case of a forward conditional branch with small displacement, a conditional bit was added to each instruction format (i.e., a form of predication). A special form of the prepare-to-branch instruction was used as a conditional skip. At the point of condition resolution, if the condition in the skip instruction was true, any instructions marked as conditional were removed from the instruction queues. If the condition was resolved to be false, then the marked instructions were unmarked and allowed to execute.

(See U.S. Patent 3,577,190.)
* Dynamic branch prediction with I-bit histories provided for instruction prefetch into the decoder, but speculative execution was ruled out because of the previous performance problems with Stretch. A 12-entry target instruction cache with eight instructions per entry was also proposed by Ed Sussenguth to provide the initial target instructions and thus eliminate the four-cycle penalty for taken branches. (See U.S. Patent 3,559,183.) * Up to 50 instructions could be in some stage of execution at any given time, so interrupts and exceptions could be costly. Most external interrupts were converted by the hardware into specially marked branches to the appropriate interrupt handler routines and then inserted into the instruction stream to allow the previously issued instructions to complete. (These were called soft interrupts.) Arithmetic exceptions were handled by having two modes: one for multiple issue with imprecise interrupts and one for serialized issue. This approach was used for the S/360 Model 91 and for the RS/6000.

Main memory was 16-way interleaved, and a store buffer provided for load bypassing, as done in Stretch. Cache memory was introduced within IBM in 1965, leading to the announcement of the S/360 Model 85 in 1968. The ACS-l adopted the cache memory approach and proposed a 64K-word unified instruction and data cache. The ACS-l cache was to be two-way set-associative with a line size of 32 words and last-recently-used (LRU) replacement; a block of up to eight 24-bit instructions could be fetched each cycle. A cache hit would requireto and from the cache.

The ACS-I processor design called for 240,000 circuits: 50% of these were for floating-point, 24% were for indexing, and the remaining 26% were for instruction sequencing. Up to 40 circuits were to be included on an integratedcircuit die. At approximately 30 mW per circuit, the total power dissipation of the processor was greater than 7 kW.

An optimizing compiler with instruction scheduling, register allocation, and global code motion was developed in parallel with the machine design by Fran Allen and John Cocke [Allen, 1981]. Simulation demonstrated that the compiler could produce better code than careful hand optimization in several instances. In her article, Fran Allen credits the ACS-I work as providing the foundations for program analysis and machine independent/dependent optimization.

Special emphasis was given to six benchmark kernels by both the instruction set design and compiler groups. One of these was double-precision floating-point inner product. Cocke estimated that the machine could reach five to six instructions per cycle on linear algebra codes of this type [1998]. Schorr [1971] and Sussenguth [1990] contain performance comparisons between the IBM 7090, CDC 6600, S/360 Model 91, and ACS-l for a simple loop [Lagrangian hydrodynamics calculation (LHC)] and a very complex loop [Newtonian diffusion (ND)] , and these comparisons are given in Table 8.1.

An analysis of several machines was also performed that normalized relative performance with respect to the number of circuits and the circuit speed of each machine. The result was called a relative architectural factor. although average memory access time (affected by the presence or absence of cache memory) affected the results. Based on this analysis, and using the 7090 for normalization, Stretch had a factor of 1.2; both the CDC 6600 and the Model 91 had factors of 1.1; and the Model 195 (with cache) had a factor of 1.7. The ACS-I had a factor of 5.2.

The ACS-l was in competition with other projects within IBM, and by the late 1960s, a design that was incompatible with the S/360 architecture was losing support within the company. Gene Amdahl, having become an IBM Fellow in 1965 and having come to California as a consultant to Paley, began working with John Earle on a proposal to redesign the ACS to provide S/360 compatibility. In early 1968, persuaded by increased sales forecasts, IBM management accepted the Amdahl-Earle plan. However, the overall project was thrown into a state of disarray by this decision, and approximately one-half of the design team left.

Because of the constraint of architectural compatibility, the ACS-360 had to discard the innovative branching and predication schemes, and it also had to provide a strongly ordered memory model as well as precise interrupts. Compatibility also meant that an extra gate level of logic was required in the execution stage, with consequent loss of clock frequency. One ACS-360 instruction set innovation that later made it into the S/370 was start I/O fast release (SIOF), so that the processor would not be unduly slowed by the initiation of I/O channels.

Unfortunately, with the design no longer targeted to number-crunching, the ACS-360 had to compete with other IBM S/360 projects on the basis of benchmarks that included commercial data processing. The result was that the IPC of the ACS-360 was less than one. In 1968, a second instruction counter and a second set of registers were added to the simulator to make the ACS-360 the first simultaneous multithreaded design. Instructions were tagged with an additional redlblue bit to designate the instruction stream and register set; and, as project members had expected, the utilization of the function units increased.

However, it was too late. By 1969, emitter coupled logic (ECL) circuit design problems, coupled with the performance achievements of the cache-based S/360 Model 85, a slowdown in the national economy, and East CoastlWest Coast tensions within the company, led to the cancellation of the ACS-360 [Pugh et aI., 1991]. Amdahl left shortly thereafter to start his own company. Further work was done at IBM on superscalar S/370s up through the 1990s. However, IBM never produced a superscalar mainframe, with the notable exception of a processor announced 25 years later, the ES/9000 Model 520 [Liptay, 1992].



### 8.1.3  Instruction-Level Parallelism Studies
In the early 1970s two important studies on multiple instruction decoding and issue were published: one by Gary Tjaden and Mike Flynn [1970] and one by Ed Riseman and Caxton Foster [1972]. Flynn remembers being skeptical of the idea of multiple decoding, but later, with his student Tjaden, he examined some of the inherent problems of interlocking and control in the context of a multipleissue 7094. Flynn also published what appears to be the first open-literature reference to multiple decoding as part of his classic SISD/SIMD/MIMD paper [Flynn, 1966] .

While Tjaden and Flynn concentrated on the decoding logic for a multipleissue IBM 7094, Riseman and Foster examined the effect of branches in CDC 3600 programs. Both groups reported small amounts of available parallelism in the benchmarks they studied 0.86 and l.72 instructions per cycle, respectively); however, Riseman and Foster found increasing levels of parallelism as the number of branches were eliminated by knowing which paths were executed.enthusiasm for fine-grain, single-program parallelism (see Section 1.4.2). It would be the early 1980s before Josh Fisher and Bob Rau's VLIW efforts [Fisher, 1983; Rau et aI., 1982] and Tilak Agerwala and John Cocke's superscalar efforts (see the following) would convince designers of the feasibility of multiple instruction issue and thus inspire numerous design efforts.



### 8.1.4 By-Products of DAE: 
The First Multiple-Decoding Implementations In the early 1980s, work by Jim Smith appeared on decoupled access-execute (DAE) architectures [Smith, 1982; 1984; Smith and Kaminski, 1982; Smith et aI., 1986]. Smith was a veteran of Control Data Corporation (CDC) design efforts and was now teaching at the University of Wisconsin. In his 1982 International Symposium on Computer Architecture (ISCA) paper he gives credit to the IBM Stretch as the first machine to decouple access and execution, thereby allowing memory loads to start as early as possible. Smith's design efforts included architecturally visible queues on which the loads and stores operated. Computational instructions referenced either registers or loaded-data queues. His ideas led to the design and development of the dual-issue Astronautics ZS-1 in the mid-1980s [Smith et aI., 1987].

As shown in Figure 8.3, the ZS-1 fetched 64-bit words from memory into an instruction splitter. Instructions could be either 32 or 64 bits in length, so the splitter could fetch up to two instructions per cycle. Branches were 64 bits and were fully executed in the splitter and removed from the instruction stream; 
unresolved conditional branches stalled the splitter. Access (A) instructions were placed in a four-entry A instruction queue, and execute (X) instructions were placed in a 24-entry X instruction queue. In-order issue occurs from these instruction queues; issue requires that there be no dependences or conflicts, and operands are fetched at that time from registers and/or load queues, as specified in the instruction.

The access processor included three execution units: integer ALU, shift, and integer multiply/divide; and the execute processor included four execution units: logical, floating-point adder, floating-point multiplier, and reciprocal approximation unit. In this manner, up to two instructions could be issued per cycle.

In the 1982 ISCA paper, Smith also cites the CSPI MAP 200 array processor as an example of decoupling access and execution [Cohler and Storer, 1981]. The MAP 200 had separate access and execute processors coupled by FIFO buffers, but each processor had its own program memory. It was up to the programmer to ensure correct coordination of the processors.

In 1986 Glen Culler announced a dual-issue DAE machine, the Culler-7, a multiprocessor with an M68010-based kernel processor and up to four user processors [Lichtenstein, 1986]. Each user processor was a combination of an A machine, used to control program sequencing and data memory addressing and access, and a microcoded X machine, used for floating-point computations and which could run in parallel with the A machine. The A and X machines were coupled by a four-entry input FIFO buffer and a single-entry output buffer. A program memory contained sequences of X instructions, sometimes paired with and then trailed by some number of A instructions.

The X instructions were lookups into a control store of microcode routines; these routines were sequences of horizontal micro-instructions that specified operations for a floating-point adder and multiplier, two 4K-entry scratch pad memories, and various registers and busses. Single-precision floating-point operations were single-cycle, while double-precision operations took two cycles.

User-microcoded routines could also be placed in the control store.
X and A instruction pairs were fetched, decoded, and executed together when available. A common sequence was a single X instruction, which would start a microcoded routine, followed by a series of A instructions to provide the necessary memory accesses. The first pair would be fetched and executed together, and the remaining A instructions would be fetched and executed in an overlapping manner with the multicycle X instruction. The input and output buffers between the X and A machines were interlocked, but the programmer/compiler was responsible for deadlock avoidance (e.g., omission of a required A instruction before the next X instruction).

The ZS-1 and Culler-7, developed without knowledge of each other, represent the first commercially sold processors in which multiple instructions from a single instruction stream were fetched, decoded, and issued in parallel. This dual issue of access and execute instructions will appear several times in later designs (albeit without the FIFO buffers) in which an integer unit will have responsibility for both integer instructions and memory loads and stores and can issue these in parallel with floating-point computation instructions on a floating-point unit.

IBM Cheetah, Panther, and America Tilak Agerwala at IBM Research started a dual-issue project, code-named Cheetah, in the early 1980s with the urging and support of John Cocke. This design incorporated ACS ideas, such as backup registers, as well as ideas from the IBM 801 RISC experimental machine, another John Cocke project (circa 1974 to 1978). The three logical unit types seen in the RS/6000, i.e., branch, fixed-point (integer), and floating-point, were first proposed in Cheetah. A member of the Cheetah group, Pradip Bose, published a compiler research paper at the 1986 Fall Joint Computer Conference describing dual-issue machines such as the Astronautics ZS-1 and the IBM design.

In invited talks at several universities during 1983 to 1984, Agerwala first publicly used the term he had coined for ACS and Cheetah-like machines: superscalar.
This name helped describe the potential performance of multiple-decoding machines, especially as compared to vector processors. These talks, some of which were available on videotape, and a related IBM technical report were influential in rekindling interest in multiple-decoding designs. By the time Jouppi and Wall presented their paper on available instruction-level parallelism at ASPLOS-III [1989] and Smith, Johnson, and Horowitz presented their paper on the limits on multiple instruction issue [1989], also at ASPLOS-III, superscalar and VLIW processors were hot topics.

Further development of the CheetahlPanther design occurred in 1985 to 1986 and led to a four-way issue design called America [Special issue, IBM Journal of Research and Development, 1990]. The design team was led by Greg Grohoski and included Marc Auslander, Al Chang, Marty Hopkins, Peter Markstein, Vicky Markstein, Mark Mergen, Bob Montoye, and Dan Prener. In this design, a generalized register renaming facility for floating-point loads replaced the use of backup registers, and a more aggressive branch-folding approach replaced the Cheetah's delayed branching scheme. In 1986 the IBM Austin development lab adopted the America design and began refining it into the RS/6000 architecture (also known as RIOS and POWER).



### 8.1.6 Oecoupled Microarchitectures

In the middle 1980s, Yale Patt and his students at the University of California, Berkeley, including Wen-Mei Hwu, Steve Melvin, and Mike Shebanow, proposed a generalization of the Tomasulo floating-point unit of the IBM S/360 Model 91, which they called restricted dataflow. The key idea was that a sequential instruction stream could be dynamically converted into a partial data flow graph and executed in a data flow manner. The results of decoding the instruction stream would be stored in a decoded instruction cache (DIC), and this buffer area decouples the instruction decoding engine from the execution engine.



#### 8.1.6.1  Instruction Fission. 
In their work on the high-peiformance substrate
(HPS), Patt and his students determined that regardless of the complexity of the target instruction set, the nodes of the partial dataflow graph stored in the DIC could be RISC-like micro-instructions. They applied this idea to the V AX ISA and found that an average of four HPS micro-instructions were needed per VAX instruction and that a restricted dataflow implementation could reduce the CPI of a VAX instruction stream from the then-current 6 to 2 [patt et aI. , 1986; Wilson et aI., 1987].RISC-like micro-instruction streams was the basis of a number of IA32 processors, including the NexGen NxS86, the AMD KS, and the Intel Pentium Pro. The recent Pentium 4 caches the translated micro-instruction stream in its trace cache, similar to the decoded instruction cache of HPS. This fission-like approach is also used by some nominally reduced instruction set computer processors.

One example is the recent POWER4, which cracks some of the more complex PowerPC instructions into multiple internal operations.



#### 8.1.6.2  Instruction Fusion. 
Another approach to a decoupled microarchitecture is to fetch instructions and then allow the decoding logic to fuse compatible instructions together, rather than break each apart into smaller micro-operations.
The resulting instruction group traverses the execution engine as a unit, in almost the same manner as a VLIW instruction.
One early effort along this line was undertaken at AT&T Bell Labs in the middle 1980s to design a decoupled scalar pipeline as part of the C Machine Project. The result was the CRISP microprocessor, described in 1987 [Ditzel and McLellan, 1987; Ditzel et aI., 1987]. CRISP translated variable-length instructions into fixed-length formats , including next-address fields, during traversal of a three-stage decode pipeline. The resulting decoded instructions were placed into a 32-entry DIC, and a three-stage execution pipeline fetched and executed these decoded entries. By collapsing computation instructions and branches in this manner, CRISP could run simple instruction sequences at a rate of greater than one instruction per cycle. The Motorola 68060 draws heavily from this design.

Another effort at fusing instructions was the National Semiconductor Swordfish. The design, led by Don Alpert, began in Israel in the late 1980s and featured dual integer pipelines (A and B) and a multiple-unit floating-point coprocessor. A decoded instruction cache was organized into instruction pair entries. An instruction cache miss started a fetch and pre-decode process, called instruction loading.

This process examined the instructions, precalculated branch target addresses, and checked opcodes and register dependences for dual issue. If dual issue was possible, a special bit in the cache entry was set. Regardless of dual issue, the first instruction in a cache entry was always sent to pipeline A, and the second instruction was supplied to both pipeline B and the floating-point pipeline. Programsequencing instructions could only be executed by pipeline B. Loads could be performed on either pipeline, and thus they could issue on A in parallel with branches or floating-point operations on B. Pipeline B operated in lockstep with the floating-point pipeline; and in cases where a floating-point operation could trap, pipeline B cycled twice in its memory stage so that it and the floating-point pipeline would enter their writeback stages simultaneously. This provided in-order completion and thus made floating-point exceptions precise.

Other designs using instruction fusion include the Transputer T9000, introduced in 1991 and the TI SuperSPARC, introduced in 1992. Within the T9000, up to four instructions could be fetched per cycle, but an instruction grouper could build groups of up to eight instructions that would flow through the five-stage pipeline together [May et aI., 1991]. The SuperSPARC had a similar grouping stage that combined up to three instructions.

Some recent processors use the idea of grouping instructions into larger units as a way to gain efficiency for reservation station slot allocation, reorder buffer allocation, and retirement actions, e.g., the Alpha 21264, AMD Athlon, Intel Pentium 4, and IBM POWER4. However, in these cases the instructions or micro-operations are not truly fused together but are independently executed within the execution engine.



### 8.1.7 Other Efforts in the 19805

There were several efforts at multiple-instruction issue undertaken in the 1980s.
H. C. Torng at Cornell University examined multiple-instruction issue for Cray-like machines and developed an out-of-order multiple-issue mechanism called the dispatch stack [Acosta et aI., 1986]. Introduced in 1986 was the Stellar GS-1000 graphics supercomputer workstation [Sporer et aI., 1988]. The GS-1000 used a fourway multithreaded, 12-stage pipelined processor in which two adjacent instructions in an instruction stream could be packetized and executed in a single cycle.

The Apollo DN 10000 and the Intel i860 were dual-issue processors introduced in the late 1980s, but in each case the compile-time marking of dual issue makes these machines better understood as long-instruction-word architectures rather than as superscalars. In particular, the Apollo design used a bit in the integer instruction format to indicate whether a companion floating-point instruction (immediately following the integer instruction, with the pair being double-word aligned) should be dual-issued. The i860 used a bit in the floating-point instruction format to indicate dual operation mode in which aligned pairs of integer and floating-point instructions would be fetched and executed together. Because of pipelining, the effect of the bit in the i860 governed dual issue of the next pair of instructions.



### 8.1.8 Wide Acceptance of Superscalar

In 1989 Intel announced the first single-chip superscalar, the i960CA, which was a triple-issue implementation of the i960 embedded processor architecture [Hinton, 1989]. Also 1989 saw the announcement of the IBM RS/6000 as the first superscalar workstation; a special session with three RS/6000 papers was presented at the International Conference on Computer Design that October. Appearing in 1990 was the aggressively microcoded Tandom Cyclone, which executed special dual-instructionexecution microprograms whenever possible [Horst et aI., 1990], and Motorola introduced the dual-issue 88110 in 1991. Mainframe manufacturers were also experimenting with superscalar designs; Univac announced the A19 in 1991, and in the following year Liptay [1992] described the IBM ES/9000 Model 520. A flurry of announcements occurred in the early 1990s, including the dual-issue Intel Pentium and the triple-issue PowerPC 601 for personal computers. And 1995 saw the introduction of five major processor cores that, with various tweaks, have powered computer systems for the past several years: HP 8000, Intel P6 (basis for Pentium Pro/II/III) MIPS RI0000, HaL SPARC64, and UltraSPARC-I. Intel recently introduced the Pentium 4 with a redesigned core, and Sun has introduced the redesigned UItraSPARC-III. AMD has been actively involved in mUltiple superscalar designs since the K5 in 1995 through the current Athlon (K7) and Opteron (K8). IBM and Motorola have also introduced multiple designs in the POWER and PowerPC families. However, several system manufacturers, such as Compaq and MIPS (SGI), have trimmed or canceled their superscalar processor design plans in anticipation of adopting processors from the Intelltanium processor family, a new explicitly parallel instruction computing (EPIC) architecture. For example, the Alpha line of processors began with the introduction of the dual-issue 21064 (EV5) in 1992 and continued until the cancellation of the eight-issue 21464 (EV9) design in 2001.

Figure 8.4 presents a time line of the designs, papers, and commercially available processors that have been important in the development of superscalar 1961
techniques. (There are many more superscalar processors available today than can fit in the figure, so your favorite one may not be listed.) 


## 8.2 A Classification of Recent Designs

This section presents a classification of superscalar designs. We distinguish among various techniques and levels of sophistication that were used to provide multiple issue for pipelined ISAs, and we compare superscalar processors developed for the fastest clock cycle times (speed demons) and those developed for high issue rates (brainiacs). Of course, designers pick and choose from among the different design techniques and a given processor may exhibit characteristics from multiple categories.




### 8.2.1  RiSe and else Retrofits
Many manufacturers chose to compete at the level of performance introduced by the IBM RS/6000 in 1989 by retrofitting superscalar techniques onto their 1980s-era RISC architectures, which were typically optimized for a single integer pipeline, or onto legacy complex instruction set computer (CISC) architectures. Six subcategories, or levels of sophistication, of retrofit are evident (these are adapted from Shen and Wolfe [1993]). These levels are design points rather than being strictly chronological developments. For example, in 1996, QED chose to use the first design point for the 200-MHz MIPS R5000 and obtained impressive SPEC95 numbers: 70% of the SPECint95 performance and 85% of the SPECfp95 performance of a contemporary 200-MHz Pentium Pro (a level-6 design style).

1. Floating-point coprocessor style
  * These processors cannot issue multiple integer instructions, or even an integer instruction and a branch in the same cycle; instead, the issue logic allows the dual issue of an integer instruction and a floating-point instruction. This is the easiest extension of a pipelined RISe. Performance is gained on floating-point codes by allowing the integer unit to execute the necessary loads and stores of floating-point values, as well as index register updates and branching.
  * Examples: Hewlett-Packard PA-RISC 7100 and MIPS R5000.
2. Integer with branch
  * This type of processor allows combined issue of integer instructions and branches. Thus performance on integer codes is improved.
  * Examples: Intel i960CA and HyperSPARe.
3. Multiple integer issue
  * These processors include multiple integer units and allow dual issue of multiple integer and/or memory instructions.
  * Examples: Hewlett-Packard PA-RISC 7100LC, Intel i960MM, and Intel Pentium.
4. Dependent integer issue
  * This type of processor uses cascaded or three-input ALUs to allow multiple issue of dependent integer instructions. A related technique is to double-pump the ALU each clock cycle.
  * Examples: SuperSPARC and Motorola 68060.
5. Multiple function units with precise exceptions * This type of processor emphasizes a precise exception model with sophisticated recovery mechanisms and includes a large number of function units with few, if any, issue restrictions. Restricted forms of out-of-order execution using distributed reservation stations are possible (i.e., interunit slip).
  * Example: Motorola 88110.
6. Extensive out-of-order issue
  * This type of processor provides complete out-of-order issue for all instructions. In addition to the normal pipeline stages, there is an identifiable dispatch stage, in which instructions are placed into a centralized reservation station or a set of distributed reservation stations, and an identifiable retirement stage, at which point the instructions are allowed to change the architectural register state and stores are allowed to change the state of the data cache. 
  * Examples: Pentium Pro and HaL SPARC64.


### 8.2.2 Speed Demons: Emphasis on Clock Cycle Time 
High clock rate is the primary goal for a speed demon design. Such designs are characterized by deep pipelines, and designers will typically trade off lower issue rates and longer load-use and branch misprediction penalties for clock rate. Section 2.3 discusses these tradeoffs in more detail.
The initial DEC Alpha implementation, the 21064, illustrates the speed demon approach. The 21064 combined superpipelining and two-way superscalar issue and used seven stages in its integer pipeline, whereas most contemporary designs in 1992 used five or at most six stages. However, the tradeoff is that the 21064 would be classified only at level 1 of the retrofit categories given earlier. This is because only one integer instruction could be issued per cycle and could not be paired with an integer branch.

An alternative view of a speed demon processor is to consider it without the superpipelining exposed, that is, to look at what is accomplished in every two clock cycles. This is again illustrated by the 21064 since its clock rate was typically two or more times the clock rates of other contemporary chips. With this view, the 21064 is a four-way issue design with dependent instructions allowed with only a mild ordering constraint (i.e., the dependent instructions cannot be in the same doubleword); thus it is at level 4 of the retrofit categories.

A high clock rate often dictates a full custom logic design. Bailey gives a brief overview of the clocking, latching, and choices between static and dynamic logic used in the first three Alpha designs [1998]; he claims that full custom design is neither as difficult nor as time-consuming as is generally thought.

Grundmann et al. [1997] also discusses the full-custom philosophy used in the Alpha designs.


### 8.2.3 Brainiacs: Emphasis on IPC

A separate design philosophy, the brainiac approach, is based on getting the most work done per clock cycle. This can involve instruction set design decisions as well as implementation decisions. Designers from this school of thought will trade off large reservation stations, complex dynamic scheduling logic, and lower clock cycle times for higher IPe. Other characteristics of this approach include emphasis on low load-use penalties and special support for dependent instruction execution.

The brainiac approach to architecture and implementation is illustrated by the IBM POWER (performance optimized with enhanced RISC). Enhanced instructions, such as fused multiply-add, load-multiple/store-multiple, string operations, and automatic index register updates for load/stores, were included in order to reduce the number of instructions that needed to be fetched and executed. The instruction cache was specially designed to avoid alignment constraints for full width fetches, and the instruction distribution crossbar and front ends of the execution pipelines were designed to accept as many instructions as possible so that branches could be fetched and handled as quickly as possible. IBM also emphasized time to market and, for many components, used a standard-cell design approach that left the circuit design relatively unoptimized. This was especially true forand POWER2 implementations were 62.5 and 7l.5 MHz, respectively, while the Alpha 21064A and 21264A ran at 300 and 500 MHz, respectively. Smith and Weiss [1994] offer an interesting comparison of the DEC and IBM design philosophies. (See also Section 6.7 and Figure 6.5.) The brainiac approach to implementation can be seen in levels 4 and 6 of the retrofit categories.




## 8.3 Processor Descriptions

This section presents brief descriptions of several superscalar processors. The descriptions are ordered alphabetically according to manufacturer and/or architecture family (e.g. , AMD and Cyrix are described with the Intel IA32 processors).
The descriptions are not intended to be complete but rather to give brief overviews and highlight interesting or unusual design choices. More information on each design can be obtained from the references cited. Microprocessor Reports is also an excellent source of descriptive articles on the microarchitectural features of processors; these descriptions are often derived from manufacturer presentations at the annual Microprocessor Forum. The annual IEEE International Solid-State Circuits Conference typically holds one or more sessions with short papers on the circuit design techniques used in the newest processors.



### 8.3.1 Compaq I DEC Alpha

The DEC Alpha was designed as a 64-bit replacement for the 32-bit VAX architecture. Alpha architects Richard Sites and Rich Witek paid special attention to multiprocessor support, operating system independence, and multiple issue [Sites, 1993]. They explicitly rejected what they saw as scalar RISC implementation artifacts found in contemporary instruction sets, such as delayed branches and singlecopy resources like multiplier-quotient and string registers. They also spumed mode bits, condition codes, and strict memory ordering.

In contrast to most other recent superscalar designs , the Alpha architects chose to allow imprecise arithmetic exceptions and, furthermore , not to provide a mode bit to change to a precise-exception mode. Instead, they defined a trap barrier instruction (TRAPB, and the almost identical EXCB) that will serialize any implementation so that pending exceptions will be forced to occur. Precise floating-point exceptions can then be provided in a naive way by inserting a TRAPB after each floating-point operation. A more efficient approach is to ensure that the compiler's register allocation will not allow instructions to overwrite source registers within a basic block or smaller region (e.g., the code block corresponding to a single high-level language statement); this constraint allows precise exceptions to be provided with one TRAPB per basic block (or smaller region) since the exception handler can then completely determine the correct values for all destination registers.

The Alpha architects also rejected byte and 16-bit word load/store operations, since they require a shift and mask network and a read-modify-writesoftware. However, this turned out to be a design mistake, particularly painful when emulating IA32 programs on the Alpha; and, in 1995, byte and short loads and stores were introduced into the Alpha architecture and then supported on the 21164A.



#### 8.3.1.1  Alpha 21064 (EV4) 11992. 
The 21064 was the first implementation of
the Alpha architecture, and the design team was led by Alpha architect Rich Witek. The instruction fetch/issue unit could fetch two instructions per cycle on an aligned doubleword boundary. These two instructions could be issued together according to some complex rules, which were direct consequences of the allocation of register file ports and instruction issue paths within the design. The decoder was unaggressive; that is, if only the first instruction of the pair could be issued, no other instructions were fetched or examined until the second instruction of the pair had also been issued and removed from the decoder. However, a pipe stage was dedicated to swapping the instruction pair into appropriate issue slots to eliminate some ordering constraints in the issue rules. This simple approach to instruction issue was one of the many tradeoffs made in the design to support the highest clock rate possible. The pipeline is illustrated in Figure 8.5.

The 8K-byte instruction cache contained a I-bit dynamic branch predictor for each instruction (2 bits on the 21064A); however, by appropriately setting a control register, static prediction based on the sign of the displacement could instead be selected. A four-entry subroutine address prediction stack was also included in the 21064, but hint bits had to be explicitly set within the jump instructions to push, pop, or ignore this stack.

The 21064 had three function units: integer, load/store, and floating-point. The integer unit was pipelined in two stages for longer-executing instructions such as shifts; however, adds and subtracts finished in the first stage. The load/store unit interfaced to an 8K-byte data cache and a four-entry write buffer. Each entry was cache-line sized even though the cache was writethrough; this sizing provided for write merging. Load bypass was provided, and up to three outstanding data cache misses were supported.

For more information, see the special issue of Digital Technical Journal [1992], Montanaro [1992], Sites [1993] , and McLellan [1993].


#### 8.3.1.2  Alpha 21164 (EV5) 11995. 
The Alpha 21164 was an aggressive second
implementation of the Alpha architecture. John Edmondson was the lead architect during design, and Jim Keller was lead architect during advanced development.
Pete Bannon was a contributor and also led the design of a follow-on chip, the 21164PC. The 21164 integrated four function units, three separate caches, and an L3 cache controller on chip. The function units were integer unit 0, which also performed integer shift and load and store; integer unit 1, which also performed integer multiply, integer branch, and load (but not store); floating-point unit 0, which performed floating-point add, subtract, compare, and branch and which controlled a floating-point divider; and floating-point unit 1, which performed floating-point multiply.

The designers cranked up the clock speed for the 21164 and also reduced the shift, integer multiply, and floating-point multiply and divide cycle count latencies, as compared to the 21064. However, the simple approach of a fast but unaggressive decoder was retained, with multiple issue having to occur in order from a quadword-aligned instruction quartet; the decoder advanced only after everything in the current quartet had been issued.

The correct instruction mix for a four-issue cycle was two independent integer instructions, a floating-point multiply instruction, and an independent nonmultiply floating-point instruction. However, these four instructions did not have ordering constraints within the quartet, since a slotting stage was included in the pipeline to route instructions from a two-quartet instruction-fetch buffer into the decoder. The two integer instructions could both be loads, and each load could be for either integer or floating-point values. To allow the compiler greater flexibility in branch target alignment and generating a correct instruction mix in each quartet, three flavors of nops were provided: integer unit, floating-point unit, and vanishing nops. Special provision was made for dual issue of a compare or logic instruction and a dependent conditional move or branch. Branches into the middle of a quartet were supported by having a valid bit on each instruction in the decoder. Exceptions on the 21164 were handled in the same manner as in the 21064: issue from the decoder stalled whenever a trap or exception barrier instruction was encountered.

In this second Alpha design, the branch prediction bits were removed from the instruction cache and instead were packaged in a 2048-entry BHT. The return address stack was also increased to 12 entries. A correctly predicted taken branch could result in a one-cycle bubble, but this bubble was often squashed by stalls of previous instructions within the issue stage.

A novel, but now common, approach to pipeline stall control was adopted in the 21164. The control logic checked for stall conditions in the early pipeline stages, but late-developing hazards such as cache miss and write buffer overflow were caught at the point of execution and the offending instruction and its successors were then replayed. This approach eliminated several critical paths in the design, and the handling of a load miss was specially designed so that no additional performance was lost due to the replay.

The on-chip cache memory consisted of an Ll instruction cache (SK bytes), a dual-ported Ll data cache (SK bytes), and a unified L2 cache (96K bytes). The split Ll caches provided the necessary bandwidth to the pipelines, but the size of the Ll data cache was limited because of the dual-port design. The Ll data cache provided two-cycle latency for loads and could accept two loads or one store per cycle; L2 access time was eight cycles. There was a six-entry miss address file (MAF) that sat between the Ll and L2 caches to provide nonblocking access to the Ll cache. The MAF merged nonsequential loads from the same L2 cache line, much the same way as large store buffers can merge stores to the same cache line; up to four destination registers could be remembered per missed address. There was also a two-entry bus address file (BAP) that sat between the L2 cache and the off-chip memory to provide nonblocking access for line-length refills of the L2 cache.

See Edmondson [1994], Edmondson et al. [l995a, b], and Bannon and Keller [1995] for details of the 21164 design. Circuit design is discussed by Benschneider et al. [1995] and Bowhill et aI. [1995]. The Alpha 21164A is described by Gronowski et al. [1996].



#### 8.3.1.3  Alpha 21264 (EV6) I 1997. 
The 21264 was the first out-of-order implementation of the Alpha architecture. However, the in-order parts of the pipeline retain the efficiency of dealing with aligned instruction quartets, and instructions are preslotted into one of two sets of execution pipelines. Thus, it could be said that this design approach marries the efficiency of VLIW-like constraints on instruction alignment and slotting to the flexibility of an out-of-order superscalar.

Jim Keller was the lead architect of the 21264.
A hybrid (or tournament) branch predictor is used in which a two-level adaptive local predictor is paired with a two-level adaptive global predictor. The local predictor contains 1024 ten-bit local history entries that index into a 1024-entry pattern history table, while the global predictor uses a 12-bit global history register that indexes into a separate 4096-entry pattern history table. A 4096-entry choice predictor is driven by the global history register and chooses between the local and global predictors. The instruction fetch is designed to speculate up through 20 branches.

Four instructions can be renamed per cycle, and these are then dispatched to either a 20-entry integer instruction queue or a IS-entry floating-point instruction queue. There are SO physical integer registers (32 architectural, S privileged architecture library (PAL) shadow registers, and 40 renaming registers) and 72 physical floating-point registers (32 architectural and 40 renaming registers). The instruction quartets are retained in a 20-entry reorder buffer/active list, so that up to 80 instructions along with their renaming status can be tracked. A mispredicted branch requires one cycle to recover to the appropriate instruction quartet. Instructions can retire at the rate of two quartets per cycle, but the 21264 is unusual in that it can retire instructions whenever they and all previous instructions are past the point of possible exception and/or misprediction. This can allow retirement of instructions even before the execution results are calculated.

The integer instruction queue can issue up to four instructions per cycle, one to each of four integer function units. Each integer unit can execute add, subtract, and logic instructions. Additionally, one unit can execute branch, shift, and multimedia instructions; one unit can execute branch, shift, and multiply instructions; and the remaining two can each execute loads and stores. The integer register file is implemented as two identical copies so that enough register ports can be provided. Coherency between the two copies is maintained with a one-cycle latency between a write into one file and the corresponding update in the other. Gieseke et al. [1997] estimate that the performance penalty for the split integer clusters is 1%, whereas a unified integer cluster would have required a 22% increase in area, a 47% increase in data path width, and a 75% increase in operand bus length. A unified register file approach would also have limited the clock cycle time.

The floating-point instruction queue can issue up to two instructions per cycle, one to each of two floating-point function units. One floating-point unit can execute add, subtract, divide, and take the square root, while the other floating-point unit is dedicated to multiply. Floating-point add, subtract, and multiply are pipelined and have a four-cycle latency.

The 21264 instruction and data caches are each 64K bytes in size and are organized as two-way pseudo-set-associative. The data cache is cycled twice as fast as the processor clock, so that two loads, or a store and a victim extract, can be executed during each processor clock cycle. A 32-entry load reorder buffer and a 32-entry store reorder buffer are provided.

For more information on the 21264 microarchitecture, see Leibholz and Razdan [1997], Kessler et al. [1998], and Kessler [1999]. For some specifics on the logic design, see Gowan et al. [1998] and Matson et al. [1998].



#### 8.3.1.4  Alpha 21364 (EV7) 12001. 
The Alpha 21364 uses a 21264 (EV 68) core
and adds an on-chip L2 cache, two memory controllers, and a network interface.
The L2 cache is seven-way set-associative and contains 1.75 Mbytes. The cache hierarchy also contains 16 victim buffers for Ll cast-outs, 16 victim buffers for L2 cast-outs, and 16 Ll miss buffers. The memory controllers support directory-based cache coherency and provide RAM bus interfaces. The network interface supports out-of-order transactions and adaptive routing over four links per processor, and it can provide a bandwidth of 6.4 Gbytes/s per link.



#### 8.3.1.5  Alpha 21464 (EV8) 1Canceled. 
The Alpha 21464 was an aggressive
eight-wide superscalar design that included four-way simultaneous multithreading. The design was oriented toward high single-thread throughput, yet the chipresources was minimal (reported to be 6%).
With up to two branch predictions performed each cycle, instruction fetch was designed to return two blocks, possibly noncontiguous, of eight instructions each.
After fetch, the 16 instructions would be collapsed into a group of eight instructions, based on the branch predictions. Each group was then renamed and dispatched into a single 128-entry instruction queue. The queue was implemented with the dispatched instructions assigned age vectors, as opposed to the collapsing FIFO design of the instruction queues in the 21264.

Each cycle up to eight instructions would be issued to a set of 16 function units: eight integer ALUs, four floating-point ALUs, two load pipelines, and two store pipelines. The register file was designed to have 256 architected registers (64 each for the four threads) and an additional 256 registers available for renaming. Eight-way issue required the equivalent of 24 ports, but such a structure would be difficult to implement. Instead, two banks of 512 registers each were used, with each register being eight-ported. This structure required significantly more die area than the 64K-byte L1 data cache. Moreover, the integer execution pipeline, planned as requiring the equivalent of 18 stages, devoted three clock cycles to register file read. Several eight-entry register caches were included within the function units to provide forwarding (compare with the UltraSPARC-III working register file).

The chip design also included a system interconnect router for building a directory-based cache coherent NUMA system with up to 512 processors.
Alpha processor development, including the 21464, was canceled in June 2001 by Compaq in favor of switching to the Intel Itanium processors. Joel Emer gave an overview of the 21464 design in a keynote talk at PACT 2001, and his slides are available on the Internet. See also Preston et al. [2002]. Seznec et al. [2002] describe the branch predictor.



### 8.3.2 Hewlett-Packard PA-RISC Version 1.0

Hewlett-Packard's Precision Architecture (PA) was one of the first RISC architectures; it was designed between 1981 and 1983 by Bill Worley and Michael Mahon, prior to the introduction of MIPS and SPARe. It is a load/store architecture with many RISC-like qualities, and there is also a slight VLIW flavor to its instruction set architecture (ISA). In several cases, multiple operations can be specified in one instruction. Thus, while superscalar processors in the 32-bit PA line (PA-RISC version 1.0) were relatively unaggressive in superscalar instruction issue width, they were all capable of executing multiple operations per cycle. Indeed, the first dual-issue PA processor, the 7100, could issue up to four operations in a given cycle: an integer ALU operation, a condition test on the ALU result to determine if the next instruction would be nullified (i.e., predicated execution), a floating-point add, and an independent floating-point multiply. Moreover, these four operations could be issued while a previous floating-point divide was still in execution and while a cache miss was outstanding.

The 32-bit PA processors prior to the 7300LC were characterized by relatively low numbers of transistors per chip and instead emphasized the use of large off-chip caches. A simple five-stage pipeline was the starting point for each design, but careful attention was given to tailoring the pipelines to run as fast as the external cache SRAMs would allow. While small, specialized on-chip caches were introduced on the 7100LC and the 7200, the 7300LC featured large on-chip caches. The 64-bit, out-of-order 8000 reverted back to reliance on large, off-chip caches. Later versions of the 8xOO series have once again added large, on-chip caches as transistor budgets have allowed. These design choices resulted from the close attention HP system designers have paid to commercial workloads (e.g., transaction processing), which exhibit large working sets and thus poor locality for small on-chip caches.

The implementations listed next follow the HP tradition of team designs. That is, no one or two lead architects are identified. Perhaps more than other companies, HP has attempted to include compiler writers on these teams at an equal level with the hardware designers.



#### 8.3.2.1  PA 7100 11992. 
The 7100 was the first superscalar implementation of the Precision Architecture series. It was a dual-issue design with one integer unit and three independent floating-point units. One integer unit instruction could be issued along with one floating-point unit instruction each cycle. The integer unit handled both integer and floating-point load/stores, while integer multiply was performed by the floating-point multiplier. Special pre-decode bits in the instruction cache were assigned on refill so that instruction issue was simplified. There were no ordering or alignment requirements for dual issue.

Branches on the 7100 were statically predicted based on the sign of the displacement. Precise exceptions were provided for a dual-issue instruction pair by delaying the writeback from the integer unit until the floating-point units had successfully written back.
A load could be issued each cycle, and returned data from a cache hit in two cycles. Special pairing allowed a dependent floating-point store to be issued in the same cycle as the result-producing floating-point operation. Loading to RO provided for software-controlled data prefetching.
See Asprey et al. [1993] and DeLano et al. [1992] for more information on the PA 7100. The 7150 is a 125-MHz implementation of the 7100.


#### 8.3.2.2  PA 7100LCand 7300LC/1994and 1996. 
The PA 7100LC was a lowcost, low-power extension of the 7100 that was oriented toward graphics and multimedia workstation use. It was available as a uniprocessor only, but it provided a second integer unit, a lK-byte on-chip instruction cache, an integrated memory controller, and new instructions for multimedia support. Figure 8.6 illustrates the PA 7100 pipeline.

The integer units on the 7100LC were asymmetric, with only one having shift and bit-field circuitry. Given that there could be only one shift instruction per cycle, then either two integer instructions, or an integer instruction and a load/store, or an integer instruction and a floating-point instruction, or a load/store and a floating-point Clocking

instruction could be issued in the same cycle. There was also a provision that two loads or two stores to the two words of a 64-bit aligned doubleword in memory could also be issued in the same cycle. This is a valuable technique for speeding up subroutine entry and exit.
Branches, and other integer instructions that can nullify the next sequential instruction, could be dual issued only with their predecessor instruction and not with their successor (e.g., a delayed branch cannot be issued with its branch delay slot). Instruction pairs that crossed cache line boundaries could be issued, except when the pair was an integer instruction and a load/store. The register scoreboard on the 7100LC also allowed write-after-write dependences to issue in the same cycle. However, to reduce control logic, the whole pipeline would stall on any operation longer in duration than two cycles; this included integer multiply, double-precision floating-point operations, and floating-point divide.

See Knebel et ai. [1993], Undy et al. [1994], and the April 1995 special issue of the Hewlett-Packard Journal for more information on the PA 7100LC.
The 7300LC is a derivative of the 7100LC with dual 64K-byte on-chip caches [Hollenbeck et aI., 1996; Blanchard and Tobin, 1997; Johnson and Undy, 1997] .



#### 8.3.2.3  PA 7200 11994. 
The PA 7200 added a second integer unit and a 2K-byte on-chip assist cache for data. The instruction issue logic was similar to that of the 7100LC, but the pipeline did not stall on multiple-cycle operations. The 7200 provided multiple sequential prefetches for its instruction cache and also aggressively prefetched data. These data prefetches were internally generated according to the direction and stride of the address-register-update forms of the load/store instructions.

The decoding scheme on the 7200 was similar to that of the National Semiconductor Swordfish. The instruction cache expanded each doubleword with six pre-decode bits, some of which indicated data dependences between the two instructions and some of which were used to steer the instructions to the correct function units. These pre-decode bits were set upon cache refill.

The most interesting design twist to the 7200 was the use of an on-chip, fully associative assist cache of 64 entries, each being a 32-byte data cache line. All data cache misses and prefetches were directed to the assist cache, which had a FIFO replacement into the external data cache. A load/store hint was set in the instruction to indicate spatial locality only (e.g., block copy), so that the replacement of marked lines in the assist cache would bypass the external data cache. Thus cache pollution and unnecessary conflict misses in the direct-mapped external data cache were reduced.

See Kurpanek et al. [1994] and Chan et al. [1996] for more details on the PA 7200.
S.3.3

Hewlett-Packard PA-RISC Version 2.0

Michael Mahon and Jerry Hauck led the Hewlett-Packard efforts to extend Precision Architecture to 64 bits. PA-RIse 2.0 also includes multimedia extensions, called MAX [Lee and Huck, 1996]. The major change for superscalar implementations is the definition of eight floating-point condition bits rather than the original one. PA-RIse 2.0 adds a speculative cache line prefetch instruction that avoids invoking miss actions on a TLB miss, a weakly ordered memory model mode bit in the processor status word (PSW), hints in procedure calls and returns for maintaining a return-address prediction stack, and a fused multiply-add instruction.

PA-RISe 2.0 further defines cache hint bits for loads and stores (e.g., for marking accesses as having spatial locality, as done for the HP PA 7200). PA-RIse 2.0 also uses a unique static branch prediction method: If register numbers are in ascending order in the compare and branch instruction, then the branch is predicted in one way; if they are in descending order, the branch is predicted in the opposite manner. The designers chose this covert manner of passing the static prediction information since there were no spare opcode bits available.

5.3.3.1 HP PA SOOO /1996. The PA SOOO was the first implementation of the 64-bit PA-RIse 2.0 architecture. This core is still used today in the various SxOO chips. As shown in Figure S. 7, the PA SOOO has two 2S-entry combined reservation station/reorder buffers and 10 function units: two integer ALUs, two shift/merge unit, two divide/square root unit, two multiply/accumulate units, and two load/store units. ALU instructions are dispatched into the ALU buffer, while memory instructions are dispatched into the memory buffer as well as a matching 2S-entry address buffer. Some instructions, such as load-and-modify and branch, are dispatched to both buffers.

The combined reservation station/reorder buffers operate in an interesting divide-and-conquer manner [Gaddis and Lotz, 1996]. Instructions in the evennumbered slots in a buffer are issued to one integer ALU or one load/store unit, while instructions in the odd-numbered slots are issued to the other integer ALU or load/store unit. Additionally, arbitration for issue is done by subdividing a buffer's even half and odd half into four banks each (with sizes of 4,4,4, and 2).

Thus there are four groups of four banks each. Within each group, the first ready instruction in the bank that contains the oldest instruction wins the issue arbitration. Thus, one instruction can be issued per group per cycle, leading to a maximum issue rate of two ALU instructions and two memory instructions per cycle.

A large number of comparators is used to check register dependences when instructions are dispatched into the buffers, and an equally large number of comparators is used to match register updates to waiting instructions. Special propagate logic within the reservation station/reorder buffers handles carry-borrow dependences.

Because of the off-chip instruction cache, a taken branch on the 8000 can have a two-cycle penalty. However, a 32-entry, fully associative BTAC was used on the 8000 along with a 256-entry BHT. The BHT maintained a three-bit branch history register in each entry, and a prediction was made by majority vote of the history bits. A hit in the BT AC that leads to a correctly predicted taken branch has no penalty. Alternatively, prediction can be performed statically using a register number ordering scheme within the instruction format (see the introductory PA-RISC 2.0 paragraphs earlier). Static or dynamic prediction is selectable on a page basis. One suggestion made by HP is to profile dynamic library code, set the static prediction bits accordingly, and select static prediction for library pages. This preserves a program's dynamic history in the BHT across library calls.

See Hunt [1995] and Gaddis and Lotz [1996] for further description of the PA 8000.


#### 8.3.3.2  PA8200/1997.
The PA 8200 is a follow-on chip that includes some improvements such as quadrupling the number of entries in the BHT to 1024 and allowing multiple BHT entries to be updated in a single cycle. The TLB entries are also increased from 96 to 120. See the special issue of the Hewlett-Packard Journal [1997] for more information on the PA 8000 and PA 8200.



#### 8.3.3.3  PA 8500 /1998. 
The PA 8500 is a shrink of the PA 8000 core and integrates 0.5 Mbyte of instruction cache and 1 Mbyte of data cache onto the chip. The 8500 changes the branch prediction method to use a 2-bit saturating agree counter in each BHT entry; the counter is decremented when a branch follows the static prediction and incremented when a branch mispredicts. The number of BHT entries is also increased to 2048. See Lesartre and Hunt [1997] for a brief description of the PA 8500.



#### 8.3.3.4  Additional PA 8xOO Processors. 
The PA 8600 was introduced in 2000
and provides for lockstep operation between two chips for fault tolerant designs.
The PA 8700, introduced in 2001, features increased cache sizes: a 1.5-Mbyte data cache and a 0.75-Mbyte instruction cache. See the Hewlett-Packard technical report [2000] for more details of the PA 8700.
Hewlett-Packard plans to introduce the PA 8800 and PA 8900 designs before switching its product line over to processors from the Intel Itanium processor family. The PA 8800 is slated to have dual PA 8700 cores, each with a 0.75-Mbyte data cache and a 0.75-Mbyte instruction cache, on-chip L2 tags, and a 32-Mbyte off-chip DRAM L2 cache.



### 8.3.4 IBM POWER

The design of the POWER architecture was led by Greg Grohoski and Rich Oehler and was based on the ideas of Cocke and Agerwala. Following the Cheetah and America designs, three separate function units were defined, each with its own register set. This approach reduced the design complexity for the initial implementations since instructions for different units do not need complex dependency checking to identify shared registers.

The architecture is oriented toward high-performance double-precision floating point. Each floating-point register is 64 bits wide, and all floating-point operations are done in double precision. Indeed, single-precision loads and stores require extra time in the early implementations because of converting to and from the internal double-precision format. A major factor in performance is the fused multiply-add instruction, a four-operand instruction that multiplies two operands, adds the product to a third, and stores the overall result in the fourth. This is exactly the operation needed for the inner product function found so frequently in inner loops of numerical codes. Brilliant logic design accomplished this operation in a two-pipe-stage design in the initial implementation. However, a side effect is that the addition must be done in greater than double precision, and this is visible in results that are slightly different from those obtained when normal floating-point rounding is performed after each operation.

Support for innermost loops in floating-point codes is seen in the use of the branch-and-count instruction, which can be fully executed in the branch unit, and in the renaming of floating-point registers for load instructions in the first implementation. Renaming the destination registers of floating-point loads is sufficient to allow mUltiple iterations of the innermost loop in floating-point codes to overlap execution, since the load in a subsequent iteration is not delayed by its reuse of an architectural register. Later implementations extend register renaming for all instructions.

Provision of precise arithmetic exceptions is obtained in POWER by the use of a mode bit. One setting serializes floating-point execution, while the other setting provides the faster alternative of imprecise exceptions.
Two major changes/extensions have been made to the POWER architecture.
Apple, IBM, and Motorola joined forces in the early 1990s to define the PowerPC instruction set, which includes a subset of 32-bit instructions as well as 64-bit instructions. Also in the early 1980s, IBM Rochester defined the PowerPC-AS extensions to the 64-bit PowerPC architecture so that PowerPC processors could be used in the AS/400 computer systems.

The POWER family can be divided up into four major groups, with some of the more well-known members shown in the following table. (Note that there are many additional family members within the 32-bit PowerPC group that are not explicitly named, e.g., the 8xx embedded processor series.) 




#### 8.3.4.1  RIOS Pipelines /1989. 
Figure 8.8 depicts the pipelines in the initial
implementation of POWER. These are essentially the same as the ones in the America processor designed by Greg Grohoski. The instruction cache and branch unit could fetch four instructions per cycle, even across cache line boundaries.
During sequential execution these four instructions were placed in an eight-entry sequential instruction buffer. Although a predict-untaken policy was implemented with conditional issue/dispatch of sequential instructions, the branch logic inspected the first five entries of this buffer, and if a branch was found then a speculative fetch of four instructions at the branch target address was started. A special buffer held these target instructions. If the branch was not taken, the target buffer was flushed; however, if the branch was taken, the sequential buffer was flushed, the target instructions were moved to the sequential buffer, any conditionally dispatched sequential instructions were flushed, and the branch unit registers were restored from history registers as necessary. Sequential execution would then begin down the branch-taken path.elf, while two floatingpoint and integer (called fixed-point in the POWER) instructions could be dispatched to buffers. These latter two instructions could be both floating-point, both integer, or one of each. The fused multiply-add counted as one floating-point instruction. Floating-point loads and stores went to both pipelines, while other floating-point instructions were discarded by the integer unit and other integer instructions were discarded by the floating-point unit. If the instruction buffers were empty, then the first instruction of the appropriate type was allowed to issue into the unit. This dual dispatch into buffers obviated instruction pairing/ordering rules. Pre-decode tags were added to instructions on instruction cache refill to identify the required unit and thus speed up instruction dispatch.

The instruction cache and branch unit executed branches and condition code logic operations. There are three architected registers: a link register, which holds return addresses; a count register, which holds loop counts; and a condition register, which has eight separate condition code fields (CRi). CRO is the default condition code for the integer unit, and CR 1 is the default condition code for the floating-point unit. Explicit integer and floating-point compare instructions can specify any of the eight, but condition code updating as an optional side effect of execution occurs only to the default condition code. Multiple condition codes provide for reuse and also allow the compiler to substitute condition code logic operations in place of some conditional jumps in the evaluation of compound conditions. However, Hall and O'Brien [1991] indicated that the XL compilers at that point did not appear to benefit from the multiple condition codes.

The integer unit had four stages: decode, execute, cache access, and writeback.
Rather than a traditional cache bypass for ALU results, the POWER integer unit passed ALU results directly to the writeback stage, which could write two integer results per cycle (this approach came from the 801 pipeline). Floating-point stores performed effective address generation and were then set aside into a store address queue until the floating-point data arrived later. There were four entries in this queue. Floating-point load data were sent to the floating-point writeback stage as well as to the first floating-point execution stage. This latter bypass allowed a floating-point load and a dependent floating-point instruction to be issued in the same cycle; the loaded value arrived for execution without a load penalty.

The floating-point unit accepted up to two instructions per cycle from its predecode buffer. Integer instructions were discarded by the pre-decode stage, and floating-point loads and stores were identified. The second stage in the unit renamed floating-point register references at a rate of two instructions per cycle; new physical registers were assigned as the targets of floating-point load instructions. (Thirtyeight physical registers were provided to map the 32 architected registers.) At this point loads, stores, and ALU operations were separated; instructions for the latter two types were sent to their respective buffers. The store buffer thus allowed loads and ALU operations to bypass. The third pipe stage in the floatingpoint unit decoded one instruction per cycle and would read the necessary operands from the register file . The final three pipe stages were mUltiply, add, and writeback.

For more information on the POWER architecture and implementations, see the January 1990 special issue of IBM Journal of Research and Development, the IBM RISC Systeml6000 Technology book, Hester [1990], Oehler and Blasgen [1991], and Weiss and Smith [1994].


#### 8.3.4.2  RSC/1992.
In 1992 the RSC was announced as a single-chip implementation of the POWER architecture. A restriction to one million transistors meant that the level of parallelism of the RIOS chip set could not be supported. The RSC was therefore designed with three function units (branch, integer, and floatingpoint) and the ability to issue/dispatch two instructions per cycle. An 8K-byte unified cache was included on chip; it was two-way set-associative, write-through, and had a line size of 64 bytes split into four sectors.

Up to four instructions (one sector) could be fetched from the cache in a cycle; these instructions were placed into a seven-entry instruction queue. The first three entries in the instruction queue were decoded each cycle, and either one of the first two instruction entries could be issued to the integer unit and the other dispatched to the floating-point unit. The integer unit was not buffered; it had a three-stage pipeline consisting of decode, execute, and writeback. Cache access could occur in either the execute or the writeback stage to help tolerate contention for access to the single cache. The floating-point unit had a two-entry buffer into which instructions were dispatched; this allowed the dispatch logic to reach subsequent integer and branch instructions more quickly. The floating-point unit did not rename registers.

The instruction prefetch direction after a branch instruction was encountered was predicted according to the sign of the displacement; however, an opcode bit could reverse the direction of this prediction. The branch unit was quite restricted and could independently handle only those branches that were dependent on the counter register and that had a target address in the same page as the branch instruction. All other branches had to be issued to the integer unit. There was no speculative execution beyond an unresolved branch.

Charles Moore was the lead designer for the RSC; see his paper [Moore et aI., 1989] for a description of the RSC.


#### 8.3.4.3  POWER2/1994. 
Greg Grohoski led the effort to extend the four-way POWER by increasing the instruction cache to 32K bytes and adding a second integer unit and a second floating-point unit; the result allowed six-way instruction issue and was called the POWER2. Additional goals were to process two branches per cycle and allow dependent integer instruction issue.

The POWER ISA was extended in POWER2 by the introduction of load/store quadword (128 bits), floating-point to integer conversions, and floating-point square root. The page table entry search and caching rule were also changed to reduce the expected number of cache misses during TLB miss handling.
Instruction fetch in POWER2 was increased to eight instructions per cycle, with cache line crossing permitted; and, the number of entries for the sequential and target instruction buffers was increased to 16 and 8, respectively. In sequential dispatch mode, the instruction cache and branch unit attempted to dispatch six instructionsahead for branches. In target dispatch mode, the instruction cache and branch unit prepared to dispatch up to four integer and floating-point instructions by placing them on the bus to the integer and floating-point units. This latter mode did not conditionally dispatch but did reduce the branch penalty for taken branches by up to two cycles. There were also two independent branch stations that could evaluate branch conditions and generate the necessary target addresses for the next target fetch . The major benefit of using two branch units was to calculate and prefetch the target address of a second branch that follows a resolved-untaken first branch; only the untaken-path instructions beyond one unresolved branch (either first or second) could be conditionally dispatched; a second unresolved branch stopped dispatch.

There were two integer units. Each had its own copy of the integer register file, and the hardware maintained consistency. Each unit could execute simple integer operations, including loads and stores. Cache control and privileged instructions were executed on the first unit, while the second unit executed multiplies and divides. The second unit provided integer multiplies in two cycles and could also execute two dependent add instructions in one cycle.

The integer units also handled load/stores. The data cache, including the directory, was fully dual-ported. In fact, the cache ran three times faster than the normal clock cycle time; each integer unit got a turn, sometimes in reverse order to allow a read to go first, and then the cache refill got a turn.

There were also two floating-point units, each of which could execute fused multiply-add in two cycles. A buffer in front of each floating-point ALU allowed one long-running instruction and one dependent instruction to be assigned to one of the ALUs, while other independent instructions subsequent to the dependent pair could be issued out of order to the second ALU. Each ALU had multiple bypasses to the other; however, only normalized floating-point numbers could be routed along these bypasses. Numbers that were denormalized or special-valued (e.g., not a number (NaN), infinity) had to be handled via the register file .

Arithmetic exceptions were imprecise on the POWER2, so the only preciseinterrupt-generating instructions were load/stores and integer traps. The floating-point unit and the integer unit had to be synchronized whenever an interrupt-generating instruction was issued.
See Barreh et al. [1994], Shippy [1994], Weiss and Smith [1994], and White [1994] for more information on the POWER2. A single-chip POWER2 implementation is called the P2SC.



### 8.3.5  Intel i960
The i960 architecture was announced by Intel in 1988 as a RISC design for the embedded systems market. The basic architecture is integer-only and has 32 registers.
The registers are divided into 16 global registers and 16 local registers, the latter of which are windowed in a nonoverlapping manner on procedure calVreturn. A numerics extension to the architecture provides for single-precision, doubleprecision, and extended-precision floating point; in this case, four 80-bit registers are added to the programming model. The i960 chief architect was Glen Myers.

The comparison operations in the i960 were carefully designed for pipelined implementations:
* A conditional compare instruction is available for use after a standard compare.
The conditional compare does not execute if the first compare is true. This allows range checking to be implemented with only one conditional branch.
* A compare instruction with increment/decrement is provided for fast loop closing.
* A combined compare and branch instruction is provided for cases where an independent instruction cannot be scheduled by the compiler into the delay slot between a normal compare instruction and the subsequent conditional branch instruction.
The opcode name space was also carefully allocated so that the first 3 bits of an instruction easily distinguish between control instructions (C-type), register-to-register integer instructions (R-type), and load/store instructions (M-type). Thus dispatching to different function units can occur quickly, and pre-decode bits are unnecessary.




#### 8.3.5.1  i960 CA 11989. 
The i960 CA was introduced in 1989 and was the first superscalar microprocessor. It is unique among the early superscalar designs in that it is still available as a product today. Chief designers were Glenn Hinton and Frank Smith. The CA model includes on chip: an interrupt controller, a DMA controller, a bus controller, and 1.5K bytes of memory, which can be partially allocated for the register window stack and the remaining part used for low-latency memory. There are three units: instruction-fetchlbranch (instruction sequencer), integer (register side), and address generation (memory side). The integer unit includes a single-cycle integer ALU and a pipelined multiplier/ divider. The address generation unit controls access to memory and also handles accesses to the on-chip memory. The i960 CA pipeline is shown in Figure 8.9.
1. The first instruction in the four slots is issued if possible.

2. If the first instruction is a register-side instruction, that is, if it is neither a memory-side instruction nor a control instruction, then the second instruction is examined. If it is a memory-side instruction, then it is issued if possible.
3. If either one or two instructions have been issued and neither one was a control instruction, then all remaining instructions are examined. The first control instruction that is found is issued.
Thus, after a new instruction quadword has been fetched, there are nine possibilities for issue. (Here x represents an instruction that is not issued.) Notice that in the lower rows of the table the control instruction is executed early, in an out-of-order manner. However, the instruction sequencer retains the current instruction quadword until all instructions have been issued. Thus, while the peak issue rate is three instructions in a given cycle, the maximum sustained issue rate is two per cycle. The instruction ordering constraint in the issue rules has been criticized as irregular and has been avoided by most other designers. However, the M-type load-effective-address (Ida) instruction is general enough so that in many cases a pair of integer instructions can be migrated by an instruction scheduler or peephole optimizer into an equivalent pair of one integer instruction and one Ida instruction. (See also the MM model, described in Section 8.3.5.2, which provides hardware-based instruction migration.) The i960 CA includes a lK-byte, two-way set-associative instruction cache.

The set-associative design allows either one or both banks to be loaded (via a special instruction) with time-critical software routines and locked to prevent instruction cache misses. Moreover, a speculative memory fetch is started for each branch target address in anticipation of an instruction cache miss; this reduces the instruction cache miss penalty. Recovery from exceptions can be handled either by software or by use of an exception barrier instruction.

Please see Hinton [1989] and McGeady [1990a, b] for more details of the i960 CA. U.S. Statutory Invention Registration H1291 also describes the i960 CA.


#### 8.3.5.2  Other Models ofthe i960. 
The i960 MM was introduced for military
applications in 1991 and included both a 2K-byte instruction cache and a 2K-byte data cache on chip [McGeady et aI., 1991]. The decoder automatically rewrote second integer instructions as equivalent Ida instructions where possible. The MM model also included a floating-point unit to implement the numerics extension for the architecture. The CF model was announced in 1992 with a 4K-byte, two-way set-associative instruction cache and a lK-byte, direct-mapped data cache.

The i960 Hx series of models provides a 16K-byte four-way set-associative instruction cache, an 8K-byte four-way set-associative data cache, and 2K-bytes of on-chip RAM.


### 8.3.6  IntellA32-Native Approaches
The Intel IA32 is probably the most widely used architecture to be developed in the 50+ years of electronic computer history. Although its roots trace back to the 8080 8-bit microprocessor designed by Stanley Mazor, Federico Faggin, and Masatoshi Shima in 1973, Intel introduced the 32-bit computing model with the 386 in 1990 (the design was led by John Crawford and Patrick Gelsinger). The follow-on 486 (designed by John Crawford) integrated the FPU on chip and also used extensive pipelining to achieve single-cycle execution for many of the instructions. The next design, the Pentium, was the first superscalar implementation of IA32 brought to market.

Overall, the IA32 design efforts can be classified into whole-instruction (called native) approaches, like the Pentium, and decoupled microarchitecture approaches, like the P6 core and Pentium 4. Processors using the native approach are examined in this section.


#### 8.3.6.1  Intel Pentium 11993. 
Rather than being called the 586, the Pentium
name was selected for trademark purposes. Actually there were a series of Pentium implementations, with different feature sizes, power management techniques, and clock speeds. The last implementation added the MMX multimedia instruction set extension [Peleg and Weiser, 1996; Lempel et aI., 1997]. The Pentium chief architect was Don Alpert, who was assisted by Jack Mills, Bob Dreyer, Ed Grochowski, and Uri Weiser. Weiser led the initial design study in Israel that framed the P5 as a dual-issue processor, and Mills was instrumental in gaining final management approval of dual integer pipelines.

The Pentium was designed around two integer pipelines, U and V, that operated in lockstep manner. (The exception to this lockstep operation was that a paired instruction could stall in the execute stage of V without stalling the instruction in U.) The stages of these pipelines were very similar to the stages of the 486 pipeline. The first decode stage determined the instruction lengths and checked for dual issue. The second decode stage calculated the effective memory address so that the execute stage could access the data cache; this stage differed from its 486 counterpart in its ability to read both an index register and aan immediate in the same cycle. The execute stage performed arithmetic and logical operations in one cycle if all operands were in registers, but it required multiple cycles for more complex instructions. For example, a common type of complex instruction, add register to memory, required three cycles in the execute stage: one to read the memory operand from cache, one to execute the add, and one to store the result back to cache. However, if two instructions of this form (read-modify-write) were paired, there were two additional stall cycles.

Some integer instructions, such as shift, rotate, and add with carry, could only be performed in the U pipeline. Integer multiply was done by the floating-point pipeline, attached to the U pipeline, and stalled the pipelines for 10 cycles. The pipeline is illustrated in Figure 8.10.
Single issue down the U pipeline occurred for (1) complex instructions, including floating-point; (2) when the first instruction of a possible dual-issue pair was a branch; or (3) when the second instruction of a possible pair was dependent on the first (although WAR dependences were not checked and did not limit dual issue). Complex instructions generated a sequence of control words from a microcode sequencer in the 01 stage to control the pipelines for several cycles. There was special handling for pairing a flag-setting instruction with a dependent conditional branch, for pairing two push or two pop instructions in sequence (helpful for procedure entry/exit), and for pairing a floating-point stack register exchange (FXCH) and a floating-point arithmetic instruction.

The data cache on the Pentium was interleaved eight ways on 4-byte boundaries, with true dual porting of the TLB and tags. This allowed the U and V pipelines to access 32-bit doublewords from the data cache in parallel as long as there 
was no bank conflict. The cache did not allocate lines on write misses, and thus dummy reads were sometimes inserted before a set of sequential writes as a compiler or hand-coded optimization.
The floating-point data paths were 80 bits wide, directly supporting extended precision operations, and the delayed exception model of the 486 was changed to predicting exceptions (called safe instruction recognition). The single-issue of floating-point instructions on the Pentium was not as restrictive a constraint as it would be on a RISC architecture, since floating-point instructions on the IA32 are allowed to have a memory operand. The cache design also supported double-precision floating-point loads and stores by using the U and V pipes in parallel to access the upper 32 bits and the lower 32 bits of the 64-bit double-precision value.

Branches were predicted in the fetch stage by use of a 256-entry BTB; each entry held the branch instruction address, target address, and two bits of history.
For more information on the original Pentium, see Alpert and Avnon [1993].
The Pentium MMX design included 57 multimedia instructions, larger caches, and a better branch prediction scheme (derived from the P6). Instruction-length decoding was also done in a separate pipeline stage [Eden and Kagan, 1997].


#### 8.3.6.2  Cyrix 6x86 (M1) 11994. 
Mark Bluhm and Ty Garibay led a design
effort at Cyrix to improve on a Pentium-like dual-pipeline design . Their design, illustrated in Figure 8.11, was called the 6x86, and included register renaming (32 physical registers), forwarding paths across the dual pipelines (called X and Y in the 6x86), decoupled pipeline execution, the ability to swap instructions between the pipelines after the decode stages to support dynamic load balancing and stall avoidance, the ability to dual issue a larger variety of instruction pairs, the use of an eight-entry address stack to support branch prediction of return addresses, and ve stages of the U and V pipelines in the Pentium. The D 1 and D2 stages of the Pentium were split into two stages each in the 6x86: two instruction decode stages and two address calculation stages. Instructions were obtained by using two 16-byte aligned fetches; even in the worst case of instruction placement, this provided at least 9 bytes per cycle for decoding. The first instruction decode stage identified the boundaries for up to two instructions, and the second decode stage identified the operands. The second decode stage of the 6x86 was optimized for processing instruction prefix bytes.

The first address calculation stage renamed the registers and flags and performed address calculation. To allow the address calculation to start as early as possible, it was overlapped with register renaming; thus, the address adder had to access values from a logical register file while the execute stage ALU had to access values from the renamed physical register file. A register scoreboard was used to track any pending updates to the logical registers used in address calculation and enforced address generation interlocks (AGIs). Coherence between the logical and physical copies of a register that was updated during address calculation, such as the stack pointer, was specially handled by the hardware. With this support, two pushes or two pops could be executed simultaneously. The segment registers were not renamed, but a segment register scoreboard was maintained by this stage and stalled dependent instructions until segment register updates were complete.

The second address calculation stage performed address translation and cache access for memory operands (the Pentium did this in the execute stage).
Memory access exceptions were also handled by this stage, so certain instructions for which exceptions cannot be easily predicted had to be singly issued and executed serially from that point in the pipelines. An example of this is the return instruction in which a target address that is popped off the stack leads to a segmentation exception. For instructions with results going to memory, the cache access occurred in the writeback stage (the Pentium wrote memory results in the execute stage).

The 6x86 handled branches in the X pipeline and, as in the Pentium, special instruction pairing was provided for a compare and a dependent conditional jump.
Unlike the Pentium, the 6x86 had the ability to dual issue a predicted-untaken branch in the X pipeline along with its fall-through instruction in the Y pipeline.
The 6x86 also used a checkpoint-repair approach to allow speculative execution past predicted branches and floating-point instructions. Four levels of checkpoint storage were provided.
Memory-accessing instructions were typically routed to the Y pipeline, so that the X pipeline could continue to be used should a cache miss occur. The 6x86 provided special support to the repeat and string move instruction combination in which the resources of both pipelines were used to allow the move instruction to attain a speed of one cycle per iteration. Because of the forwarding paths between the X and Y pipelines (which were not present between the U and V pipelines on the Pentium) and because cache access occurred outside the execute stage, dependent instruction pairs could be dual-issued on the 6x86 when they had the form of a move memory-to-register instruction paired with an arithmetic instruction using that register, or the form of an arithmetic operation writing to a register paired with a move register-to-memory instruction using that register.

Floating-point instructions were handled by the X pipeline and placed into a four-entry floating-point instruction queue. At the point a floating-point instruction was known not to cause a memory-access fault, a checkpoint was made and instruction issue continued. This allowed the floating-point instruction to execute out of order. The 6x86 could also dual issue a floating-point instruction along with an integer instruction. However, in contrast to the Pentium's support of 80-bit extended precision floating point, the data path in the 6x86 floating-point unit was 64 bits wide and not pipelined. Also FXCH instructions could not be dual-issued with other floating-point instructions.

Cyrix chose to use a 256-byte fully associative instruction cache and a 16K-byte unified cache (four-way set-associative). The unified cache was 16-way interleaved (on 16-bit boundaries to provide better support for 16-bit code) and provided dual-ported access similar to the Pentium' s data cache. Load bypass and load forwarding were also supported.

See Burkhardt [1994], Gwennap [1993], and Ryan [1994a] for overviews of the 6x86, which was then called the Ml. McMahan et al. [1995] provide more details of the 6x86. A follow-on design, known as the M2 or 6x86MX, was designed by Doug Beard and Dan Green. It incorporated MMX instruction set extensions as well as increasing the unified cache to 64K bytes.

Cyrix continued to use the dual-pipeline native approach in several subsequent chip designs, and small improvements were made. For example, the Cayenne core allowed FXCH to dual issue in the FPIMMX unit. However, a decoupled design was started by Ty Garibay and Mike Shebanow in the rnid-1990s and came to be called the Jalapeno core (also known as Mojave). Greg Grohoski took over as chief architect of this core in 1997. In 1999, Via bought both Cyrix and Centaur (designers of the WinChip series), and by mid-2000 the Cyrix design efforts were canceled.




### 8.3.7  IntellA32-Decoupled Approaches
Decoupled efforts at building IA32 processors began at least in 1989, when NexGen publicly described its efforts for the F86 (later called the Nx586 and Nx686, and which became the AMD K6 product line). These efforts were influenced by the work of Yale Patt and his students on the high-performance substrate (HPS).

In this section, two outwardly scalar, but internally superscalar efforts are discussed first, and then the superscalar AMD and Intel designs are presented.a scalar processor; however, internally it was a decoupled microarchitecture that operated in a superscalar manner. The Nx586 translated one IA32 instruction per cycle into one or more RISC86 instructions and then dispatched the RISC-like instructions to three function units: integer with multiply/divide, integer, and address generation.

Each function unit on the Nx586 had a 14-entry reservation station, where RISC86 instructions spent at least one cycle for renaming. Each reservation station also operated in a FIFO manner, but out-of-order issue of the RISC86 instructions could occur across function units. The major drawback to this arrangement is that if the first instruction in a reservation station must stall due to a data dependency, the complete reservation station is stalled.

The Nx586 required a separate FPU chip for floating-point, but it included two 16K-byte on-chip caches, dynamic branch prediction using an adaptive branch predictor, speculative execution, and register renaming using 22 physical registers. NexGen worked on this basic design for several years; three preliminary articles were presented at the 1989 Spring COMPCON on what was then called the F86. Later information can be found in Ryan [l994b]. Mack McFarland was the first NexGen architect, then Dave Stiles and Greg Favor worked on the Nx586, and later Korbin Van Dyke oversaw the actual implementation.



#### 8.3.7.2  WinChip Series 11997 to Present. 
Glenn Henry has been working on
an outwardly scalar, internally superscalar approach, similar to the NexGen effort, for the past decade. Although only one IA32 instruction can be decoded per cycle, dual issue of translated micro-operations is possible. One item of interest in the WinChip approach is that a load-ALU-store combination is represented as one micro-operation. See Diefendorff [1998] for a description of the II-pipe-stage WinChip 4. Via is currently shipping the C3, which has a 16-pipe-stage core known as Nehemiah.



#### 8.3.7.3  AMD KS/1995. 
The lead architect of the K5 was Mike Johnson, whose 1989 Stanford Ph.D. dissertation was published as the first superscalar microprocessor design textbook [Johnson, 1991]. The K5 followed many of the design suggestions in his book, which was based on a superscalar AMD 29000 design effort.
In the K5, IA32 instructions were fetched from memory and placed into a 16Kbyte instruction cache with additional pre-decode bits to assist in locating instruction fields and boundaries (see Figure 4.15). On each cycle up to 16 bytes were fetched from the instruction cache, based on the branch prediction scheme detailed in Johnson's book, and merged into a byte queue. According to this scheme, there could only be one branch predicted to be taken per cache line, so the cache lines were limited to 16 bytes to avoid conflicts among taken branches. Each cache line was initially marked as fall-through, and the marking was changed on each misprediction. The effect was about the same as using one history bit per cache line.

As part of filling a line in the instruction cache, each IA32 instruction was tagged with the number of micro-instructions (R-ops) that would be produced.
These tags acted as repetition numbers so that a corresponding number of decoders could be assigned to decode the instructions. In this manner, an IA32 instruction could be routed to one or more two-stage decoders without having to wait for controllogic to propagate instruction alignment information across the decoders. The tradeoff is the increased instruction cache refill time required by the pre-decoding.

There were four decoders in the K5, and each could produce one R-op per cycle.
An interesting aspect of this process is that, depending on the sequential assignment of instruction + tag packets to decoders, the R-ops for one instruction might be split into different decoding cycles. Complex instructions overrode the normal decoding process and caused a stream of four R-ops per cycle to be fetched from a control store.

R-ops were renamed and then dispatched to six execution units: two integer units, two load/store units, a floating-point unit, and a branch unit. Each execution unit had a two-entry reservation station, with the exception that the floating-point reservation station had only one entry. Each reservation station could issue one R-op per cycle. With two entries in the branch reservation station, the K5 could speculatively execute past two unresolved branches.

R-ops completed and wrote their results into a 16-entry reorder buffer; up to four results could be retired per cycle. The reservation stations and reorder buffer entries handled mixed operand sizes (8, 16, and 32 bits) by treating each IA32 register as three separate items (low byte, high byte, and extended bytes). Each item had separate dependency-checking logic and an individual renaming tag.

The K5 had an 8K-byte dual-ported/four-bank data cache. As in most processors, stores were written upon R-op retirement. Unlike other processors, the refill for a load miss was not started until the load R-op became the oldest R-op in the reorder buffer. This choice was made to avoid incorrect accesses to memorymapped 110 device registers. Starting the refills earlier would have required special case logic to handle the device registers.

The K5 was a performance disappointment, allegedly from design decisions made without proper workload information from Windows 3.x applications. An agreement with Compaq in 1995 to supply K5 chips fell through, and AMD bought NexGen (see Section 8.3.7.4). See Gwennap [1994], Halfhill [1994a], and Christie [1996] for more information on the design.



#### 8.3.7.4  AMD K6 (NexGen Nx686) /1996. 
In 1995, AMD acquired NexGen and
announced that the follow-on design to the Nx586 would be marketed as the AMD K6. That design, called the Nx686 and done by Greg Favor, extended the Nx586 design by integrating a floating-point unit as well as a multimedia operation unit onto the chip. The caches were enlarged, and the decode rate was doubled.

The K6 had three types of decoders operating in a mutually exclusive manner.
There was a pair of short decoders that decoded one IA32 instruction each. These could produce one or two RISC86 operations each. There was an alternate long decoder that could handle a single, more complex IA32 instruction and produce up to four RISC86 operations. Finally, there was a vector decoder that provided an initial RISC86 operation group and then began streaming groups of RISC86operations per cycle from one of the three decoder types. Pre-decode bits assisted the K6 decoders, similar to the approach in the K5.

The K6 dispatched RISC86 operations into a 24-entry centralized reservation station, from which up to six RISC86 operations issued per cycle. The eight IA32 registers used in the instructions were renamed using 48 physical registers. Branch support included an 8192-entry BHT implementing adaptive branch prediction according to a global/adaptive/set (GAs) scheme. A 9-bit global branch history shift register and 4 bits from the instruction pointer were used to identify one out of the 8192 saturating 2-bit counters. There was also a 16-entry target instruction cache (16 bytes per line) and a 16-entry return address stack.

The data cache on the K6 ran twice per cycle to give the appearance of dual porting for one load and one store per cycle; this was chosen rather than banking in order to avoid dealing with bank conflicts.
See Halfhill [1996a] for a description of the K6. Shriver and Smith [1998] have written a book-length, in-depth case study of the K6-III.


#### 8.3.7.5  AMD Athlon (K7) 11999. 
Dirk Meyer and Fred Weber were the chief
architects of the K7, later branded as the Athlon. The Athlon uses some of the same approaches as the K5 and K6; however, the most striking differences are in the deeper pipelining, the use of MacroOps, and special handling of floating-point! multimedia instructions as distinct from integer instructions. Stephan Meier led the floating-point part of the design.

The front-end, in-order pipeline for the Athlon consists of six stages (through dispatch). Branch prediction for the front end is handled by a 2048-entry BHT, a 2048-entry BTAC, and a 12-entry return stack. This scheme is simpler than the two-level adaptive scheme used in the K6. Decoding is performed by three DirectPath decoders that can produce one MacroOp each, or, for complex instructions, by a VectorPath decoder that sequences three MacroOps per cycle out of a control store. As in the K5 and K6, pre-decode bits assist in the decoding.

A MacroOp is a representation of an IA32 instruction of up to moderate complexity. A MacroOp is fixed length but can contain one or two Ops. For the integer pipeline, Ops can be of six types: load, store, combined load-store, address generation, ALU, and multiply. Thus, register-to-memory as well as memory-to-register IA32 instructions can be represented by a single MacroOp. For the floating-point pipeline, Ops can be of three types: multiply, add, or miscellaneous. The advantage of using MacroOps is the reduced number of buffer entries needed.

During the dispatch stage, MacroOps are placed in a 72-entry reorder buffer called the instruction control unit (leU). This buffer is organized into 24 lines of three slots each, and the rest of the pipelines follow this three-slot organization. The integer pipelines are organized symmetrically with both an address generation unit and an integer function unit connected to each slot. Integer multiply is the only asymmetric integer instruction; it must be placed in the first slot since the integer multiply unit is attached to the first integer function unit. Floating-point and multimedia (MMXl3DNow! and later SSE) instructions have more restrictive slotting constraints.organized as six lines of three slots each) or the floating-point/multimedia scheduler (36 entries, organized as 12 lines of three slots each). The schedulers can schedule Ops individually and out of order, so that a MacroOp remains in the scheduler buffer until all its Ops are completed.

On the integer side, load and store Ops are sent to a 44-entry load/store queue for processing; the combined load-store Op remains in the load/store queue after the load is complete until the value to store is forwarded across a result bus; at that point it is ready to act as a store Op. The integer side also uses a 24-entry integer future file and register file (IFFRF). Integer operands or tags are read from this unit during dispatch, and integer results are written into this unit and the ICU upon completion. The ICU performs the update of the architected integer registers when the MacroOp retires.

Because of the IA32 floating-point stack model and the width of XMM registers, MacroOps sent to the floating-point/multimedia side are handled in a special manner and require additional pipeline stages. Rather than reading operands or tags at dispatch, floating-point/multimedia register references are later renamed using 88 physical registers. This occurs in three steps: first, in stage 7, stack register references are renamed into a linear map; second, in stage 8, these mapped references are renamed onto the physical registers; then, in stage 9, the renamed MacroOps are stored in the floating-point/multimedia scheduler. Because the operands are not read at dispatch on this side, an extra stage for reading the physical registers is needed. Thus, floating-point/multimedia execution does not start until stage 12 of the Athlon pipeline.

The Athlon has on-chip 64K-byte Ll caches and initially contained a controller for an off-chip L2 of up to 8 Mbytes with MOESI cache coherence. Later shrinks allowed for on-chip L2 caches. The Ll data cache is multibanked and supports two loads or stores per cycle. AMD licensed the Alpha 21264 bus, and the Athlon contains an on-chip bus controller.

See Diefendorff [1998] for a description of the Athlon.
Intel P6 Core (Pentium Pro / Pentium II/ Pentium III) /1996. The Intel P6 is discussed in depth in Chapter 7. The P6 core design team included Bob Colwell as chief architect, Glenn Hinton and Dave Papworth as senior architects, along with Michael Fetterman and Andy Glew. Figure 8.l2 illustrates the P6 pipeline.

The P6 was Intel' s first use of a decoupJed microarchitecture that decomposed IA32 instructions. Intel calls the translated micro-instructions ~ops. An eight-stage fetch and translate pipeline allocates entries for the ~ops in a 40-entry reorder buffer and a 20-entry reservation station . Limitations of the IA32 floating-point stack model are removed by allowing FXCH (exchange) instructions to be inserted directly into the reorder buffer and tagged as complete after they are processed by the renaming hardware. These instructions never occupy reservation station slots.

Because of transistor count limitations on the instruction cache and the problem of branching to what a pre-decoder has marked as an interior byte of an instruction, extra pre-decode bits were rejected. Instead, fetch stages mark the 

### 8.3.7 Instruction

instruction boundaries for decoding. Up to three IA32 instructions can be decoded in parallel; but to obtain this maximum decoding effectiveness, the instructions must be arranged so that only the first one can generate mUltiple !-lops (up to four) while the other two instructions behind it must each generate one !-lop only.

Instructions with operands in memory require multiple !-lops and therefore limit the decoding rate to one IA32 instruction per cycle. Extremely complex IA32 instructions (e.g., PUSHA) require that a long sequence of !-lops be fetched from a control store and dispatched into the processor over several cycles. Prefix bytes and a combination of both an immediate operand and a displacement addressing mode in the same instruction are also quite disruptive to decoding.

The reservation station is scanned in a FIFO-like manner each cycle in an attempt to issue up to four !-lops to five issue ports. Issue ports are a collection of two read ports and one write port to and from the reservation station. One issue port supports wide data paths and has six execution units of various types attached: integer, floating-point add, floating-point multiply, integer divide, floating-point divide, and integer shift. A second issue port handles !-lops for a second integer unit and a branch unit. The third port is dedicated to loads, while the fourth and fifth ports are dedicated to stores. In scanning of the reservation station, preference is given to back-to-back !-lops to increase the amount of operand forwarding among the execution units.

Branch handling uses a two-level adaptive branch predictor, and to assist branching when a branch is not found by a BTB lookup, a decoder shortstop in the middle of the front-end pipeline predicts the branch based on the sign of the displacement. A conditional move has been added to the IA32 ISA to help avoid some conditional branches, and new instructions to move the floating-point condition codes to the integer condition codes have also been added.

The Pentium Pro was introduced at 133 MHz, but the almost immediate availability of the 200-MHz version caught many in the industry by surprise, since its performance on the SPEC integer benchmarks exceeded even that of the contemporary 300-MHz DEC Alpha 21164. In the personal computer marketplace, theperformance (i.e., virtual 8086) to provide the best 32-bit performance possible; thus they chose to serialize the machine on such instructions as far calls and other segment register switches. While small-model 16-bit code runs well, large-model code (e.g., DOS and Windows programs) runs at only Pentium speed or worse.

See Gwennap [1995] and Halfhill [1995] for additional descriptions of the P6.
Papworth [1996] discusses design tradeoffs made in the microarchitecture.



#### 8.3.7.7  Intel Pentium 4/2001. 
The Pentium 4 design, led by Glenn Hinton,
takes the same decoupled approach as in the P6 core, but the Pentium 4 looks even more like Yale Patt's HPS proposal by including a decoded instruction cache. This cache, called the trace cache, is organized to hold 2048 lines of six flOps each in trace order, that is, with branch target flOps placed immediately next to predicttaken branch flOps. The fetch bandwidth of the trace cache is three flOps per cycle.

The Pentium 4 is much more deeply pipelined than the P6 core, resulting in 30 or more pipeline stages. The number and actions of the back-end stages have not yet been disclosed, but the branch misprediction pipeline has been described. It has 20 stages from starting a trace cache access on a mispredicted path to restarting the trace cache on the correct path. The equivalent length in the P6 core is 10 stages.

There are two branch predictors in the Pentium 4, one for the front end of the pipeline and a smaller one for the trace cache itself. The front-end BTB has 4096 entries and reportedly uses a hybrid prediction scheme. If a branch misses in this structure, the front-end pipe stages will predict it based on the sign of the displacement, similar to the P6 shortstop.

Because the trace cache eliminates the need to re-decode recently executed IA32 instructions, the Pentium 4 uses a single decoder in its front end. Thus, compared to the P6 core, the Pentium 4 might take a few more cycles for decoding the first visit to a code segment but will be more efficient on subsequent visits. To maximize the hit rate in the trace cache, the Pentium 4 optimization manual advises against overuse of FXCH instructions (whereas P6 optimization encourages their use; see Section 8.3.7.6). Excessive loop unrolling should be avoided for the same reason.

Another difference between the two Intel designs is that the Pentium 4 does not store source and result values in the reservation stations and reorder buffer.
Instead, it uses 128 physical registers for renaming the architected integer registers and a second set of 128 physical registers for renaming the floating-point stack and XMM registers. A front-end register alias table is used along with a retirement register alias table to keep track of the lookahead and retirement states.

flOps are dispatched into two queues: one for memory operations and one for other operations. There are four issue ports, two of which handle load/stores and two of which handle the other operations. These latter two ports have multiple schedulers examining the flOP queue and arbitrating for issue permission on the two ports. Some of these schedulers can issue one flOP per cycle, but other fast schedulers can issue ALU flOps twice per cycle. This double issue is because the integer ALUs are pipelined to operate in three half-cycles, with two half-cyclethe flags. The overall effect is that the integer ALUs have one-half cycle effective latencies. Because of this staggered structure, dependent !lops can be issued backto-back in half cycles.

The Pentium 4 reorder buffer has 128 entries, and 126 !lops can be in flight.
The processor also has a 48-entry load queue and a 24-entry store queue, so that 72 of the 126 !lops can be load/stores. The Ll data cache provides two-cycle latency for integer values and six-cycle latency for floating-point values. This cache also supports one load and one store per cycle. The schedulers speculatively issue !lops that are dependent on loads so that the loaded values can be immediately forwarded to the dependent !lops. However, if a load has a cache miss, the dependent !lops must be replayed.

See Hinton et al. [2000] for more details of the Pentium 4.


#### 8.3.7.8  Intel Pentium M 12003. 
The Pentium M design was led by Simcha
Gochman and is a low-power revision of the P6 core. The Intel team in Israel started their revision by adding streaming SIMD extensions (SSE2) and the Pentium 4 branch predictor to the basic P6 microarchitecture. They also extended branch prediction in two ways. The first is a loop detector that captures and stores loop counts in a set of hardware counters; this leads to perfect branch prediction of for-loops. The second extension is an adaptive indirect-branch prediction scheme that is designed for data-dependent indirect branches, such as are found in a bytecode interpreter. Mispredicted indirect branches are allocated new table entries in locations corresponding to the current global branch history shift register contents.

Thus, the global history can be used to choose one predictor from among many possible instances of predictors for a data-dependent indirect branch.
The Pentium M team made two other changes to the P6 core. The first is that the IA32 instruction decoders have been redesigned to produce single, fused !lops for load-and-operate and store instructions. In the P6 these instruction types can be decoded only by the complex decoder and result in two !lops each. In the Pentium M they can be handled by any of the three decoders, and each type is now allocated a single reservation station entry and ROB entry. However, the !lop scheduling logic recognizes and treats a fused-!lop entry as two separate !lops, so that the execution pipelines remain virtually the same. The retirement logic also recognizes a fused-!lop entry as requiring two completions before retirement (compare with AMD Athlon MacroOps). A major benefit of this approach is a 10% reduction in the number of !lops handled by the front-end and rear-end pipeline stages and consequent power savings. However, the team also reports a 5% increase in performance for integer code and 9% increase for floating-point code. This is due to the increased decoding bandwidth and to less contention for reservation station and ROB entries.

Another change made in the Pentium M is the addition of register tracking logic for the hardware stack pointer (ESP). The stack pointer updates that are required for push, pop, call, and return are done using dedicated logic and a dedicated adder in the front end, rather than sending a stack pointer adjustment !loppointer are adjusted as needed for load and store !lops that reference the stack, and a history buffer records the speculative stack pointer updates in case of a branch mispredict or exception (compare with the Cyrix 6x86 stack pointer tracking).

See Gochman et al. [2003] for more details.
S.3.S xS6-64
AMD has proposed a 64-bit extension to the x86 (Intel IA32) architecture. Chief architects of this extension were Kevin McGrath and Dave Christie. In the x86-64, compatibility with IA32 is paramount. The existing eight IA32 registers are extended to 64 bits in width, and eight more general registers are added. Also the SSE and SSE2 register set is doubled from 8 to 16 in size. See McGrath [2000] for a presentation of the x86-64 architecture.

S.3.S.1 AMD Opteron (KS) 12003. The first processor supporting the extended architecture is the AMD Opteron. An initial K8 project was led by Jim Keller but was canceled. The Opteron processor brought to market is an adaptation of the Athlon design, and this work was led by Fred Weber.
As compared to the Athlon (see Section 8.3 .7.5), the Opteron retains the same three-slotted pipeline organization. The three regular decoders, now called FastPath, can handle more of the multimedia instructions without having to resort to the VectorPath decoder. The Opteron has two more front-end pipe stages than the Athlon (and fewer pre-decode bits in the instruction cache), so that integer instructions start execution in stage 10 rather than 8, and floating-point/multimedia instructions start in stage 14 rather than 12. Branch prediction is enhanced by enlarging the BHT to 16K entries. The integer scheduler and IFFRF sizes are increased to 24 and 40 entries, respectively, and the number of floating-point/multimedia physical registers is increased to 120.

The Opteron chip also contains three HyperTransport links for multiprocessor interconnection and an on-chip controller that integrates many of the normal Northbridge chip functions.
See Keltcher et al. [2003] for more information on the Opteron.
S.3.9 MIPS
The MIPS architecture is the quintessential RISC. It originated in research work on noninterlocked pipelines by John Hennessy of Stanford University, and the first design by the MIPS company included a noninterlocked load delay slot. The MIPS-I and -II architectures were defined in 1986 and 1990, respectively, by Craig Hansen. Earl Killian was the 64-bit MIPS-III architect in 1991. Peter Hsu started the MIPS-IV extensions at SGI prior to the SGIIMIPS merger; the R8000 and R10000/12000 implement MIPS-IV. MIPS-V was finalized by Earl Killian in 1995, with input from Bill Huffman and Peter Hsu, and includes the MIPS digital media extensions (MDMX).

MIPS is known for clean, fast pipeline design, and the R4000 designers (Peter Davies, Earl Killian, and Tom Riordan) chose to introduce a superpipelined (yeta superscalar approach. Through simulation, the superpipeline design performed better on unrecompiled integer codes than a competing in-house superscalar design. This was because the superscalar required multiple integer units to issue two integer instructions per cycle but lacked the ability to issue dependent integer instruction pairs in the same cycle. In contrast, the superpipelined design ran the clock twice as fast and, by use of a single fast-cycle ALU, could issue the dependent integer instruction pair in only two of the fast cycles [Mirapuri et aI., 1992]. It is interesting to compare this approach with the issue of dependent instructions using cascaded ALUs in the SuperSPARC, also a 1992 design. Also, the fast ALU idea is helpful to the Pentium 4 design.



#### 8.3.9.1  MIPS R8000 (TFP) 11994. 
The MIPS R8000 was superscalar but not
superpipelined; this might seem an anomaly, and indeed, the R8000 was actually the final name for the tremendous floating-point (TFP) design that was started at Silicon Graphics by Peter Hsu. The R8000 was a 64-bit machine aimed at floatingpoint computation and seems in some ways a reaction to the IBM POWER. However, many of the main ideas in the R8000's design were inspired by the Cydrome Cydra-5. Peter Hsu was an alumnus of Cydrome, as were some of his design team:

Ross Towle, John Brennan, and Jim Dehnert. Hsu also hired Paul Rodman and John Ruttenberg, who were formerly with Multiflow.
The R8000 is unique in separating floating-point data from integer data and addresses. The latter could be loaded into the on-chip 16K-byte cache, but floatingpoint data could not. This decision was made in an effort to prevent the poor temporal locality of floating-point data in many programs from rendering the on-chip cache ineffective. Instead the R8000 provided floating-point memory bandwidth using a large second-level cache that is two-way interleaved and has a five-stage access pipeline (two stages of which were included for chip crossings).

Bank conflict was reduced by the help of a one-entry address bellow; this provided for reordering of cache accesses to increase the frequency of pairing odd and even bank requests.
A coherency problem could exist between the external cache and the on-chip cache when floating-point and integer data were mixed in the same structure or assigned to the same field (i.e., a union data structure). The on-chip cache prevented this by maintaining one valid bit per word (the MIPS architecture requires aligned accesses). Cache refill would set the valid bits, while integer and floatingpoint stores would set and reset the appropriate bits, respectively.

The R8000 issued up to four instructions per cycle to eight execution units:
four integer, two floating-point, and two load/store. The integer pipelines inserted an empty stage after decode so that the ALU operation was in the same relative position as the cache access in the load/store pipelines. Thus there were no load/ use delays, but address arithmetic stalled for one cycle when it depended on a loaded value.

A floating-point queue buffered floating-point instructions until they were ready to issue. This allowed the integer pipelines to proceed even when adependent floating-point instruction. Imprecise exceptions were thus the rule for floating-point arithmetic, but there was a floating-point serialization mode bit to help in debugging, as in the IBM POWER.

A combined branch prediction and instruction alignment scheme similar to the one in the AMD K5 was used. There was a single branch prediction bit for each block of four instructions in the cache. A source bit mask in the prediction entry indicated how many valid instructions existed in the branch block, and another bit mask indicated where the branch target instruction started in the target block.

Compiler support to eliminate the problem of two likely-taken branches being placed in the same block was helpful.
Hsu [1993, 1994] presents the RSOOO in greater detail.



#### 8.3.9.2  MIPS R10000 (15) 11996. 
Whereas the RSOOO was a multichip implementation, the RlOOOO (previously code-named the T5, and designed by Chris Rowen and Ken Yeager) is a single-chip implementation with a peak issue rate of five instructions per cycle. The sustained rate is limited to four per cycle. Figure S.13 illustrates the MIPS RlOOOO pipeline.

Instructions on the RlOOOO are stored in a 32K-byte instruction cache with pre-decode bits and are fetched up to four per cycle from anywhere in a cache line.
Decoding can run at a rate of four per cycle, and there is an eight-entry instruction buffer between the instruction cache and the decoder that allows fetch to continue even when decoding is stalled.
The decoder also renames registers. While the MIPS ISA defines 33 integer registers (31 plus two special registers for multiply and divide) and 31 floatingpoint registers, the RlOOOO has 64 physical registers for integers and 64 physical registers for floating-point. The current register mapping between logical registers and physical registers is maintained in two mapping tables, one for integer and one for floating-point.

Instructions are dispatched from the decoder into one of three instruction queues: integer, load/store, and floating-point. These queues serve the role of reservation stations, but they do not contain operand values, only physical register numbers. Operands are instead read from the physical register files during instruction issue out of a queue.

Each queue has 16 entries and supports out-of-order issue. Up to five instructions can be issued per cycle: two integer instructions can be issued to the two integer units, one of which can execute branches while the other contains integer multiply/divide circuitry; one load/store instruction can be issued to its unit; and one floating-point add instruction and one floating-point multiply instruction can be issued in parallel.

The implementation of the combined floating-point multiply-add instruction is unique in that an instruction of this type must first traverse the first two execution stages of the multiply pipeline and is then routed into the add pipeline, where it finishes normalization and writeback. Results from other floating-point operations can also be forwarded after two execution stages.

The processor keeps track of physical register assignments in a 32-entry active list of decoded instructions. The list is maintained in program order. An entry in this list is allocated for each instruction upon dispatch, and a done flag in each entry is initialized to zero. The indices of the active list entries are also used to tag the dispatched instructions as they are placed in the instruction queues. At completion, each instruction writes its result into its assigned physical register and sets its done flag to 1. In this manner the active list serves as a reorder buffer and supports in-order retirement (called graduation).

Entries in the active list contain the logical register number named as a destination in an instruction as well as the physical register previously assigned. This arrangement provides a type of history buffer for exception handling. Upon detecting an exception, instruction dispatching ceases; current instructions are allowed to complete; and then, the active list is traversed in reverse order, four instructions per cycle, unmapping physical registers by restoring the previous assignments to the mapping table. To provide precise exceptions, this process continues until the excepting instruction is unmapped. At that point, an exception handler can be called.

To make branch misprediction recovery faster, a checkpoint-repair scheme is used to make a copy of the register mapping tables and preserve the alternate path address at each branch. Up to four checkpoints can exist at one time, so the RlOOOO can speculatively execute past four branches. Recovery requires only one cycle to repair the mapping tables to the point of the branch and then restart instruction fetch at the correct address. Speculative instructions on the mispredicted path are flushed from the processor by use of a 4-bit branch mask added to each decoded instruction. The mask indicates if an instruction is speculative and on which of the four predicted branches it depends (multiple bits can be set). As branches are resolved, a correct prediction causes each instruction in the processor to reset the corresponding branch mask bit. Conversely, a misprediction causes each instruction with the corresponding bit set to be flushed.

Integer multiply and divide instructions have multiple destination registers (HI, LO) and thus disrupt normal instruction flow. The decoder in the RlOOOO stalls after encountering one of these instructions; also, the decoder will not dispatch a multiply or divide as the fourth instruction in a decode group. The reason for this is that special handling is required for the multiple destinations: two entries must be allocated in the active list for each multiply or divide.

Conditional branches are supported on the RlOOOO by a special condition file, in which the one bit per physical register is set to I whenever a result equal to zero is written into the physical register file. A conditional branch that compares against zero can immediately determine taken or not taken by checking the appropriate bit in the condition file, rather than read the value from the physical register file and check if it is zero. A 512-entry BHT is maintained for branch prediction, but there is no caching of branch target addresses. This results in a one-cycle penalty for correctly predicted taken branches.

Another interesting branch support feature of the RlOOOO is a branch link quadword, which holds up to four instructions past the most recent subroutine call.
This acts as a return target instruction cache and supports fast returns from leaf subroutines. During initial design in 1994, a similar cache structure was proposed for holding up to four instructions on the fall-through path for the four most recent predicted-taken branches. Upon detecting a misprediction this branch-resume cache would allow immediate restart, and RlOOOO descriptions from 1994 and 1995 describe it as a unique feature. However, at best this mechanism only saves a single cycle over the simpler method of fetching the fall-through path instructions from the instruction cache, and it was left out of the actual RlOOOO chip.

To support strong memory consistency, the load/store instruction queue is maintained in program order. Two 16-by-16 matrices for address matching are used to determine load forwarding and also so that cache set conflicts can be detected and avoided.
See Halfhill [1994b] for an overview of the RlOOOO. Yeager [1996] presents an in-depth description of the design, including details of the instruction queues and the active list. Vasseghi et al. [1996] presents circuit design details of the RlOOOO.
The follow-on design, the R12000, increases the active list to 48 entries and the BHT to 2048 entries, and it adds a 32-entry two-way set-associative branch target cache. The recent R14000 and R16000 are similar to the R12000.
MIPS RSOOO and QED RM7000 /1996 and 1997. The R5000 was designed by QED, a company started by Earl Killian and Tom Riordan, who also designed some of the R4xOOO family members. The R5000 organization is very 


#### 8.3.9.3  (a level-l design); however, the performance is as impressive as that of competing designs with extensive out-of-order capabilities.  Riordan also extended this
approach in the RM7000, which retains the R5000's dual-issue structure but integrates on one chip a 16K-byte four-way set-associative Ll instruction cache, a 16K-byte four-way set-associative Ll data cache, and a 256K-byte four-way setassociative L2 unified cache.


### 8.3.1  Motorola
Two Motorola designs have been superscalar, apart from processors in the PowerPC family.


### 8.3.1  Motorola 881101 1991. 
The 88110 was a very aggressive design for its time (1991) and was introduced shortly after the IBM RS/6000 started gaining popularity. The 88110 was a dual-issue implementation of the Motorola 88K RISC architecture and extended the 88K architecture by introducing a separate extended-precision (80-bit) floating-point register file and by adding graphics instructions and nondelayed branches. The 88110 was notable for its 10 function units (see Figure 4.7) and its use of a history buffer to provide for precise exceptions and recovery from branch mispredictions. Keith Diefendorff was the chief architect; Willie Anderson designed the graphics and floating-point extensions; and Bill Moyer designed the memory system.

The 10 function units were the instruction-fetchlbranch unit, load/store unit, bitfield unit, floating-point add unit, multiply unit, divide unit, two integer units, and two graphics units. Floating-point operations were performed using 80-bit extended precision. The integer and floating-point register files each had two dedicated history buffer ports to record the old values of two result registers per cycle. The history buffer provided 12 entries and could restore up to two registers per cycle.

On each cycle two instructions were fetched, unless the instruction pair crossed a cache line. The decoder was aggressive and tried to dual issue in each cycle. There was a one-entry reservation station for branches and a three-entry reservation station for stores; thus the processor performed in-order issue except for branches and stores. Instructions speculatively issued past a predicted branch were tagged as conditional and flushed if the branch was mispredicted; and any registers already written by mispredicted conditional instructions were restored using the history buffer. Conditional stores, however, were not allowed to update the data cache but remained in the reservation station until the branch was resolved.

Branches were statically predicted. A target instruction cache returned the pair of instructions at the branch's target address for the 32 most recently taken branches. The TIC was virtually addressed, and it had to be flushed on each context switch.
There was no register renaming, but instruction pairs with write-after-read dependences were allowed to dual issue, and dependent stores were allowed to dual issue with the result-producing instruction. The load/store unit had a four-entry load buffer and allowed loads to bypass stores.
There were two 80-bit writeback busses shared among the 10 function units.
Because of the different latencies among the function units, instructions arbitrated for the busses. The arbitration priority was unusual in that it gave priority to lower-cycle-count operations and could thus further delay long-latency operations. This was apparently done in response to a customer demand for this type of priority.

Apple, Next, Data General, Encore, and Harris designed machines for the 88110 (with the latter three delivering 8811O-based systems). However, Motorola had difficulty in manufacturing fully functional chips and canceled revisions and follow-on designs in favor of supporting the PowerPC. However, several of the cache, TLB, and bus design techniques for the 88110 were used in the IBM/ Motorola PowerPC processors and in the Motorola 68060.

See Diefendorff and Allen [1992a,b] and Ullah and Holle [1993] for articles on the 88110.



### 8.3.1  68060 /1993. 
The 68060 was the first superscalar implementation in the 68000 CISC architecture family to make it to market. Even though many of the earliest workstations used the 680xO processors and Apple chose them for the Macintosh, the 680xO family has been displaced by the more numerous IA32 and RISC designs. Indeed, Motorola had chosen in 1991 to target the PowerPC for the workstation market, and thus the 68060 was designed as a low-cost, low-power entrant in the embedded systems market. The architect was Joe Circello. The 68060 pipeline is illustrated in Figure 8.14.

The 68060 implementation has a decoupled microarchitecture that translates a variable-length 68000 instruction into a fixed-length format that completely identifies the resources required. The translated instructions are stored in a 16-entry FIFO buffer. Each entry has room for a 16-bit opcode, 32-bit extension words, and early decode information. Some of the complex instructions require more than one entry in the buffer. Moreover, some of the most complex 68040 instruction types Integer
The 68060 contains a 256-entry branch cache with 2-bit predictors. The branch cache also uses branch folding, in which the branch condition and an address recovery increment are stored along with the target address in each branch cache entry.
Each entry is tagged with the address of the instruction prior to the branch and thus allows the branch to be eliminated from the instruction stream sent to the FIFO buffer whenever the condition code bits satisfy the branch condition.
The issue logic attempts to in-order issue two instructions per cycle from the FIFO buffer to two four-stage operand-execution pipelines. The primary operandexecution pipeline can execute all instructions, including the initiation of floatingpoint instructions in a separate execution unit. The secondary operand-execution pipeline executes only integer instructions.

These dual pipelines must be operated in a lockstep manner, similar to the Pentium, but the design and the control logic are much more sophisticated. Each operand execution pipeline is composed of two pairs of fetch and execute stages; Motorola literature describes this as two RISC engines placed back to back. This is required for instructions with memory operands: the first pair fetches address components and uses an ALU to calculate the effective address (and starts the cache read), and the second pair fetches register operands and uses an ALU to calculate the operation result. Taking this further, by generalizing the effective address ALU, some operations can be executed by the first two stages in the primary pipeline and then have their results forwarded to the second pipeline in a cascaded manner. While some instructions are always executed in the first two stages, others are dynamically allocated according to the issue pair dependency; thus many times pairs of dependent instructions can be issued in the same cycle. Register renaming is also used to remove false dependences between issue pairs.

The data cache is four-way interleaved and allows one load and one nonconflicting store to execute simultaneously. See Circello and Goodrich [1993], Circello [1994], and Circello et a1. [1995] for more detailed descriptions of the 68060.



### 8.3.1  PowerPC-32-bit Architecture
The PowerPC architecture is the result of cooperation begun in 1991 between IBM, Motorola, and Apple. IBM and Motorola set up the joint Somerset Design Center in Austin, Texas, and the POWER ISA and the 88110 bus interface were adopted as starting points for the joint effort. Single-precision floating-point, revised integer multiply and divide, load word and reserve and store word conditional, and support for both little-endian as well as big-endian were added to the ISA, along with the definition of a weakly ordered memory model and an I/O barrier instruction (the humorously named "eieio" instruction). Features removed include record locking, the multiplier-quotient (MQ) register and its associated instructions, and several bit-field and string instructions. Cache control instructions were also changed to provide greater flexibility. The lead architects were Rich Oehler (IBM), Keith Diefendorff (Motorola), Ron Hochsprung (Apple), and John Sell (Apple).contain more information about the history of the PowerPC cooperation and the changes from POWER.



### 8.3.1  PowerPC 601 11993. 
The 601 was the first implementation of the PowerPC architecture and was designed by Charles Moore and John Muhich. An important design goal was time to market, so Moore's previous RSC design was used as a starting point. The bus and cache coherency schemes of the Motorola 88110 were also used to leverage Apple's previous 8811O-based system designs.

Compared to the RSC, the 601 unified cache was enlarged to 32K bytes and the TLB structure followed the 88110 approach of mapping pages and larger blocks.
Each cycle, the bottom four entries of an eight-entry instruction queue were decoded. Floating-point instructions and branches could be dispatched from any of the four entries, but integer instructions had to be issued from the bottom entry. A unique tagging scheme linked the instructions that were issued/dispatched in a given cycle into an instruction packet. The progress of this packet was monitored through the integer instruction that served as the anchor of the packet. If an integer instruction was not available to be issued in a given cycle, a nop was generated so that it could serve as the anchor for the packet. All instructions in a packet completed at the same time.

Following the RSC design, the 601 had a two-entry floating-point instruction queue into which instructions were dispatched, and it did not rename floatingpoint registers. The RSC floating-point pipeline stage design for multiply and add was reused. The integer unit also handled loads and stores, but there was a more sophisticated memory system than that in the RSC. Between the processor and the cache, the 601 added a two-entry load queue and a three-entry store queue.

Between the cache and memory a five-entry memory queue was added to make the cache nonblocking. Branch instructions were predicted in the same manner as in the RSC, and conditional dispatch but not execution could occur past unresolved branches.
The designers added many multiprocessor capabilities to the 601. For example, the data cache implemented the MESI protocol, and the tags were double-pumped each cycle to allow for snooping. The writeback queue entries were also snooped so that refills could have priority without causing coherency problems.

See Becker et al. [1993], Diefendorff [1993], Moore [1993], Potter et al. [1994], and Weiss and Smith [1994] for more information on the 601.


### 8.3.1  PowerPC 603/1994. 
The 603 is a low-power implementation of the PowerPC that was designed by Brad Burgess, Russ Reininger, and Jim Kahle for small, single-processor systems, such as laptops. The 603 has separate 8K-byte instruction and data caches and five independent execution units: branch, integer, system, load/store, and floating-point. The system unit executes the condition code logic operations and instructions that move data to and from special system registers.

Two instructions are fetched each cycle from the instruction cache and sent to both the branch unit and a six-entry instruction queue. The branch unit can delete branches in the instruction queue when they do not change branch unit registers; otherwise, branches pass through the system unit. A decoder looks at the bottom two entries in the instruction queue and issues/dispatches up to two instructions per cycle. Dispatch includes reading register operands and assigning a rename register to destination registers. There are five integer rename registers and four floating-point rename registers.

There is a reservation station for each execution unit so that dispatch can occur even with data dependences. Dispatch also requires that an entry for each issued/dispatched instruction be allocated in the five-entry completion buffer.
Instructions are retired from the completion buffer at a rate of two per cycle; retirement includes the updating of the register files by transferring the contents of the assigned rename registers. Because all instructions that change registers retire from the completion buffer in program order, all exceptions are precise.

Default branch prediction is based on the sign of the displacement, but a bit in the branch opcode can be used by the compilers to reverse the prediction. Speculative execution past one conditional branch is provided, with the speculative path able to follow an unconditional branch or a branch-on-count while conditional branches wait to be resolved. Branch misprediction is handled by flushing the predicted instructions and the completion buffer contents subsequent to the branch.

The load/store unit performs multiple accesses for unaligned operands and sequences multiple accesses for the load-multiple/store-multiple and string instructions. Loads are pipelined with a two-cycle latency; stores are not pipelined.
Denormal floating-point numbers are supported by a special internal format, or a flush-to-zero mode can be enabled.
There are four power management modes: nap, doze, sleep, and dynamic. The dynamic mode allows idle execution units to reduce power consumption without impacting performance.
See Burgess et al. [1994a, 1994b] and the special issue of the Communications of the ACM on "The Making of the PowerPC" for more information. An excellent article describing the simulation studies of design tradeoffs for the 603 can be found in Poursepanj et al. [1994].
The 603e, done by Brad Burgess and Robert Golla, is a later implementation that doubles the sizes of the on-chip caches and provides the system unit with the ability to execute integer adds and compares. (Thus the 603e could be described as having a limited second integer unit.)



### 8.3.1  PowerPC 604/1994. 
The 604 looks much like the standard processor design of Mike Johnson's textbook on superscalar design. As shown in Figure 8.15, there are six function units, each having a two-entry reservation station, and a 16-entry reorder buffer (completion buffer). Up to four instructions can be fetched per cycle into a four-entry decode buffer. These instructions are next placed into a four-entry dispatch buffer, which reads operands and performs register renaming.

From this buffer, up to four instructions are dispatched per cycle to the six function units: a branch unit, two integer units, an integer multiply unit, a load/store unit, and a floating-point unit. Each of the integer units can issue an instruction [nteger units (X 3)

from either reservation station entry (i.e., out of order), whereas the reservation stations assigned to other units issue in order for the given instruction type but, of course, provide for interunit slip. There are two levels of speculative execution supported. The reorder buffer can retire up to four instructions per cycle.

Renaming is provided by a l2-entry rename buffer for integer registers, an eight-entry rename buffer for floating-point registers, and an eight-entry rename buffer for condition codes. Speculative execution is not allowed for stores, and the 604 also disallows speculative execution for logical operations on condition registers and integer arithmetic operations that use the carry bit.

Branch prediction on the 604 is supported by a 5l2-entry BHT, each entry having a 2-bit predictor, and a 64-entry fully associative BT AC. The decode stage recognizes and handles prediction for unconditional branches and branches that hit in the BHT but not in the BTAC. There is also special branch prediction for branches on the count register, which typically implement innermost loops. The dispatch logic stops collecting instructions for multiple dispatch when it encounters a branch, so only one branch per cycle is processed.

Peter Song was the chief architect of the 604. See Denman [1994] and Song et al. [1994] for more information on the 604. Denman et al. [1996] discuss a follow-on chip, the 604e, which is a lower-power, pin-compatible version. The 604e doubles the cache sizes and provides separate execution units for condition register operations and branches. Each of these two units has a two-entry reservation station, but dispatch is limited to one per cycle.Burgess. The 750 is designed as a low-power chip with four pipeline stages, and it has less buffering than the 604. Burgess characterizes the design as "modest issue width, short pipeline, large caches, and an aggressive branch unit focused on resolving branches rather than predicting them." The 750 has six function units:

two integer units, a system register unit, a load/store unit, a floating-point unit, and the branch unit. Unlike the 604, function units other than the branch unit and the load/store unit have only one entry each in their reservation stations.
Instructions are pre-decoded into a 36-bit format prior to storing in the Ll instruction cache. Four instructions can be fetched per cycle, and up to two instructions can be dispatched per cycle from the two bottom entries of a six-entry instruction buffer. Branches are processed as soon as they are recognized, and when predicted taken, they are deleted (folded out) from the instruction buffer and overlaid with instructions from the branch target path. Speculative execution is provided past one unresolved branch, and speculative fetching continues past two unresolved branches. An interesting approach to save space in the six-entry completion buffer is the "squashing" of nops and untaken branches from the instruction buffer prior to dispatch. These two types of instructions will not be allocated completion buffer entries, but an unresolved, predicted-untaken branch will be held in the branch unit until resolution so that any misprediction recovery can be performed.

The 750 includes a 64-entry four-way set-associative BTIC and a 512-entry BHT. The chip also includes a two-way set-associative level-two cache controller and the level-two tags; this supports 256K bytes, 5I2K bytes, or I Mbyte of off-chip SRAM. (The 740 version of the chip does not contain the L2 tags and controller.) See Kennedy et al. [1997] for more details on the 750.



### 8.3.1  PowerPC 7400 (G4) and 74S0 (G4+) 11999 and 2001. 
The 7400, a design led by Mike Snyder, is essentially the 750 with AltiVec added. A major redesign in the 74xx series occurred in 2001 with the seven-stage 7450. In this design, led by Brad Burgess, the issue and retire rates have been increased to three per cycle, and 10 function units are provided. The completion queue has been enlarged to 16 entries, and branch prediction has also been improved by quadrupling the BHT to 2048 entries and doubling the BTIC to 128 entries. A 256K-byte L2 cache is integrated onto the 7450 chip. See Diefendorff [1999] for a description of the 7450.



### 8.3.1  PowerPC eSOO Core 12001. 
The e500 core implements the 32-bit embedded processor "Book E" instruction set. The e500 also implements the signal processing engine (SPE) extensions, which provide two-element vector operands, and the integer select extension, which provides for partial predication.

The e500 core is a two-way issue, seven-stage-pipeline design similar in some ways to the 7450. Branch prediction in the e500 core is provided by a single structure, a 512-entry BTB. Two instructions can be dispatched from the 12-entry instruction queue per cycle; and, both of these instructions can be moved into the four-entry general instruction queue, or one can be moved there and the other can be moved into the two-entry branch instruction queue. A single reservation station is placed between the branch instruction queue and the branch unit, and a similar arrangement occurs for each of the other functional units, which are fed instead by the general instruction queue. These units include two simple integer units, a multiplecycle integer unit, and a load/store unit. The SPE instructions execute in the simple and multiple-cycle integer units along with the rest of the instructions. The completion queue has 14 entries and can retire up to two instructions per cycle.




### 8.3.1  PowerPC-64-bit Architecture
When the PowerPC architecture was defined in the early 1990s, a 64-bit mode of operation was also defined along with an 80-bit virtual address. See Peng et al.
[1995] for a detailed description of the 64-bit PowerPC architecture.


### 8.3.1  PowerPC 620 11995. 
The 620 was the first 64-bit implementation of the PowerPC architecture and is detailed in Chapter 6. Its designers included Don Waldecker, Chin Ching Kau, and Dave Levitan. The four-way issue organization was similar to that of the 604 and used the same mix of function units. However, the 620 was more aggressive than the 604 in several ways. For example, the decode stage was removed from the instruction pipeline and instead replaced by pre-decoding during instruction cache refills (see Figure 6.2). The load/store unit reservation station was increased from two entries to three entries with out-of-order issue, and the branch unit reservation station was increased from two entries to four entries. To assist in speculating through the four branches, the 620 doubled the number of condition register fields rename buffers (to 16), and quadrupled the number of entries in the BTAC and the BHT (to 256 and 2048, respectively). Some implementation simplifications were (1) integer instructions that require two source registers could only be dispatched from the bottom two slots of the eight-entry instruction queue, (2) integer rename registers were cut from 12 in the 604 to 8 in the 620, and (3) reorder buffer entries were allocated and released in pairs.

The 620 implementation reportedly had bugs that initially restricted multiprocessor operation, and very few systems shipped with 620 chips. For more information on the design of the 620, see Thompson and Ryan [1994] and Levitan et al. [1995] .


### 8.3.1  POWER3 (630) 11998. 
Chapter 6 notes that the single floating-point unit in the 620 and the inability to issue more than one load plus one store per cycle are major bottlenecks in that design. These problems were addressed in the follow-on design, called at first the 630 but later known as the POWER3. Starting with the 620 core, the POWER3 doubled the number of floating-point and load/ store units to two each. The data cache supported up to two loads, one store, and one refill each cycle; it also had four miss handling registers rather than the single register found in the 620. (See Table 6.11.)

Each of the eight function units in POWER3 could be issued an instruction each cycle (versus an issue limit of four in the 620). While branch and load/storeother five units could be issued instructions out of order. The completion buffer was doubled to 32 entries, and the number of rename registers was doubled and tripled for integer instructions and floating-point instructions, respectively. A fourstream hardware prefetch facility was also added.

A decision was made to not store operands in the reservation station entries; instead, operands were read from the physical registers in a separate pipe stage just prior to execution. Also, timing issues led to a separate finish stage prior to the commit stage. Thus the POWER3 pipeline has two additional stages as compared to the 620 and was able to reach a clock rate approximately three times faster than the 620.

See Song [1997b] and O'Connell and White [2000] for more information on the POWER3.


### 8.3.1  POWER4/2002. The IBM POWER4 is a high-performance multiprocessing system design. Jim Kahle and Chuck Moore were the chief architects.
Each chip contains two processing cores, with each core having its own eight function units (including two floating-point units and two load/store units) and Ll caches but sharing a single unified L2 cache and L3 cache controller and directory. A single multichip module can package four chips, so the basic system building block is an eight-way SMP.

The eight-way issue core is equally as ambitious in design as the surrounding caches and memory access path logic. The traditional IBM brainiac style was explicitly discarded in POWER4 in favor of a deeply pipelined speed demon that even cracks some of the enhanced-RISC PowerPC instructions into separate, simpler internal operations. Up to 200 instructions can be in-flight.

Instructions are fetched based on a hybrid branch prediction scheme that is unusual in its use of I-bit predictors rather than the more typical 2-bit predictors.
A 16K-entry selector chooses between a 16K-entry local predictor and a gsharelike 16K-entry global predictor. Special handling of branch-to-link and branch-oncount instructions is also provided. POWER4 allows hint bits in the branch instructions to override the dynamic branch prediction.
In a scheme somewhat reminiscent of the PowerPC 601, instruction groups are formed to track instruction completion; however, in POWER4, the group is anchored by a branch instruction. Groups of five are formed sequentially, with the anchoring branch instruction in the fifth slot and nops used to pad out any unfilled slots. Condition register instructions must be specially handled, and they can only be assigned to the first or second slot of a group. The groups are tracked by use of a 20-entry global completion table.

Only one group can be dispatched into the issue queues per cycle, and only one group can complete per cycle. Instructions that require serialization form their own single-issue groups, and these groups cannot execute until they have no other uncompleted groups in front of them. Instructions that are cracked into two internal operations, like load-with-update, must have both internal operations in the same group. More complex instructions, like load-multiple, are cracked into several internal operations (called millicoding), and these operations must be placed into groups separated from other instructions. Upon an exception, instructions within the group from which the exception occurred are redispatched in separate, single-instruction groups.

Once in the issue queues, instructions and internal operations can issue out of order. There are 11 issue queues with a total of 78 entries among them. In a scheme somewhat reminiscent of the HP 8000, an even-odd distribution of the group slots to the issue queues and function units is used. An abundance of physical registers are provided, including 80 physical registers for the 32 architected general registers, 72 physical registers for the 32 architected floating-point registers, 16 physical registers for the architected link and count registers, and 32 physical registers for the eight condition register fields.

The POWER4 pipeline has nine stages prior to instruction issue (see Figure 6.6).
Two of these stages are required for instruction fetch, six are used for instruction cracking and group formation, and one stage provides for resource mapping and dispatch. A simple integer instruction requires five stages during executing, including issue, reading operands, executing, transfer, and writing the result. Groups can complete in a final complete stage, making a 15-stage pipeline for integer instructions. Floating-point instructions require an extra five stages.

The on-chip caches include two 64K-byte instruction caches, two 32K-byte data caches, and a unified L2 cache of approximately 1.5 Mbytes. Each Ll data cache provides up to two reads and one store per cycle. Up to eight prefetch streams and an off-chip L3 of 32 Mbytes is supported. The L2 cache uses a sevenstate, enhanced MESI coherency protocol, while the L3 uses a five-state protocol.

See Section 6.8 and Tendler et al. [2002] for more information on POWER4.


### 8.3.1  PowerPC 970 (GS) 12003. 
The PowerPC 970 is a single-core version of the POWER4, and it includes the AltiVec extensions. The chief architect is Peter Sandon. An extra pipeline stage was added to the front end for timing purposes, so the 970 has a 16-stage pipeline for integer instructions. While two SIMD units have been added to make a total of 10 function units, the instruction group size remains at five and the issue limit remains at eight instructions per cycle. See Halfhill [2002] for details.



### 8.3.1 PowerPC-AS

Following a directive by IBM President Jack Kuehler in 1991, a corporate-wide effort was made to investigate standardizing on the PowerPC. Engineers from the AS/400 division in Rochester, Minnesota, had been working on a commercial RISC design (C-RISC) for the next generation of the single-level store AS/400 machines, but they were told to instead adapt the 64-bit PowerPC architecture. This extension, called Amazon and later PowerPC-AS, was designed by Andy Wottreng and Mike Corrigan at IBM Rochester, under the leadership of Frank Soltis.

Since the 64-bit PowerPC 620 was not ready, Rochester went on to develop the multichip A30 (Muskie), while Endicott developed the single-chip AlO (Cobra). These designs did not include the 32-bit PowerPC instructions, but theseries and called the RS64. See Soltis [2001] for details of the Rochester efforts.

Currently, PowerPC-AS processors, including the POWER4, implement the 228 64-bit PowerPC instruction set plus more than 150 AS-mode instructions.
PowerPC-AS A30 (Muskie) 11995. The A30 was a seven-chip, highend, SMP-capable implementation. The design was based on a five-stage pipeline:
fetch , dispatch, execute, commit, and writeback. Five function units were provided, and up to four instructions could be issued per cycle, in order. Hazard detection was done in the execute stage, rather than the dispatch stage, and floatingpoint registers were renamed to avoid hazards. The commit stage held results until they could be written back to the register files. Branches were handled using predict-untaken, but the branch unit could look up to six instructions back in the 16-entry current instruction queue and determine branch target addresses. An eight-entry branch target queue was used to prefetch taken-path instructions.

Borkenhagen et al. [1994] describes the A30.


### 8.3.1 ### 8.3.1  PowerPC-AS A 10 (Cobra) and A35 (Apache, RS64) 11995 and 1997.
The AlO was a single-chip, uniprocessor-only implementation with four pipeline stages and in-order issue of up to three instructions per cycle. No renaming was done. See Bishop et al. [1996] for more details. The A35 (Apache) was a folIowon design at Rochester that added the full PowerPC instruction set and multiprocessor support to the AlO. It was a five-chip implementation and was introduced in 1997.

PowerPC-AS A50 (Star series) 11998-2001. In 1998, Rochester introduced the first of the multithreaded Star series of PowerPC-AS processors.
This was the A50, also called Northstar and known as the RS64-II when used in RS/6000 systems. Process changes [specifically, copper interconnect and then silicon on insulator (SOl)] led to the A50 design being renamed as Pulsar I RS64-III and then i-Star. See Borkenhagen et al. [2000] for a description of the most recent member of the Star series, the s-Star or RS64-IV.




### 8.3.1 ### 8.3.1 SPARC Version 8

The SPARC architecture is a RISC design derived from work by David Patterson at the University of California at Berkeley. One distinguishing feature of that early work was the use of register windows for reducing memory traffic on procedure calls, and this feature was adopted in SPARC by chief architect Robert Garner.

The first SPARC processors implemented what was called version 7 of the architecture in 1986. It was highly pipeline oriented and defined a set of integer instructions, each of which could be implemented in one cycle of execution (integer multiply and divide were missing), and delayed branches. The architecture manual explicitly stated that "an untaken branch takes as much or more time than a taken branch." A floating-point queue was also explicitly defined in the architecture manual; it is a reorder buffer that can be directly accessed by exception handler software.

Although the version 7 architecture manual included suggested subroutines for integer multiply and divide, version 8 of the architecture in 1990 adopted integer multiply. The SuperSPARC and HyperSPARC processors implement version 8.



### 8.3.1  Texas Instruments SuperSPARC (Viking) 11992. 
The SuperSPARC was designed by Greg Blanck of Sun, with the implementation overseen by Steve Krueger of TI. The SuperSPARC issued up to three instructions per cycle in program order and was built around a control unit that handled branching, a floatingpoint unit, and a unique integer unit that contained three cascaded ALUs. These cascaded ALUs permitted the simultaneous issue of a dependent pair of integer instructions.

The SuperSPARC fetched an aligned group of four instructions each cycle.
The decoder required one and one-half cycles and attempted to issue up to three instructions in the last half-cycle, in what Texas Instruments called a grouping stage. While some instructions were single-issue (e.g., register window save and restore, integer multiply), the grouping logic could combine up to two integer instructions, one load/store, and/or one floating-point instruction per group. The actual issue rules were quite complex and involved resource constraints such as a limit on the number of integer register write ports. An instruction group was said to be finalized after any control transfer instruction. In general, once issued, the group proceeded through the pipelines in lockstep manner. However, floatingpoint instructions would be placed into a four-entry instruction buffer to await floating-point unit availability and thereafter would execute independently. The SPARC floating-point queue was provided for dealing with any exceptions. As noted before, a dependent instruction (integer, store, or branch) could be included in a group with an operand-producing integer instruction due to the cascaded ALUs. This was not true for an operand-producing load; because of possible cache misses, any instruction dependent on a load had to be placed in the next group.

The SuperSPARC contained two four-instruction fetch queues. One was used for fetching along the sequential path, while the other was used to prefetch instructions at branch targets whenever a branch was encountered in the sequential path.
Since a group finalized after a control transfer instruction, a delay slot instruction was placed in the next group. This group would be speculatively issued. (Thus the SuperSPARC was actually a predict-untaken design). If the branch was taken, the instructions in the speculative group, other than the delay slot instruction, would be squashed, and the prefetched target instructions would then be issued in the next group. Thus there was no branch penalty for a taken branch; rather there was a one-issue cycle between the branch group and the target group in which the delay slot instruction was executed by itself.

See Blanck and Krueger [1992] for an overview of SuperSPARC. The chip was somewhat of a performance disappointment, allegedly due to problems in the cache design rather than the core.of multiple issue. However, its success in competing in performance against the SuperSPARC is another example, like Alpha versus POWER, of a speed demon versus a brainiac. The HyperSPARC specification was done by Raju Vegesna and the first simulator by Jim Monaco. A preliminary article on the HyperSPARC was published by Vegesna [1992].

The HyperSPARC had four execution units: integer, floating-point, load/ store, and branch. Two instructions per cycle could be fetched from an 8K-byte on-chip instruction cache and placed into the decoder. The two-instruction-wide decoder was unaggressive and would not accept more instructions until both previously fetched instructions had been issued. The decoder also fetched register operand values.

Three special cases of dependent issue were supported: (1) sethi and dependent, (2) sethi and dependent load/store, and (3) an integer ALU instruction that sets the condition code and a dependent branch. Two floating-point instructions could also be dispatched into a four-entry floating-point prequeue in the same cycle, if the queue had room. There were several stall conditions, some of which involved register file port contention since there were only two read ports for the integer register file. Moreover, there were 53 single-issue instructions, including call, save, restore, multiply, divide, and floating-point compare.

The integer unit had a total of 136 registers, thus providing eight overlapping windows of 24 registers each and eight global registers. The integer pipeline, as well as the load/store and branch pipelines, consisted of four stages beyond the common fetch and decode: execute, cache read, cache write, and register update.

The integer unit did not use the two cache-related stages, but they were included so that all non-floating-point pipelines would be of equal length. Integer multiply and divide were unusually long, 18 and 37 cycles, respectively; moreover, they stalled further instruction issue until they were completed.

The floating-point unit's four-entry prequeue and a three-entry postqueue together implemented the SPARC floating-point queue technique for out-of-order completions in the floating-point unit. The prequeue allowed the decoder to dispatch floating-point instructions as quickly as possible. Instructions in the floatingpoint prequeue were decoded in order and issued into the postqueue; each postqueue entry corresponded to an execution stage in the floating-point pipeline (execute-I, execute-2, round). A floating-point load and a dependent floating-point instruction could be issued/dispatched in the same cycle; however, the dependent instruction would spend two cycles in the prequeue before the loaded data were forwarded to the execute-l stage. When a floating-point instruction and a dependent floatingpoint store were paired in the decoder, the store waited for at least two cycles in the decoder before the operation result entered the round stage and from there was forwarded to the load/store unit in the subsequent cycle.



### 8.3.1  Metaflow Lightning and Thunder 1Canceled. 
The Lightning and Thunder were out-of-order execution SPARC designs by Bruce Lightner and Val Popescu. These designs used a centralized reservation station approach called deferred-scheduling register-renaming instruction shelf (DRIS). Thunder was described at the 1994 Hot Chips and was an improved three-chip version of the four-chip Lightning, which was designed in 1991. Thunder issued up to four instructions per cycle to eight execution units: three integer units, two floatingpoint units, two load/store units, and one branch unit. Branch prediction was dynamic and included return address prediction. See Lightner and Hill [1991] and Popescu et al. [1991] for articles on Lightning, and see Lightner [1994] for a presentation on Thunder. Neither design was delivered, and Hyundai was assigned the patents.



### 8.3.1  SPARC Version 9
The 64-bit SPARC instruction set is known as version 9. The revisions were decided by a large committee with more than 100 meetings. Major contributors were Dave Ditzel (chairman), Joel Boney, Steve Chessin, Bill Joy, Steve Kleiman, Steve Kruger, Dave Weaver, Winfried Wilcke, and Robert Yung. The goals of the version 9 architecture also included avoiding serialization points. Thus, there are now four separate floating-point condition codes as well as a new type of integer branch that conditionally branches on the basis of integer register contents, giving the effect of multiple integer condition codes. Version 9 also added support for nonfaulting speculative loads, branch prediction bits in the branch instruction formats, conditional moves, and a memory-barrier instruction for a weakly ordered memory model.



### 8.3.1  Hal SPARC64 I 1995. 
The SPARC64 was the first of several implementations of the SPARC version 9 architecture that were planned by HaL, including a multiprocessor version with directory-based cache coherence. The HaL designs use a unique three-level memory management scheme (with regions, views, and then pages) to reduce the amount of storage required for mapping tables for its 64-bit address space. The SPARC64 designers were Hisashige Ando, Winfried Wilcke, and Mike Shebanow.

The windowed register file contained 116 integer registers, 78 of which were bound at any given time to form four SPARC register windows. This left 38 free integer registers to be used for renaming. There were also 112 floating-point registers, 32 of which were bound at any given time to single-precision and another 32 of which were bound to double-precision. This left 48 free floating-point registers to be used in renaming. The integer register file had 10 read ports and 4 write ports, while the floating-point register file had 6 read ports and 3 write ports.

The SPARC64 had four 64K-byte, virtually addressed, four-way set-associative caches (two were used for instructions, and two were used for data; this allowed two nonconflicting load/stores per cycle). A real address table was provided for inverse mapping of the data caches, and non blocking access to the data caches (with load merging) was also provided using eight reload buffers. For speeding up instruction access, a level-O 4K-byte direct-mapped instruction cache was provided in which SPARC instructions were stored in a partially decoded internalA 2-bit branch history was also provided for each instruction in the level-O instruction cache.

Up to four instructions were dispatched per cycle, with some limits according to instruction type, into four reservation stations. There was an 8-entry reservation station for four integer units (two integer ALUs, an integer multiply unit, and an integer divide unit); an 8-entry reservation station for two address generation units; an 8-entry reservation station for two floating-point units (a floating-point multiplier-adder unit and a floating-point divider); and a 12-entry reservation station for two load/store units. Register renaming was performed during dispatch. A load or store instruction was dispatched to both the address generation unit reservation station and the load/store unit reservation station. The effective address was sent from the address generation unit to a value cache associated with the load/ store reservation station.

While some designs provide for an equal number of instructions to be dispatched, issued, completed, and retired during a given cycle, the SPARC64 had a wide variance. In a given cycle, up to four instructions could dispatch, up to seven instructions could issue, up to ten could execute, up to nine instructions could complete, up to eight instructions could commit, and up to four instructions could retire. A maximum of 64 instructions could be active at any point, and the hardware kept track of these in the A ring via individually assigned 6-bit serial numbers. The A ring operated in a checkpoint-repair manner to provide branch misprediction recovery, and there was room for 16 checkpoints (at branches or instructions that modified unrenamed control registers). Four pointers were used to update the A ring: last issued serial number (ISN), last committed serial number (CSN), resource recovery pointer (RRP), and noncommitted memory serial number pointer (NCSNP), which allowed aggressive scheduling of loads and stores. A pointer to the last checkpoint was appended to each instruction to allow for a onecycle recovery to the checkpoint. For trapping instructions that were not aligned on a checkpoint, the processor could undo four instructions per cycle.

The integer instruction pipeline had seven stages: fetch, dispatch, execute, write, complete, commit, and retire. A decode stage was missing since the decoding was primarily accomplished as instructions were loaded into the level-O instruction cache. The complete stage checked for errors/exceptions; the commit stage performed the in-order update of results into the architectural state; and the retire stage deallocated any resources. Two extra execution stages were required for load/stores. Using the trap definitions in version 9, the SPARC64 could rename trap levels, and this allowed the processor to speculatively enter traps that were detected during dispatch.

See Chen et al. [1995], Patkar et al. [1995], Simone et al. [1995], Wilcke [1995], and Williams et al. [1995] for more details of SPARC64. The Simone paper details several interesting design tradeoffs, including special priority logic for issuing condition-code-modifying instructions.
HaL was bought by Fujitsu, which produced various revisions of the basic design, called the SPARC64-II, -III, GP, and -IV (e.g., increased level-O instruction cache and BHT sizes). A two-level branch predictor and an additional pipeline stage for dispatch were introduced in the SPARC64-III [Song, 1997a]. An ambitious new core, known as the SPARC64 V, was an eight-way issue design using a trace cache and value prediction. Mike Shebanow, the chief architect, described this design at the 1999 Microprocessor Forum [Diefendorff, 1999b] and at a seminar presentation at Stanford University in 1999 [Shebanow, 1999]. Fujitsu canceled this project and instead introduced another revision of the original core under the name SPARC64-V in 2003 [Krewell, 2002].



### 8.3.1  UltraSPARC-1/199S. 
The UltraSPARC-I was designed by Les Kohn, Marc Tremblay, Guillermo Maturana, and Robert Yung. It provided four-way issue to nine function units (two integer ALUs, load/store, branch, floating-point add, floating-point multiply, floating-point divide/square root, graphics add, and graphics multiply). A set of 30 or so graphics instructions was introduced for the UltraSPARC and is called the visual instruction set (VIS). Block load/store instructions and additional register windows were also provided in the U1traSPARC-I. Figure 8.16 illustrates the UltraSPARC-I pipeline.

The U1traSPARC-I was not an ambitious out-of-order design as were many of its contemporaries. The design team extensively simulated many designs, including various forms of out-of-order processing. They reported that an out-oforder approach would have cost a 20% penalty in clock cycle time and would have likely increased the time to market by three to six months. Instead, high performance was sought by including features such as speculative, nonfaulting loads, which the UltraSPARC compilers can use to perform aggressive global code motion.rmed inorder issue of groups of up to four instructions each. The design provided precise exceptions by discarding the traditional SPARC floating-point queue in favor of padding out all function unit pipelines to four stages each. Exceptions in longerrunning operations (e.g., divide, square root) were predicted.

Speculative issue was provided using a branch prediction mechanism similar to Johnson's proposal for an extended instruction cache. An instruction cache line in UltraSPARC-I contained eight instructions. Each instruction pair had a 2-bit history, and each instruction quad had a 12-bit next-cache-line field. The history and nextline field were used to fill the instruction buffer, and this allocation of history bits was claimed to improve prediction accuracy by removing interference between multiple branches that map to the same entry in a traditional BHT. Branches were resolved after the first execute stage in the integer and floating-point pipelines.

The UltraSPARC-I was relatively aggressive in its memory interface. The instruction cache used a set prediction method that provided the access speed of a direct-mapped cache while retaining the reduced conflict behavior of a two-way set-associative cache. There was a nine-entry load buffer and an eight-entry store buffer. Load bypass was provided as well as write merging of the last two store buffer entries.

See Wayner [1994], Greenley et al. [1995], Lev et al. [1995] , and Tremblay and O'Connor [1996] for descriptions of the UItraSPARC-I processor. Tremblay et al. [1995] discusses some of the tradeoff decisions made during the design of this processor and its memory system. Goldman and Tirumalai [1996] discuss the UltraSPARC-II, which adds memory system enhancements, such as prefetching, to the UltraSPARC-I core.



### 8.3.1  Ultra5PARC-1II/2000. 
Gary Lauterbach is the chief designer for the UItraSPARC-III, which retains the in-order issue approach of its predecessor. The UltraSPARC-III pipeline, however, is extended to 14 stages with careful attention to memory bandwidth. There are two integer units, a memory/special-instruction unit, a branch unit, and two floating-point units. Instructions are combined into groups of up to four instructions, and each group proceeds through the pipelines in lockstep manner. Grouping rules are reminiscent of the SuperSPARC and UltraSPARC-1. However, as in the Alpha 21164, the UltraSPARC-III rejects a global stall signaling scheme and instead adopts a replay approach.

Branches are predicted using a form of gshare with 16K predictors. Pipeline timing considerations led to a design with the pattern history table being held in eight banks. The xor result of 11 bits from the program counter and 11 bits from the global branch history shift register is used to read out one predictor per bank, and then an additional three low-order bits from the program counter are used in the next stage to select among the eight predictors. Simulations indicated that this approach has similar accuracy to the normal gshare scheme.

A four-entry miss queue for holding fall-through instructions is used along with a 16-entry instruction queue (although sometimes described as having 20 entries) to reduce the branch misprediction penalty for untaken branches.
Conditional moves are available in the instruction set for partial predication, but the code optimization section of the manual advises that code performance is better with conditional branches than with conditional moves if the branches are fairly predictable.
To reduce the number of integer data forwarding paths, a variant of a future file, called the working register file, is used. Results are written to this structure in an out-of-order manner and are thus available to dependent instructions as early as possible. Registers are not renamed or tagged. Instead, age bits are included in the decoded instruction fields along with destination register IDs and are used to eliminate W A W hazards. WAR hazards are prevented by reading operands in the issue ("dispatch") stage. Precise exceptions are supported by not updating the architectural register file until the last stage, after all possible exceptions have been checked. If recovery is necessary, the working register file can be reloaded from the architectural register file in a single cycle.

The UltraSPARC-III has a 32K-byte L1 instruction cache and 64K-byte L1 data cache. The data cache latency is two cycles, which derives from a sumaddressed memory technique. A 2K-byte write cache allows the data cache to appear as write-through but defers the actual L2 update until a line has to be evicted from the write cache itself. Individual byte valid bits allow for storing only the changed bytes in the write cache and also support write-merging. A 2K-byte triple-ported prefetch cache is provided, which on each clock cycle can provide two independent 8-byte reads and receive 16 bytes from the main memory. In addition to the available software prefetch instructions, a hardware prefetch engine can detect the stride of a load instruction within a loop and automatically generates prefetch requests. Also included on-chip is a memory controller and cache tags for an 8-Mbyte L2 cache.

See Horel and Lauterbach [1999] and Lauterbach [1999] for more information on the UltraSPARC-I11. The working register file is described in more detail in U.S. Patent 5,964,862. The UltraSPARC-IV is planned to be a chip mUltiprocessor with two UltraSPARC-III cores.



## 8.4 Verification of Superscalar Processors

Charles Moore (RSC, PPC 601, and POWER4) recently started a series of articles in IEEE Micro about the challenges of complexity faced by processor design teams [2003]. He suggested that a design team was in trouble when there were any less than two verification people assigned to clean up after each architect. While this simple and humorous rule of thumb may not hold in every case, it is true that superscalar processors are some of the most complex types of logical designs. It is not unusual to have over 100 in-flight instructions that may interact with each other in various ways and interact with corner cases, such as exceptions and faults .

The combinatorial explosion of possible states is overwhelming. Indeed, several architects have chosen simpler in-order design strategies explicitly to reduce complexity and thereby improve time-to-market.
A study of verification techniques is beyond the scope of this chapter. However, since verification plays such an important role in the design process, a sampling of references to verification efforts for commercial superscalar processors follows. Articles on design and verification techniques used for Alpha processors includes Kantrowitz and Noack [1996], Grundmann et al. [1997], Reilly [1997], Dohm et al. [1998], Taylor et al. [1998], and Lee and Tsien [2001] . An article by Monaco et al. [1996] is a study of functional verification for the PPC 604, while an article by Ludden et al. [2002] is a more recent study of the same topic for POWER4. As a further sample of the approaches taken by industry design teams, Turumella et al. [1995] review design verification for the HaL SPARC64, Mangelsdorf et al. [1997] discuss the verification of the HP PA-8000, and Bentley and Gray [2001] present the verification techniques used for the Intel Pentium 4.




## 8.5 Acknowledgments to the Author (Mark Smotherman) 
Several people were very helpful in providing information on the superscalar processors covered in this chapter: Tilak Agerwala, Fran Allen, Gene Amdahl, Erich Bloch, Pradip Bose, Fred Brooks, Brad Burgess, John Cocke, Lynn Conway, Marvin Denman, Mike Flynn, Greg Grohoski, Marty Hopkins, Peter Song, and Ed Sussenguth, all associated with IBM efforts; Don Alpert, Gideon Intrater, and Ran Talmudi, who worked on the NS Swordfish; Mitch Alsup, Joe Circello, and Keith Diefendorff, associated with Motorola efforts; Pete Bannon, John Edmondson, and Norm Jouppi, who worked for DEC; Mark Bluhm, who worked for Cyrix; Joel Boney, who worked on the SPARC64; Bob Colwell, Andy Glew, Mike Haertel, and Uri Weiser, who worked on Intel designs; Josh Fisher and Bill Worley of HP; Robert Garner, Sharad Mehrotra, Kevin Normoyle, and Marc Tremblay of Sun; Earl Killian, Kevin Kissell, John Ruttenberg, and Ross Towle, associated with SGIIMIPS; Steve Krueger ofTI; Woody Lichtenstein and Dave Probert, both of whom worked on the Culler 7; Tim Olson; Yale Patt of the University of Texas and inventor of HPS; Jim Smith of the University of Wisconsin, designer of the ZS-I, and co-enthusiast for a processor pipeline version of lane's Fighting Ships; and John Yates, who worked on the Apollo DN 10000. Peter Capek of IBM was also instrumental in helping me obtain information on the ACS. I also want to thank numerous students at Clemson, including Michael Laird, Stan Cox, and T. J. Tumlin.


REFERENCES
Processor manuals are available from the individual manufacturers and are not included in the references.
Acosta, R., J. Kjelstrup, and H. Torng: "An instruction issuing approach to enhancing perfonnance in mUltiple functional unit processors," IEEE Trans. on Computers, C-35, 9, September 1986, pp. 815-828.
Allen, F. : "The history of language processor technology in IBM," IBM Journal of Research and Development, 25, 5, September 1981, pp. 535-548.3, June 1993, pp. 11-21.
Asprey, T., G. Averill, E. DeLano, R. Mason, B. Weiner, and J. Yetter: "Performance features of the PA 7100 microprocessor," IEEE Micro, 13, 3, June 1993, pp. 22-35.
Bailey, D.: "High-performance Alpha microprocessor design," Proc. Int. Symp. VLSI Tech., Systems and Appls., Taipei, Taiwan, June 1999, pp. 96-99.
Bannon, P., and J. Keller: "The internal architecture of Alpha 21164 microprocessor," Proc. COMPCON, San Francisco, CA, March 1995, pp. 79-87 .
Barreh, J. , S. Dhawan, T. Hicks, and D. Shippy: "The POWER2 processor," Proc.
COMPCON, San Francisco, CA, Feb.-March 1994, pp. 389-398.
Bashe, c., L. Johnson, J. Palmer, and E. Pugh: IBM's Early Computers. Cambridge, MA:
M.I.T. Press, 1986.
Becker, M., M. Allen, C. Moore, J. Muhich, and D. Tuttle: "The PowerPC 601 microprocessor," IEEE Micro, 13,5, October 1993, pp. 54-67.
Benschneider, B., et al.: "A 300-MHz 64-b quad issue CMOS RISC microprocessor," IEEE Journal oJSolid-State Circuits, 30, 11, November 1995, pp. 1203-1214. [21164] Bentley, B., and R. Gray, "Validating the Intel Pentium 4 Processor," Intel Technical Journal, quarter 1, 2001, pp. 1-8.
Bishop, J., M. Campion, T. Jeremiah, S. Mercier, E. Mohring, K. Pfarr, B. Rudolph, G. Still, and T. White: "PowerPC AS AIO 64-bit RISC microprocessor," IBM Journal oj Research and Development, 40, 4, July 1996, pp. 495-505 .
Blanchard, T., and P. Tobin: "The PA 7300LC microprocessor: A highly integrated system on a chip," Hewlett-Packard Journal, 48, 3, June 1997, pp. 43-47.
Blanck, G., and S. Krueger: "The SuperSPARC microprocessor," Proc. COMPCON, San Francisco, CA, February 1992, pp. 136-141.
Borkenhagen, J., R. Eickemeyer, R. Kalla, and S. Kunkel: "A multithreaded PowerPC processor for commercial servers," IBM Journal oj Research and Development, 44, 6, November 2000, pp. 885-898. [SStarIRS64-IV]
Borkenhagen, J., G. Handlogten, J. Irish, and S. Levenstein: "AS/400 64-bit PowerPCcompatible processor implementation," Proc. ICCD, Cambridge, MA, October 1994, pp. 192-196.
Bose, P.: "Optimal code generation for expressions on super scalar machines," Proc.
AFIPS Fall Joint Computer Conj , Dallas, TX, November 1986, pp. 372-379.
Bowhill, W., et al.: "Circuit implementation of a 300-MHz 64-bit second-generation CMOS Alpha CPU," Digital TechnicaLJournal, 7, I, 1995, pp. 100-118. [21164] Buchholz, W., Planning a Computer System. New York: McGraw-Hill, 1962. [IBM Stretch] Burgess, B. , M. Alexander, Y.-W. Ho, S. Plummer Litch, S. Mallick, D. Ogden, S.-H. Park, and J. Slaton: "The PowerPC 603 microprocessor: A high performance, low power, superscalar RISC microprocessor," Proc. COMPCON, San Francisco, CA, Feb.-March 1994a,pp.300-306.

Burgess, 8., N. Ullah, P. Van Overen, and D. Ogden: "The PowerPC 603 microprocessor," Communications oJthe ACM, 37, 6, June 1994b, pp. 34-42.
Burkhardt, B.: "Delivering next-generation performance on today's installed computer base," Proc. COMPCON, San Francisco, CA, Feb.-March 1994, pp. 11-16. [Cyrix 6x86] Chan, K., et al. : "Design of the HP PA 7200 CPU," Hewlett-Packard Journal, 47, 1, February 1996, pp. 25-33.
Chen, c., Y. Lu, and A. Wong: "Microarchitecture of HaL's cache subsystem," Proc.
COMPCON, San Francisco, CA, March 1995, pp. 267-271. [SPARC64] Christie, D.: "Developing the AMD-KS architecture," IEEE Micro, 16,2, April 1996, pp. 16-26.
Circello, J., and F. Goodrich: "The Motorola 68060 microprocessor," Proc. COMPCON, San Francisco, CA, February 1993, pp. 73- 78.
Circello, J., "The superscalar hardware architecture of the MC68060," Hot Chips VI, videotaped lecture, August 1994, http://murl.microsoft.comILectureDetails.asp?490.
Circello, J., et al.: "The superscalar architecture of the MC68060," IEEE Micro, 15, 2, April 1995, pp. 10-21.
Cocke, J. : "The search for performance in scientific processors," Communications of the ACM, 31,3, March 1988, pp. 250-253.
Cohler, E., and J. Storer: "Functionally parallel architecture for array processors," IEEE Computer, 14, 9, Sept. 1981, pp. 28-36. [MAP 200] DeLano, E., W. Walker, J. Yetter, and M. Forsyth: "A high speed superscalar PA-RISC processor," Proc. COMPCON, San Francisco, CA, February 1992, pp. 116-121. [PA 7100] Denman, M., "PowerPC 604 RISC microprocessor," Hot Chips VI, videotaped lecture, August 1994, http://murl.microsoft.comILectureDetails.asp?492.

Denman, M., P. Anderson, and M. Snyder: "Design of the PowerPC 604e microprocessor," Proc. COMPCON, Santa Clara, CA, February 1996, pp. 126-131.
Diefendorff, K., "PowerPC 601 microprocessor," Hot Chips V, videotaped lecture, August 1993, http://murl.microsoft.comILectureDetails.asp?483.
Diefendorff, K.: "History of the PowerPC architecture," Communications of the ACM, 37, 6, June 1994, pp. 28-33 .
Diefendorff, K., "K7 challenges Intel," Microprocessor Report, 12, 14, October 26, 1998a, pp.l,6-11.
Diefendorff, K., "WinChip 4 thumbs nose at ILP," Microprocessor Report, 12, 16, December 7, 1998b, p. 1.
Diefendorff, K., "PowerPC G4 gains velocity," Microprocessor Report, 13, 14, October 25, 1999a, p. 1.
Diefendorff, K., "Hal makes Sparcs fly," Microprocessor Report, 13, 15, November 15, 1999b, pp. 1,6-12.
Diefendorff, K., and M. Allen: "The Motorola 88110 superscalar RISC microprocessor," Proc. COMPCON, San Francisco, CA, February I 992a, pp. 157-162.
Diefendorff, K., and M. Allen: "Organization of the Motorola 88110 superscalar RISC microprocessor," IEEE Micro, 12,2, April 1992b, pp. 40-63.
Diefendorff, K., R. Oehler, and R. Hochsprung: "Evolution of the PowerPC architecture," IEEE Micro, 14,2, April 1994, pp. 34-49.
Diefendorff, K., and E. Silha: "The PowerPC user instruction set architecture," IEEE Micro, 14,5, December 1994, pp. 30-41.
Ditzel, D., and H. McLellan: "Branch folding in the CRISP microprocessor: Reducing branch delay to zero," Proc. ISCA, Philadelphia, PA, June 1987, pp. 2-9.
Ditzel, D., H. McLellan, and A. Berenbaum: "The hardware architecture of the CRISP microprocessor," Proc. ISCA, Philadelphia, PA, June 1987, pp. 309-319.
Dohm, N., C. Ramey, D. Brown, S. Hildebrandt, J. Huggins, M. Quinn, and S. Taylor, "Zen and the art of Alpha verification," Proc. ICCD, Austin, TX, October 1998, pp. 111-117.
Eden, M., and M. Kagan: "The Pentium processor with MMX technology," Proc. COMPCON, San Jose, CA, February 1997, pp. 260-262.
Edmondson, J., "An overview of the Alpha AXP 21164 microarchitecture," Hot Chips VI, videotaped lecture, August 1994, http://murI.microsoft.com/LectureDetails.asp?493.
Edmondson, J., et al.: "Internal organization of the Alpha 21164, a 300-MHz 64-bit quadissue CMOS RISC microprocessor," Digital Technical Journal, 7, 1, 1995a, pp. 119-135.
Edmondson, J., P. Rubinfeld, R. Preston, and V. Rajagopalan: "Superscalar instruction execution in the 21164 Alpha microprocessor," IEEE Micro, 15,2, April 1995b, pp 33-43.
Fisher, J.: "Very long instruction word architectures and the ELI-512," Proc. ISCA, Stockholm, Sweden, June 1983, pp. 140-150.
Flynn, M.: "Very high-speed computing systems," Proc. IEEE, 54, 12, December 1966, pp. 1901-1909.
Gaddis, N., and J. Lotz: "A 64-b quad-issue CMOS RISC microprocessor," IEEE Journal of Solid-State Circuits, 31 , 11 , November 1996, pp. 1697-1702. [PA 8000] Gieseke, B., et al.: "A 600MHz superscalar RISC microprocessor with out-of-order execution," Proc. IEEE Int. Solid-State Circuits Conference, February 1997. pp. 176-177. [21264] Gochman, S., et aI., "The Pentium M processor: Microarchitecture and performance," Intel Tech. Journal, 7,2, May 2003, pp. 21-36.

Goldman, G., and P. Tirumalai: "UltraSPARC-II: The advancement of ultracomputing," Proc. COMPCON, Santa Clara, CA, February 1996, pp. 417-423.
Gowan, M., L. Brio, and D. Jackson, "Power considerations in the design of the Alpha 21264 microprocessor," Proc. Design Automation Conf, San Francisco, CA, June 1998, pp. 726-73l.
Greenley, D. , et al.: "UltraSPARC: The next generation superscalar 64-bit SPARC," Proc.
CaMP CON, San Francisco, CA, March 1995, pp. 442-45l.
Gronowski, P., et al.: "A 433-MHz 64-b quad-issue RISC microprocessor," IEEE Journal of Solid-State Circuits, 31, II, November 1996, pp. 1687-1696. [21 I 64A] Grundmann, W., D. Dobberpuhl, R. Almond, and N. Rethman, "Designing high performance CMOS microprocessors using full custom techniques," Proc. Design Automation Con[., Anaheim, CA, June 1997, pp. 722-727.

Gwennap, L.: "Cyrix describes Pentium competitor," Microprocessor Report, 7, 14, October 25, 1993, pp. 1-6. [M1I6x86]
Gwennap, L.: "AMD's K5 designed to outrun Pentium," Microprocessor Report, 8, 14, October 14, 1994, pp. 1-7.
Gwennap, L.: "Intel's P6 uses decoupled superscalar design," Microprocessor Report, 9,2, February 16, 1995, pp. 9-15.
Halfhill, T.: "AMD vs. Superman," Byte, 19, 11, November 1994a, pp. 95-104. [AMD K5] Halfhill, T.: "T5: Brute force," Byte, 19, 11, November 1994b, pp. 123-128. [MIPS Rl0000] Halfhill, T.: "Intel's P6," Byte, 20,4, April 1995, p. 435. [Pentium Pro] Halfhill, T.: "AMD K6 takes on Intel P6," Byte, 21, 1, January 1996a, pp. 67-72.

Halfhill, T.: "PowerPC speed demon," Byte, 21,12, December 1996b, pp. 88NAI-88NA8.
Halfhill, T., "IBM trims Power4, adds AltiVec," Microprocessor Report, October 28,2002.
Hall, c., and K. O'Brien: "Performance characteristics of architectural features of the IBM RISC System/6000," Proc. ASPLOS-IV, Santa Clara, CA, April 1991, pp. 303-309.
Hester, P., "Superscalar RISC concepts and design of the IBM RISC System/6000," videotaped lecture, August 1990, http://murl.microsoft.com/LectureDetails.asp?31S.
Hewlett-Packard: "PA-RISC 8xOO family of microprocessors with focus on PA-8700," Hewlett Packard Corporation, Technical White Paper, April 2000.
Hinton, G.: "80960-Next generation," Proc. COMPCON, San Francisco, CA, March 1989, pp. 13-17.
Hinton, G., D. Sager, M. Upton, D. Boggs, D. Carmean, A. Kyker, and P. Roussel : "The microarchitecture of the Pentium 4 processor," Intel Technology Journal, Quarter I, 2001, pp. 1-12.
Hollenbeck, D., A. Undy, L. Johnson, D. Weiss, P. Tobin, and R. Carlson: "PA7300LC integrates cache for cost/performance," Proc. COMPCON, Santa Clara, CA, February 1996, pp. 167-174.
Horel, T., and G. Lauterbach: "UltraSPARC-III: Designing third generation 64-bit performance," IEEE Micro, 19, 3, May-June, 1999, p. 85 .
Horst, R., R. Harris, and R. Jardine: "Multiple instruction issue in the NonStop Cyclone processor," Proc.ISCA, Seattle, WA, May 1990, pp. 216-226.
Hsu, P., "Silicon GraphicsTFP micro-supercomputer chipset," Hot Chips V, videotaped lecture, August 1993, http://murl.microsoft.com/LectureDetails.asp?484. [R8000] Hsu, P.: "Designing the TFP microprocessor," IEEE Micro, 14,2, April 1994, pp. 23-33 .
[MIPS R8000]
Hunt, J.: "Advanced performance features of the 64-bit PA-8000," Proc. COMPCON, San Francisco, CA, March 1995, pp. 123-128.
IBM: IBM RISC System/6000 Technology. Austin, TX: IBM Corporation, 1990, p. 421.
Johnson, L., and S. Undy: "Functional design of the PA 7300LC," Hewlett-Packard Journal, 48, 3, June 1997, pp. 48-63.
Jouppi, N., and D. Wall: "Available instruction-level parallelism for superscalar and superpipelined machines," Proc. ASPLOS-llI, Boston, MA, April 1989, pp. 272-282.
Kantrowitz, M., and L. Noack, "I'm done simulating: Now what? Verification coverage analysis and correctness checking of the DECchip 21164 Alpha microprocessor," Proc.
Design Automation Conj, Las Vegas, NV, June 1996, pp. 325-330.
Keltcher, C., K. McGrath, A. Ahmed, and P. Conway, "The AMD Opteron processor for multiprocessor servers," IEEE Micro, 23, 2, March-April 2003, pp. 66-76.
Kennedy, A., et al.: "A G3 PowerPC superscalar low-power microprocessor," Proc.
COMPCON, San Jose, CA, February 1997, pp. 315-324. [PPC 7401750, but one diagram lists this chip as the 613 .]
Kessler, R.: "The Alpha 21264 microprocessor," IEEE Micro, 19, 2, March-April 1999, pp. 24-36.
Kessler, R., E. McLellan, and D. Webb: "The Alpha 21264 microprocessor architecture," Proc. ICCD, Austin, TX, October 1998, pp. 90-95.Walker: "HP's PA7100LC: A low-cost superscalar PA-RISC processor," Proc. COMPCON, San Francisco, CA, February 1993, pp. 441-447.
Krewell, K., "Fujitsu's SPARC64 V is real deal," Microprocessor Report, 16, 10, October 21 , 2002, pp.1-4.
Kurpanek, G., K. Chan, J. Zheng, E. DeLano, and W. Bryg: "PAnOO: A PA-RISC processor with integrated high performance MP bus interface," Proc. COMPCON, San Francisco, CA, Feb.-March 1994, pp. 375-382.
Lauterbach, G.: "Vying for the lead in high-performance processors," IEEE Computer, 32, 6, June 1999, pp. 38-41. [UltraSPARC III]
Lee, R., and J. Huck, "64-bit and multimedia extensions in the PA-RISC 2.0 architecture," Proc. COMPCON, Santa Clara, CA, February 1996, pp. 152-160.
Lee, R, and B. Tsien, "Pre-silicon verification of the Alpha 21364 microprocessor error handling system," Proc. Design Automation Conj, Las Vegas, NV, 2001, pp. 822-827.
Leibholz, D., and R. Razdan: "The Alpha 21264: A 500 MHz out-of-order-execution microprocessor," Proc. COMPCON, San Jose, CA, February 1997, pp. 28-36.
Lempel, 0., A. Peleg, and U. Weiser: "Intel's MMX technology-A new instruction set extension," Proc. COMPCON, San Jose, CA, February 1997, pp. 255-259.
Lesartre, G., and D. Hunt: "PA-8500: The continuing evolution of the PA-8000 family," Proc. COMPCON, San Jose, CA, February 1997.
Lev, L., et al.: "A 64-b microprocessor with multimedia support," IEEE Journal of SolidState Circuits, 30, 11, November 1995, pp. 1227-1238. [UltraSPARC] Levitan, D. , T. Thomas, and P. Tu: "The PowerPC 620 microprocessor: A high performance superscalar RISC microprocessor," Proc. COMPCON, San Francisco, CA, March 1995, pp. 285-291.

Lichtenstein, W.: "The architecture of the Culler 7," Proc. COMPCON, San Francisco, CA, March 1986, pp. 467-470.
Lightner, B., "Thunder SPARC processor," Hot Chips VI, videotaped lecture, August 1994, http://murl.microsoft.com/LectureDetails.asp?494.
Lightner, B., and G. Hill: "The Metaflow Lightning chipset," Proc. COMPCON, San Francisco, CA, February 1991, pp. 13-18.
Liptay, J. S.: "Design of the IBM Enterprise SystemJ9000 high-end processor," IBM Journal of Research and Development, 36, 4, July 1992, pp. 713-731.
Ludden, J., et al.: "Functional verification of the POWER4 microprocessor and POWER4 multiprocessor systems," IBM Journal of Research and Development, 46, 1, 2002, pp. 53-76.
Mangelsdorf, et al.: "Functional verification of the HP PA 8000 processor," HP Journal, 48,4, August 1997, pp. 22-31.
Matson, M., et aI., "Circuit implementation of a 600 MHz superscalar RISC microprocessor," Proc. ICCD, Austin, TX, October 1998, pp. 104-110. [Alpha 21264] May, D., R Shepherd, and P. Thompson, "The T9000 Transputer," Proc. ICCD, Cambridge, MA, October 1992, pp. 209-212.
McGeady, S.: "The i960CA superscalar implementation of the 80960 architecture," Proc.
COMPCON, San Francisco, CA, February 1990a, pp. 232-240.
McGeady, S.: "Inside Intel's i960CA superscalar processor," Microprocessors and Microsystems, 14,6, July/August 1990b, pp. 385-396.superscalar i960MM embedded microprocessor," Proc. CaMP CON, San Francisco, CA, February 1991, pp. 4-7.
McGrath, K., "x86-64: Extending the x86 architecture to 64 bits," videotaped lecture, September 2000, http://murl.microsoft.com/LectureDetails.asp?690.
McLellan, E. : "The Alpha AXP architecture and 21064 processor," IEEE Micro, II, 3, June 1993, pp. 36-47.
McMahan, S. , M . Bluhm, and R. Garibay, Jr. : "6x86: The Cyrix solution to executing x86 binaries on a high performance microprocessor," Proc. IEEE, 83 , 12, December 1995,pp. 1664-1672.
Mirapuri, S., M. Woodacre, and N. Vasseghi: "The Mips R4000 processor," IEEE Micro, 12,2, April 1992, pp. 10-22.
Monaco, J., D. Holloway, and R. Raina: "Functional verification methodology for the PowerPC 604 microprocessor," Proc. Design Automation Con!, Las Vegas, NV, June 1996, pp. 319- 324.
Montanaro, J.: "The design of the Alpha 21064 CPU chip," videotaped lecture, April 1992, http://murl.microsoft.com/LectureDetails.asp?373.
Moore, c.: "The PowerPC 601 microprocessor," Proc. COMPCON, San Francisco, CA, February 1993, pp. 109-116.
Moore, c.: "Managing the transition from complexity to elegance: Knowing when you have a problem," IEEE Micro, 23, 5, Sept.-Oct. 2003, pp. 86-88.
Moore, C., D. Balser, J. Muhich, and R. East: "IBM single chip RISC processor (RSC)," Proc. ICCD, Cambridge, MA, October 1989, pp. 200-204.
O'Connell, F., and S. White: "POWER3 : The next generation of PowerPC processors," IBM Journal of Research and Development, 44, 6, November 2000, pp. 873-884.
Oehler, R., and M. Blasgen: "IBM RISC Systeml6000: Architecture and performance," IEEE Micro, 11,3, June 1991 , pp. 54-62.
Papworth, D.: "Tuning the Pentium Pro microarchitecture," IEEE Micro, 16, 2, April 1996, pp.8-15.
Patkar, N., A. Katsuno, S. Li, T. Maruyama, S. Savkar, M. Simone, G. Shen, R. Swami, and D. Tovey: "Microarchitecture of HaL's CPU," Proc. COMPCON, San Francisco, CA, March 1995, pp. 259-266. [SPARC64]
Patt, Y., S. Melvin, W-M. Hwu, M. Shebanow, C. Chen, and 1. Wei: "Run-time generation of HPS microinstructions from a VAX instruction stream," Proc. MICRO-19, New York, December 1986, pp. 75-8\.
Peleg, A., and U. Weiser: "MMX technology extension to the Intel architecture," IEEE Micro, 16,4, August 1996, pp. 42-50.
Peng, C. R., T. Petersen, and R. Clark: "The PowerPC architecture: 64-bit power with 32-bit compatibility," Proc. COMPCON, San Francisco, CA, March 1995, pp. 300-307.
Popescu, V., M. Schultz, J. Spracklen, G. Gibson, and B. Lightner: 'The Metaflow architecture," IEEE Micro, 11,3, June 1991, pp. 10-23.
Potter, T., M. Vaden, 1. Young, and N. Ullah: "Resolution of data and control-flow dependencies in the PowerPC 601 ," IEEE Micro, 14, 5, October 1994, pp. 18- 29.
Poursepanj, A., D. Ogden, B. Burgess, S. Gary, C. Dietz, D. Lee, S. Surya, and M. Peters:
"The PowerPC 603 Microprocessor: Performance analysis and design tradeoffs," Proc.
COMPCON, San Francisco, CA, Feb.-March 1994, pp. 316-323.
Preston, R., et aI., "Design of an 8-wide superscalar RISC microprocessor with simultaneous multithreading," Proc. ISSCC, San Francisco, CA, February 2002, p. 334. [Alpha 21464]
Pugh, E., L. Johnson, and J. Palmer: IBM's 360 and Early 370 Systems. Cambridge, MA:
MIT Press, 1991.
Rau, B., C. Glaeser, and R. Picard: "Efficient code generation for horizontal architectures:
Compiler techniques and architectural support," Proc. ISCA, Austin, TX, April 1982, pp. 131-139. [ESL machine, later Cydrome Cydra-5] Reilly, M.: "Designing an Alpha processor," IEEE Computer, 32, 7, July 1999, pp. 27-34.
Riseman, E., and C. Foster: "The inhibition of potential parallelism by conditional jumps," IEEE Trans. on Computers, C-21 , 12, December 1972, pp. 1405-1411.
Ryan, B.: "Ml challenges Pentium," Byte, 19, I , January 1994a, pp. 83-87 . [Cyrix 6x86] Ryan, B.: "NexGen Nx586 straddles the RISC/CISC divide," Byte, 19, 6, June 1994b, p. 76.
Schorr, H.: "Design principles for a high-performance system," Proc. Symposium on Computers and Automata, New York, April 1971, pp. 165-192. [IBM ACS] Seznec, A. , S. Felix, V. Krishnan, and Y. Sazeides: "Design tradeoffs for the Alpha EV8 conditional branch predictor," Proc. ISCA , Anchorage, AK, May 2002, pp. 295-306.

Shebanow, M., "SPARC64 V: A high performance and high reliability 64-bit SPARC processor," videotaped lecture, December 1999, http://murl.microsoft.comILectureDetails.asp? 455.
Shen, J. P., and A. Wolfe: "Superscalar processor design," Tutorial, ISCA, San Diego, CA, May 1993.
Shippy, D.: "POWER2+ processor," Hot Chips VI, videotaped lecture, August 1994, http:// murl.microsoft.comILectureDetails.asp? 495.
Shriver, B., and B. Smith: The Anatomy of a High-Peiformance Microprocessor: A Systems Perspective. Los Alamitos, CA: IEEE Computer Society Press, 1998. [AMD K6-1II] Simone, M., A.
Ramaswami, M.
tradeoffs in using
processor," Proc.
SPARC64]

Essen, A. Ike, A. Krishnamoorthy, T. Maruyama, N. Patkar, M.
Shebanow, V. Thirumalaiswamy, and D. Tovey: "Implementation a restricted data flow architecture in a high performance RISC microISCA, Santa Margherita Ligure, Italy, May 1995, pp. 151-162. [HaL 
Sites, R.: "Alpha AXP architecture," Communications of the ACM, 36, 2, February 1993, pp.33-44.
Smith, J. E. : "Decoupled access/execute computer architectures," Proc. ISCA, Austin, TX, April 1982, pp. 112-119.
Smith, J. E.: "Decoupled access/execute computer architectures," ACM Trans. on Computer Systems, 2,4, November 1984, pp. 289-308.
Smith, J. E., G. Dermer, B. Vanderwarn, S. Klinger, C. Rozewski, D. Fowler, K. Scidmore, and J. Laudon: "The ZS-1 central processor," Proc. ASPLOS-II, Palo Alto, CA, October 1987,pp.199-204.Monticello, IL, October 1982, pp. 577-586.
Smith, J. E., and S. Weiss: "PowerPC 601 and Alpha 21064: A tale of two RISCs," IEEE Computer, 27,6, June 1994, pp. 46-58.
Smith, J. E., S. Weiss, and N. Pang: "A simulation study of decoupled architecture computers," IEEE Trans. on Computers, C-35, 8, August 1986, pp. 692-702.
Smith, M., M. Johnson, and M. Horowitz: "Limits on multiple instruction issue," Proc.
ASPLOS-lll, Boston, MA, April 1989, pp. 290-302.
Soltis, F. Fortress Rochester: The Inside Story of the IBM iSeries. Loveland, CO: 29th Street Press, 2001.
Song, P., "HAL packs SPARC64 onto single chip," Microprocessor Report, 11, 16, December 8, 1997a, p. 1.
Song, P., "IBM' s Power3 to replace P2SC," Microprocessor Report, 11, 15, November 17, 1997b, pp. 23- 27.
Song, S., M. Denman, and J. Chang: "The PowerPC 604 RISC microprocessor," IEEE Micro, 14, 5, October 1994, pp. 8-17.
Special issue: "The IBM RISC Systeml6000 processor," IBM Journal of Research and Development, 34, 1, January 1990.
Special issue: " Alpha AXP architecture and systems," Digital Technical Journal, 4, 4, 1992.
Special issue: "Digital 's Alpha chip project," Communications of the ACM, 36, 2, February 1993.
Special issue: "The making of the PowerPC," Communications of the ACM, 37,6, June 1994.
Special issue: "POWER2 and PowerPC architecture and implementation," IBM Journal of Research and Development, 38,5, September 1994.
Special issue: Hewlett-Packard Journal, 46, 2, April 1995. [HP PA 7100LC] Special issue: Hewlett-Packard Journal, 48, 4, August 1997. [HP PA 8000 and PA 8200] Special issue: IBM Journal of Research and Development, 46, 1,2002. [POWER4] Sporer, M., F. Moss, and C. Mathias: "An introduction to the architecture of the Stellar graphics supercomputer," Proc. COMPCON, San Francisco, CA, 1988, pp. 464-467. [GS-1000] Sussenguth, E.: "Advanced Computing Systems," video-taped talk, Symposium in Honor of John Cocke, IBM T. J. Watson Research Center, Yorktown Heights, NY, June 18, 1990.

Taylor, S., et al.: "Functional verification of a multiple-issue, out-of-order, superscalar Alpha microprocessor," Proc. Design Automation Coni , San Francisco, CA, 1998, pp. 638-643.
Tendler, J. , J. Dodson, 1. Fields, H. Le, and B. Sinharoy, "POWER4 system microarchitecture," IBM Journal of Research and Development, 46, 1,2002, pp. 5-26.
Thompson, T., and B. Ryan : "PowerPC 620 soars," Byte, 19, 11 , November 1994, pp. 113-120.
Tjaden, G., and M. Flynn: "Detection of parallel execution of independent instructions," IEEE Trans. on Computers, C-19, 10, October 1970, pp. 889-895.
Tremblay, M., D. Greenly, and K. Normoyle: "The design of the microarchitecture of the UltraSPARC I," Proc. IEEE, 83, 12, December 1995, pp. 1653-1663.
Tremblay, M., and J. M. O'Connor: "UltraSPARC I: A four-issue processor supporting multimedia," IEEE Micro, 16,2, April 1996, pp. 42-50.
Turumella, B., et al.: "Design verification of a super-scalar RISC processor," Proc. Fault Tolerant Computing Symposium, Pasadena, CA, June 1995, pp. 472-477. [HaL SPARC64] Ullah, N., and M. Holle: "The MC88110 implementation of precise exceptions in a superscalar architecture," ACM Computer Architecture News, 21 , 1, March 1993, pp. 15-25.

Undy, S., M. Bass, D. Hollenbeck, W. Kever, and L. Thayer: "A low-cost graphics and multimedia workstation chip set," IEEE Micro, 14,2, April 1994, pp. 10-22. [HP 7100LC] Vasseghi, N., K Yeager, E. Sarto, and M. Seddighnezhad: "200-MHz superscalar RISC microprocessor," IEEE Journal o/Solid-State Circuits, 31, 11, November 1996, pp. 1675-1686.

[MIPS RIOOOO]
Vegesna, R.: "Pinnacle-I: The next generation SPARC processor," Proc. COMPCON, San Francisco, CA, February 1992, pp. 152-156. [HyperSPARC] Wayner, P.: "SPARC strikes back," Byte, 19, ll, November 1994, pp. 105-112.
[UitraSPARC]
Weiss, S. , and J. E. Smith: POWER and PowerPC. San Francisco, CA: Morgan Kaufmann, 1994.
White, S.: "POWER2: Architecture and performance," Proc. COMPCON, San Francisco, CA, Feb.-March 1994, pp. 384-388.
Wilcke, W .: "Architectural overview of HaL systems," Proc. COMPCON, San Francisco, CA, March 1995, pp. 251-258. [SPARC64]
Williams, T ., N. Patkar, and G. Shen: "SPARC64: A 64-b 64-active-instruction out-oforder-execution MCM processor," IEEE Journal o/Solid-State Circuits, 30, 11, November 1995, pp. 1215-1226.
Wilson, J., S. Melvin, M. Shebanow, W.-M. Hwu, and Y. Patt: "On tuning the microarchitecture of an HPS implementation of the VAX," Proc. Micro-20, Colorado Springs, CO, December 1987, pp. 162-167. [This proceeding is hard to obtain, but the paper also appears in reduced size in SIGMICRO Newsletter, 19,3, September 1988, pp. 56-58.] Yeager, K : "The MIPS Rl0000 superscalar microprocessor," IEEE Micro, 16, 2, April 1996, pp. 28-40.


HOMEWORK PROBLEMS
PS.l Although logic design techniques and microarchitectural tradeoffs can be treated as independent design decisions, explain the typical pairing of synthesized logic and a brainiac design style versus full custom logic and a speed-demon design style.
PS.2 In the late 1950s, the Stretch designers placed a limit of 23 gate levels on any logic path. As recently as 1995, the UltraSPARC-I was designed with 20 gate levels per pipe stage. Yet many designers have tried to drastically reduce this number. For example, the ACS had a target of five gate levels of logic per stage, and the Ultra-SPARC-III uses the equivalent of eight gate levels per stage. Explain the rationale for desiring low gate-level counts. (You may also want to examine theHinton et al. [2001].) 

PS.3 Prepare a table comparing the approaches to floating-point arithmetic exception handling found on these IBM designs: Stretch, ACS, RIOS , PowerPC 601, PowerPC 620, POWER4.
PS.4 Consider Table 8-2. Can you identify any trends? If so, suggest a rationale for each trend you identify.
PS.S Explain the market forces that led to the demise of the Compaq/DEC Alpha. Are there any known blemishes in the Alpha instruction set that make high-performance implementations particularly difficult or inefficient? Is the Alpha tradition of full custom logic design too labor or resource intensive?

PS.6 Compare how the Compaq/DEC Alpha and IBM RIOS eliminated the type of complex instruction pairing rules that are found in the Intel i960 CA.
PS.7 Explain the importance of caches in HP processor designs. How was the assist cache used in the HP 7200 both a surprise and a natural development in the HP design philosophy?
PS.S Find a description of load/store locality hints in the Itanium Processor Family. Compare the Itanium approach with the approaches used in the HP 7200 and MIPS R8000.
PS.9 Consider the IBM RIOS.
(a) The integer unit pipeline design is the same as the pipeline used in the IBM 801. Explain the benefit of routing the cache bypass path directly from the ALU stage to the writeback stage as opposed to this bypass being contained within the cache stage (and thus having ALU results required to flow through the ALU/cache and cache/writeback latches as done in the simple five- and six-stage scalar pipeline designs of Chapter 2). What is the cost of this approach in terms of the integer register file design? (b) New physical registers are assigned only for floating-point loads.

For what types of code segments is this sufficient? (c) Draw a pipeline timing diagram showing that a floating-point load and a dependent floating-point instruction can be fetched, dispatched, and issued together without any stalls resulting.

PS.I0 Why did the IBM RIOS provide three separate logic units, each with a separate register set? This legacy has been carried into the PowerPC instruction set. Is this legacy a help, hindrance, or inconsequential to high-issue-rate PowerPC implementations?of the Intel i960 CA.
PS.12 Is the Intel P6 a speed demon, a brainiac, or both? Explain your answer.
PS.13 Consider the completion/retirement logic of the PowerPC designs. How are the 601 , 620, and POWER4 related?
PS.14 Draw a pipeline timing diagram illustrating how the SuperSPARC processor deals with a delayed branch and its delay slot instruction.
PS.15 The UltraSPARC-I provides in-order completion at the cost of empty stages and additional forwarding paths.
(a) Give a list of the pipe stage destinations for the forwarding paths that must accompany an empty integer pipeline stage.
(b) List the possible sources of inputs to the multiplexer that fronts one leg of the ALU in the integer execution pipe stage. (Note: This is more than the empty integer stages.)
(c) Describe how the number of forwarding paths was reduced in the UItraSPARC-III, which had even more pipeline stages.
