第2章

# 流水线处理器

章节大纲
* 2.1流水线基础知识 
* 2.2流水线处理器设计 
* 2.3深度流水线处理器 
* 2.4摘要
* 参考文献
* 家庭作业问题

流水线技术是一种功能强大的实现技术，可在不需要大量复制硬件的情况下提高系 它在20世纪60年代初首次应用于高端大型机的设计。指令流水线最初是在IBM 7030中引入的，绰号为Stretch计算机[Bloch，1959，Bucholtz，1962]。后来CDC 6600结合了流水线和多功能单元的使用[Thornton，1964]。

在20世纪80年代，流水线技术成为RISC处理器设计方法的基石。构成RISC方法的大多数技术直接或间接地与有效流水线的目标相关。从那时起，流水线技术也有效地应用于CISC处理器。英特尔i486是IA32架构的第一个流水线实现[Crawford，1990]。

Digital VAX和摩托罗拉M68K架构的流水线版本在商业上也非常成功。流水线技术现在被广泛用于指令集处理器的设计中。本章重点介绍（标量）流水线处理器的设计。许多与流水线处理器设计相关的方法和技术，例如用于危险检测和分辨的管道互锁机制，是超标量处理器设计的基础。


目前的趋势是走向非常深的管道。管道深度从不到10增加到超过20.深管道是实现非常高的时钟频率所必需的。这是获得更高处理器性能的非常有效的手段。有迹象表明这种趋势将持续下去。




## 2.1 Pipelining Fundamentals

本节介绍流水线的动机和基本原则。
历史上，管道有两种主要类型：算术流水线和指令流水线。虽然指令流水线是本书的重点，但我们首先检查算术流水线示例。算术管道更容易说明一系列基于流水线设计原理的理想假设。
我们将这些理想化的假设称为流水线理想主义。它正在处理这些理想化假设与指令流水线中的现实考虑之间的差异，这使得流水线处理器设计如此有趣。



### 2.1.1流水线设计
本小节介绍了流水线设计的基本概念。介绍了流水线的动机和局限性。由Peter Kogge提出的从硬件设计角度出发的最佳流水线理论模型被描述为[Kogge，1981]。


#### 2.1.1.1动机。 
流水线操作的主要动机是增加系统的吞吐量，而硬件几乎没有增加。系统的吞吐量或带宽是根据每单位时间执行的任务数量来衡量的，它表征系统的性能。对于一次对一个任务进行操作的系统，吞吐量P等于1I D，其中D是任务的等待时间或与系统执行任务相关的延迟。如果有许多任务需要使用相同的系统，则可以通过流水线操作增加系统的吞吐量。每项任务的实际延迟仍然保持不变，甚至可能略有增加。

流水线操作涉及将系统划分为多个阶段，并在阶段之间添加缓冲。这些阶段和级间缓冲区构成管道。由原始系统执行的计算被分解为k个子计算，在管道的k个阶段中执行。一旦前一个任务遍历第一阶段，新任务就可以开始进入管道。因此，不是每D单位时间启动一个新任务，而是每个Dlk时间单元可以启动一个新任务，其中k是流水线中的级数，并且k计算的处理现在在流水线中重叠。假设D的原始等待时间被均匀地划分为k个阶段，并且添加的缓冲器不会引入额外的延迟。鉴于要处理的任务总数非常大，流水线系统的吞吐量可能接近非流水线系统的k倍。通过简单地在k级流水线中添加新缓冲区，这种潜在的性能提高了k倍，这是流水线设计的主要吸引力。图2.1说明了k级流水线系统中吞吐量的潜在k倍增加。

到目前为止，我们假设添加级间缓冲区不会引入任何额外的延迟。这不是不现实的。图2.2（a）中所示的Earle锁存器是在IBM 360/91中设计和使用的，用于在流水线乘法单元中的进位保存加法器的各阶段之间进行缓冲。在Earle锁存器中，当时钟C = 1时，输出Z跟随输入D.当时钟变低时，D处的值通过锁存环锁存在Z处，然后输出Z对D处的进一步变化不敏感。 D输入需要适当的保持时间以确保正确锁定。

中间与门确保无故障操作; 此AND门代表的产品术语“涵盖”潜在危险。危险是由同时改变多个信号的竞争条件引起的假脉冲。“或”门的顶部和底部输入可能会在相反的方向上同时发生变化。在这种情况下，如果“或”门没有中间（冗余）输入，则可能会在“或”门的输出端出现寄生脉冲（危险）。Earle闩锁具有这种理想的无干扰操作功能。此外，Earle锁存器可以集成到逻辑功能中，以免引起任何额外的门延迟。图2。图2（b）示出了如何将锁存功能合并到组合逻辑电路的最后两个AND-OR电平中，导致没有用于添加锁存器的额外门延迟。图2.2（b）中的电路执行与图2.2（a）相同的逻辑功能，而不会产生两个额外的门锁延迟用于锁存。栅极扇入的增加可以略微增加通过这些栅极的延迟。




#### 2.1.1.2限制。 
由于在流水线设计中获得的性能与管道的深度（即，级数）成比例，因此最佳设计似乎总是最大化流水线系统的级数。然而，由于时钟约束，对于原始计算可以如何精细地划分成流水线阶段存在物理限制。

流水线的每个阶段都可以看作是一个组合逻辑F，后跟一组锁存器L.信号必须通过F传播并被锁存在L.让TM成为通过F的最大传播延迟，即通过最长的信号路径; 令Tm为通过F的最小传播延迟，即通过最短信号路径的延迟。设TL是正确计时所需的额外时间。延迟1'L可以包括必要的建立和保持时间以确保正确的锁存，以及潜在的时钟偏移，即，在不同锁存器处的时钟边沿的到达时间之间的最差情况差异。如果在时间TI处将第一组信号XI施加到级的输入，那么F的输出必须在TI + TM'处有效。为了在L处正确锁存，


这意味着X 2最早可能到达锁存器的时间必须早于正确锁存XI所需的时间。这种不平等可以改写为

其中T2-TI实际上是最小时钟周期T.因此，时钟周期T必须大于TM -T m + Tu，并且最大时钟速率不能超过1 / T.

基于前述分析，两个因素限制了时钟速率。一个是通过逻辑的最大和最小传播延迟之间的差异，即TM-T m'另一个是正确计时所需的额外时间，即TL。如果所有信号传播路径具有相同的长度，则可以消除第一因素。这可以通过填充短路径来完成。因此，TM-T m接近于零。第二个因素取决于锁存管道阶段结果的需要。适当的锁存需要通过反馈环路传播信号并稳定环路中的信号值。对TL的另一个贡献是最坏情况下的时钟偏差。由于时钟信号的产生和分配到所有锁存器，时钟信号可以在略微不同的时间到达不同的锁存器。在完全同步的系统中，必须在时钟周期中考虑这种最坏情况的时钟偏移。最终，同步系统流水线的深度限制取决于锁存所需的最小时间和与时钟分配网络中的延迟相关的不确定性。




#### 2.1.1.3权衡。 
时钟约束决定了流水线深度的最终物理限制。除了这个限制，当考虑成本或流水线开销时，最大流水线深度可能不是最佳设计。在流水线系统的硬件设计中，必须考虑成本和性能之间的权衡。Peter Kogge提出了流水线设计的成本/性能权衡模型，并在此进行了总结[Kogge，1981]。提出了成本和性能的模型。非流水线设计的成本表示为G.该成本可以是门数，晶体管数或硅片面积。k级流水线设计的成本C等于

C = G + K×L个


其中k是流水线中的级数，L是添加每个锁存器的成本，G是原始非流水线硬件的成本。基于该成本模型，管道成本C是k的线性函数，即管道的深度。基本上，管道的成本相对于管道的深度线性上升。

假设非流水线系统的延迟为T.那么非流水线设计的性能是1 / T，即计算速率。管道设计的性能P可以建模为1 /（TI k + S），其中T是原始非管线设计的延迟，S是由于添加锁存器而导致的延迟。
假设原始等待时间T可以均匀地划分为k个阶段，（T / k + S）是与每个阶段相关联的延迟，因此是流水线的时钟周期。
因此，1 /（T / k + S）等于时钟速率和流水线设计的吞吐量。因此，流水线设计的性能是

注意，P是k的非线性函数。

鉴于这些成本和性能模型，成本/性能比的表达式是

此表达式可以重写为 

图2.3中绘制了两组G，L，T和S样本值。
等式（2.6）表示作为k的函数的成本/性能比。可以采用一阶导数并将其设置为等于零，以确定将产生最小成本/性能比的k的值。如公式（2.7）所示，该k值就其他参数而言是最佳流水线深度。

给定k的最佳值的这种表达式，具有k <kopt的流水线设计可以被认为是管道不足，因为进一步的流水线操作或增加管道深度是有益的并且通过性能的提高来增加成本是合理的。另一方面，k> kopt表示超流水线设计，其中流水线成本增加导致性能回报减少。上述权衡模型完全基于硬件设计考虑; 没有考虑管道的动态行为或正在执行的计算。我们将在2.2节开始讨论这些问题。




### 2.1.2

算术管道示例

管道有两种主要类型：算术流水线和指令流水线。虽然指令流水线设计是本章的重点，但我们将从查看算术流水线示例开始。算术管道清楚地说明了流水线的有效性，而无需处理指令流水线设计中涉及的一些复杂问题。这些复杂的问题将在本章的后续章节中讨论。



#### 2.1.2.1浮点乘法。  
使用流水线浮点乘法器的设计作为示例。这种“复古”板级设计取自Shlomo Waser和Mike Flynn [Waser and Flynn，1982]的经典文本。（尽管这种设计假设了1980技术，但它仍然可以作为说明算术流水线的有效工具。）这种设计假定64位浮点格式使用指数e（8位）的超额128表示法和符号-magnitude分数表示法，尾数为m的隐藏位（57位，包括隐藏位）。

在该设计中实现的浮点乘法算法如下。

1.检查是否有任何操作数为零。如果是，则结果立即设置为零。
2.添加两个特征（指数的物理位模式）并校正多余的128偏差，即e I +（e 2  -  128）。
3.执行m I和m2'两个尾数的定点乘法运算 
4.规范化尾数的乘积，包括向左移一位并将指数递减1.（尾数的归一化表示没有前导零。） 
5.通过向第一个保护位（尾数的最低有效位右侧的位）加1来舍入结果。这实际上是四舍五入。如果尾数溢出，那么尾数必须向右移一位并且指数递增1以维持尾数的归一化表示。

图2.4在功能框图中说明了浮点乘法器的非流水线设计。输入锁存器存储要乘的两个操作数。
在下一个时钟，两个操作数的乘积将存储在输出锁存器中。

定点尾数乘数代表了该设计中最复杂的模块，由三个子模块组成，用于部分产品生成，部分产品减少和最终减少。可以获得每个子模块的集成电路（IC）芯片的数量和以纳秒为单位的传播延迟的硬件复杂性。

* 部分产品生成。可以使用8×8硬件乘法器来同时生成部分乘积。为了生成所有部分乘积，需要34个这样的8×8乘法器。涉及的延迟是125 ns。
* 部分产品减少。生成所有部分产品后，必须将它们减少或求和。称为（5,5,4）计数器的求和电路可用于将每列5位的两列减少为4位和。可以使用具有50ns延迟的1K×4只读存储器（ROM）来实现（5,5,4）计数器。需要三级（5,5,4）计数器来减少所有部分产品。因此，总共需要72个这样的1K x 4 ROM，总延迟为150 ns。
* 最终减少。一旦所有部分产品减少到两个部分产品，就可以使用快速进位Iookahead（CLA）加法器实现最终的减少水平，以产生最终结果。此最终还原步骤需要16个带有CLA和5个4位CLA单元的4位加法器芯片。总共需要21个IC芯片和55 ns的延迟。


尾数部分需要两个附加模块，即用于执行归一化的移位器（2个码片，20-ns延迟）和用于执行舍入的增量器（15个码片，50-ns延迟）。指数部分中的Add / Sub模块需要另外4个芯片; 他们的延迟并不重要，因为他们没有处于关键的延迟路径。分别需要额外的17和10个芯片来实现输入和输出锁存器。非流水线设计中模块的总芯片数和关键延迟总结在表2.1中。

根据表2.1中的表格，浮点乘法器的非流水线设计需要175个芯片，时钟周期为400 ns，时钟频率为2.5 MHz。这意味着非流水线设计可以实现2.5 MFLOPS（每秒百万次浮点运算）的吞吐量。



#### 2.1.2.2流水线浮点乘法器。  
浮点乘法器的非流水线设计可以流水线化以增加其吞吐量。在这个例子中，我们假设子模块中没有流水线; 也就是说，分割成流水线阶段的最细粒度是在子模块级别。我们现在检查与关键延迟路径中的每个（子）模块相关的延迟。这些延迟显示在表2.1的第三列中。部分产品见表2.1

非管道式转向点乘法器设计中的模块的芯片数量和关键延迟。


减少子模块具有最长的延迟，150 ns; 然后，此延迟确定管道中的阶段的延迟。关键路径中的五个（子）模块可以划分为三个相当均匀的阶段，延迟为125 ns（部分产品生成），150 ns（部分产品减少）和125 ns（最终减少，归一化和舍入）。得到的三级流水线设计如图2.5所示。

在确定流水线设计的实际时钟速率时，我们必须考虑时钟要求。假设边沿触发寄存器用于流水线级之间的缓冲，我们必须将时钟边沿寄存器输出延迟增加17 ns，将建立时间5 ns添加到150 ns的级延迟。这导致最小时钟周期为172 ns。因此，新的流水线设计可以以5.8 MHz的速率计时，而不是以2.5 MHz的速率进行计时。
这表示吞吐量增加2.3倍。但请注意，执行每次乘法的延迟时间略有增加，从400增加到516ns。

流水线设计所需的唯一额外硬件是边缘触发寄存器芯片，用于在流水线级之间进行缓冲。在最初的175个IC芯片之上，还需要额外的82个IC芯片。使用芯片数量作为硬件复杂性的衡量标准，总共257个IC芯片在硬件复杂性方面增加了45％。硬件成本增加45％导致性能提升130％。显然，这种浮点乘法器的三级流水线设计是对原始非流水线设计的一次胜利。

此示例假定使用现成部件的板级实现。
鉴于当今的芯片技术，整个设计可以轻松实现为芯片上的小型模块。虽然浮点乘法器的板级实现可能被视为过时，但此示例的目的是使用已发布的具有实际延迟和硬件成本参数的特定设计简洁地说明流水线的有效性。实际上，图2.3中的上部曲线反映了此示例中的参数。




### 2.1.3流水线理想主义 
回想一下，k阶段流水线设计的动机是实现吞吐量k倍的增加，如图2.1所示。然而，在前面的例子中，三级流水线浮点乘法器仅实现了吞吐量增加2.3倍。没有达到吞吐量三倍增长的主要原因是k级流水线设计的吞吐量k倍增加代表理想情况，并且基于三个理想化的假设，我们称之为流水线理想主义。对管道衬砌理想主义的理解对于流水线设计的理解至关重要。在实际管道中不可避免地偏离这种理想主义使得流水线设计具有挑战性。处理这种理想主义 - 现实主义差距的解决方案包括流水线设计的有趣技术。

1.统一的子计算。要执行的计算可以均匀地划分为均匀延迟子计算。

2.相同的计算。对大量输入数据集重复执行相同的计算。
3.独立计算。相同计算的所有重复都是相互独立的。


#### 2.1.3.1统一子计算。  
流水线理想主义的第一点表明，管道计算可以均匀地划分为k个一致性子计算。这意味着原始设计可以均匀地划分为k个平衡（即具有相同的延迟）流水线阶段。如果原始计算的等待时间以及非流水线设计的时钟周期是T，那么k级流水线设计的时钟周期恰好是Tlk，这是每个k级的等待时间。给定这种理想化的假设，由于时钟速率的k倍增加，实现了吞吐量的k倍增加。

在实际的流水线设计中，这种理想化的假设可能并非如此。可能无法将计算划分为完美平衡的阶段。
我们在浮点乘法器示例中看到，原始计算的400 ns的延迟分为三个阶段，延迟分别为125,150和125 ns。显然，原始延迟未被均匀划分为三个平衡阶段。由于流水线设计的时钟周期由具有最长延迟的阶段决定，因此具有较短延迟的阶段将导致一些低效率或惩罚。在我们的例子中，第一和第三阶段的效率低至25 ns; 我们称之为管道阶段内的这种低效率，即管道阶段的内部分裂。由于这种内部碎片，执行相同计算所需的总延迟将从T增加到TJ，并且流水线设计的时钟周期将不再是Tlk而是T / k。

存在二次隐含假设，即，在流水线级之间引入缓冲器不会引入额外的延迟，并且不需要额外的延迟来确保流水线级的适当时钟。同样，这种假设在实际设计中可能并非如此。在我们的示例中，需要额外的22 ns来确保流水线级的正确时钟，这导致三级流水线设计的循环时间为172 ns。三级流水线设计的理想周期时间为133 ns。时钟周期172和133 ns之间的差异导致了吞吐量理想化三倍增长的不足。

流水线理想主义的第一点基本上假设两件事：（1）由于原始计算划分为多个子计算而没有引入低效率; （2）由于引入级间缓冲器和时钟要求而没有引起额外的延迟。在芯片级设计中，通过采用类似于Earle锁存器的锁存器，可以最小化正确流水线时钟引起的额外延迟。将计算划分为平衡流水线阶段是流水线设计的第一个挑战。目标是尽可能平衡实现阶段，以尽量减少内部碎片。

由于不完全平衡的管道阶段造成的内部破碎是偏离管道衬砌理想主义的第一点的主要原因。这种偏差成为管道开销的一种形式，并导致k阶段流水线设计中吞吐量理想化k倍增加的不足。



#### 2.1.3.2相同的计算。  
流水线理想主义的第二点表明，管道将执行相同计算的许多重复。
对多组输入数据重复相同的计算; 每次重复都需要由流水线级提供的相同的子计算序列。
对于我们的浮点乘法器示例，这意味着要将多对浮点数相乘，并且每对操作数通过相同的三个管道阶段发送。基本上，这个假设意味着每次重复计算都会使用所有流水线阶段。这对我们的例子来说确实如此。

这个假设适用于浮点乘法器示例，因为此管道仅执行一个函数，即浮点乘法。如果管道设计为执行多个功能，则此假设可能不成立。例如，可以设计算术流水线以执行加法和乘法。在多功能流水线中，并非流水线支持的每个功能都需要所有流水线级。可能需要不同的流水线级子集来执行每个功能，并且每个计算可能不需要所有流水线级。由于数据集序列以同步方式遍历流水线，因此一些数据集将不需要某些流水线阶段，并且在这些阶段期间将有效地空闲。这些未使用或空闲的流水线级引入了另一种形式的流水线效率低下，可称为流水线级的外部碎片。与内部碎片类似，外部碎片是管道开销的一种形式，应在多功能管道中最小化。对于流水线浮点乘法器示例，没有外部碎片。

流水线理想主义的第二点有效地假设所有流水线阶段都被使用。除了没有外部碎片的含义之外，这种理想化的假设还意味着要处理许多数据集。第一个数据集需要k个周期才能到达管道的最后一个阶段; 这些循环称为管道填充时间。在最后一个数据集进入第一个流水线阶段后，需要额外的k个周期来排空流水线。在管道填充和排放时间期间，并非所有阶段都将忙碌。

假设处理多组输入数据的主要原因是管道填充和排出时间占总时间的很小一部分。
因此，出于所有实际目的，可以考虑流水线阶段总是很忙。实际上，流水线浮点乘法器的吞吐量为5.8 MFLOPS是基于这个假设。


#### 2.1.3.3独立计算。  
流水线理想主义的第三点表明，由流水线处理的计算重复或简单计算是独立的。这意味着同时驻留在流水线级中的所有计算都是独立的，即，在任何一对计算之间没有数据或控制依赖性。该假设允许流水线以“流”模式操作，因为稍后的计算不需要等待由于它们之间的依赖性而完成较早的计算。对于我们的流水线浮点乘法器，这个假设成立。如果有多对操作数要相乘，则一对操作数的乘法不依赖于另一个乘法的结果。这些对可以由流模式的流水线处理。

对于某些管道，这一点可能不成立。稍后的计算可能需要较早计算的结果。这两种计算都可以同时驻留在流水线阶段。如果后面的计算已进入需要结果的流水线阶段，而早期计算尚未到达产生所需结果的流水线阶段，则后面的计算必须在该流水线阶段中等待。这种等待被称为管道失速。如果计算在流水线阶段停止，则所有后续计算也可能必须停止。

管道停滞有效地引入了空闲管道阶段，这实际上是外部分段的动态形式，并导致管道吞吐量的降低。在设计需要处理不一定独立的计算的管道时，目标是生成管道设计，以最小化管道停滞量。



### 2.1.4指令流水线

流水线理想主义的三个要点是关于流水线设计的三个理想化假设。在大多数情况下，在算术流水线中，现实与这些理想化的假设并不相同。然而，对于指导流水线操作，现实主义和理想主义之间的差距更大。正是这种差距的弥合使得指令流水线变得有趣且具有挑战性。在设计流水线处理器时，这三点成为三大挑战。现在简要介绍这三个挑战，并将在2.2节中对流水线处理器设计进行深入探讨。这三个挑战也为跟踪所有流水线处理器设计技术提供了一个很好的路线图。



#### 2.1.4.1指令流水线设计。  
流水线理想主义的三个要点成为设计指令流水线的目标或预期目标。指令的处理成为流水线的计算。必须将此计算划分为一系列相当均匀的子计算，这将导致相当平衡的流水线阶段。处理指令的等待时间称为指令周期; 每个流水线阶段的延迟决定了机器周期。指令周期可以被视为指定指令处理的逻辑概念。具有许多指令的程序的执行涉及重复执行该计算。机器周期是一个物理概念，涉及数字逻辑电路中存储元件的时钟，

我们可以将早期的浮点乘法器视为只有一条指令的非常简单的处理器的例子，即浮点乘法。指令周期涉及浮点乘法的性能; 见图2.6（a）。
基于明显的功能单元边界，该计算可以自然地划分为以下五个子计算。

1.部分产品生成（125 ns）。
2.部分产品减少（150 ns）。
3.最终减少（55 ns）。
4.归一化（20 ns）。
5.舍入（50 ns）。

出于流水线操作的目的，我们将最后三个子计算分组为一个子计算。这导致了图2.6（b）所示的三个流水线阶段。
图2.6（a）的指令周期已映射到图2.6（b）的三个机器周期，从而形成三级流水线设计。我们可以将指令周期称为在指令集架构中指定的架构（逻辑）原语，而机器周期是机器（物理）原语并在微体系结构中指定。图2.6（b）的流水线设计是图2.6（a）中指定的体系结构的实现。

指令流水线操作的主要任务可以表示为逻辑指令周期到物理机器周期的映射。换句话说，由指令周期表示的计算必须被划分为要由流水线级执行的子计算序列。要有效地执行此映射或分区，必须考虑流水线理想主义的三个要点。

**统一子计算。**将指令周期划分为多个机器周期可以称为阶段量化，并且应该执行它以最小化流水线级的内部碎片。如果不对阶段量化采取谨慎措施，引入的内部碎片可能会迅速破坏管道的效率。流水线理想主义的第一点导致指令流水线化的第一个挑战，即需要平衡流水线阶段。管道阶段越平衡，内部碎片就越少。

**相同的计算。**与单功能算术流水线不同，指令流水线本质上是一个多功能流水线，因为它必须能够处理不同的指令类型。不同的指令类型将需要稍微不同的子计算序列，因此需要不同的硬件资源。指令流水线操作的第二个挑战涉及有效合并或统一不同指令类型的不同资源需求。流水线必须能够支持所有指令类型的处理，同时最小化每种指令类型的未使用或空闲流水线级。这基本上相当于最小化外部碎片。

**独立计算。**再次，与处理数组数据的算术流水线不同，指令流水线处理不一定彼此独立的指令。因此，指令流水线必须具有内置机制来检测指令之间依赖性的发生并确保不违反这种依赖性。对施工间依赖性的强制执行可能会以管道摊位的形式受到处罚。回想一下，流水线停顿是外部碎片的动态形式，这会降低流水线的吞吐量。因此。指令流水线的第三个挑战是最小化管道失速。



#### 2.1.4.2指令集架构影响。  
在我们认真解决指令流水线的三大挑战之前。简要考虑指令集架构（IS As）可能对指令流水线的影响可能具有启发性。再次，依次考虑管道衬砌理想主义的三个点。


**统一子计算。**平衡流水线阶段的第一个挑战意味着必须确定一组统一的子计算。查看处理指令所涉及的所有子计算，必须确定需要最长延迟的一个关键子计算，并且不能轻易地进一步划分为多个更精细的子计算。在流水线处理器设计中，一个这样的关键子计算是访问主存储器。由于处理器和主存储器之间的速度差异，存储器访问可以是关键的子计算。为了支持更有效的指令流水线操作，应尽量减少涉及存储器访问的寻址模式，并应采用能够跟上处理器速度的快速高速缓存存储器。

**相同的计算。**统一不同指令类型的资源需求的第二个挑战是RISC架构的主要动机之一。通过降低不同指令类型的复杂性和多样性，统一不同指令类型的任务变得更容易。复杂寻址模式不仅需要额外访问存储器，还会增加资源需求的多样性。将所有这些资源需求统一到一个指令流水线中是非常困难的，并且对于许多具有较少复杂资源要求的指令，所得到的流水线可能变得非常低效。这些指令必须支付外部碎片开销，因为它们未充分利用管道中的各个阶段。

**独立计算。**由于内部构造依赖性而最大限度地减少管道停滞的第三个挑战可能是流水线处理器设计中最迷人的领域。为了正确操作，指令流水线必须检测并强制执行相互依赖的指令。复杂的寻址模式，特别是那些涉及内存访问的模式，由于内存引用说明符，可能使依赖性检测变得非常困难。通常，寄存器依赖性更容易检查，因为寄存器在指令中明确指定。清晰和对称的指令格式可以促进指令的解码和依赖性的检测。依赖关系的检测和执行都可以在编译时静态完成，也可以在运行时动态完成。关于在编译时做什么的决定 运行时涉及动态静态接口（DSI）的定义。DSI的位置引发了有趣和微妙的权衡。这些权衡突出了编译器和（微）架构之间的密切关系以及在处理器设计中考虑两者的重要性。




## 2.2流水线处理器设计

在设计指令流水线或流水线处理器时，流水线理想主义的三个点表现为三个主要的设计挑战。处理这些与理想化假设的偏差成为设计流水线处理器的首要任务。流水线理想主义的三点和流水线处理器设计的三个主要挑战如下：

1.统一子计算=>平衡管道阶段 
2.相同的计算=>统一指令类型 
3.独立计算=>最小化管道停顿 

这三个挑战依次在第2.2.1至2.2.3小节中讨论。这三个挑战为呈现指令流水线技术提供了一个很好的框架。所有流水线处理器设计技术都可视为解决这三个挑战的努力。

### 2.2.1平衡管道阶段

在流水线处理器设计中，要流水线化的计算是在每个指令周期中要完成的工作。典型的指令周期可以在功能上划分为以下五个通用子计算。

1.取指令（IF）
2.指令解码（ID）
3.取得操作数（OF）
4.指令执行（EX）5。操作数存储（OS）

典型的指令周期从获取要执行的下一条指令开始，然后解码该指令以确定该指令要执行的工作。通常指定一个或多个操作数，需要获取它们。这些操作数可以驻留在寄存器或存储器位置，具体取决于所使用的寻址模式。一旦必要的操作数可用，就执行指令指定的实际操作。指令周期以存储由指定操作产生的结果结束。结果可以存储在寄存器或存储器位置，同样取决于指定的寻址模式。在顺序处理器中，然后对下一条指令重复这整个子计算序列。在这五个通用子计算期间，一些副作用也可能作为执行该指令的一部分发生。通常这些副作用采取对机器状态的某些修改的形式。这些对机器状态的更改被称为副作用，因为这些效果不一定在指令中明确指定。五个通用子计算中的每一个的实现复杂性和结果延迟可以根据指定的实际ISA而显着变化。



#### 2.2.1.1阶段量化。  
流水线操作的指令周期的一个自然分区基于五个通用子计算。五个通用子计算中的每一个被映射到流水线级，从而产生五级指令流水线; 见图2.7。我们将此示例管道称为GENERIC（GNR）指令管道。在GNR管道中，逻辑指令周期已映射到五个物理机器周期。机器周期/指令周期比为5反映了流水线的程度，并给出了管道级的粒度的一些指示。

阶段量化的目的是将指令周期划分为平衡流水线阶段，以便最小化流水线阶段中的内部碎片。
阶段量化可以从指令周期的自然功能划分开始，例如，五个通用子计算。具有短延迟的多个子计算可以被分组为一个新的子计算以实现更平衡的阶段。例如，浮点乘法计算的三个子计算 - 最终简化，归一化和舍入被分组I.指令在图2.6（b）的流水线设计中的一个子计算中。类似地，典型指令周期的五个通用子计算中的一些可以被分组以实现更平衡的阶段。例如，如果指令集架构采用固定指令长度，简单寻址模式和指令格式中的正交字段，那么IF和ID sUbcomputations应该非常简单，并且与其他三个子计算相比相对简单。这两个子计算可以组合成一个新的子计算，从而产生四个子计算，这些子计算在所需的延迟方面更加平衡。基于这四个子计算，可以实现四级指令流水线; 见图2.8（a）。事实上，在MIPS R2000IR3000流水线处理器中采用IF和ID子计算的组合[Moussouris等，1986，Kane，1987]。该方法基本上使用具有最长等待时间的子计算作为参考，并尝试将具有较短延迟的其他子计算分组为具有与参考相当的等待时间的新子计算。这两个子计算可以组合成一个新的子计算，从而产生四个子计算，这些子计算在所需的延迟方面更加平衡。基于这四个子计算，可以实现四级指令流水线; 见图2.8（a）。事实上，在MIPS R2000IR3000流水线处理器中采用IF和ID子计算的组合[Moussouris等，1986，Kane，1987]。该方法基本上使用具有最长等待时间的子计算作为参考，并尝试将具有较短延迟的其他子计算分组为具有与参考相当的等待时间的新子计算。这两个子计算可以组合成一个新的子计算，从而产生四个子计算，这些子计算在所需的延迟方面更加平衡。基于这四个子计算，可以实现四级指令流水线; 见图2.8（a）。事实上，在MIPS R2000IR3000流水线处理器中采用IF和ID子计算的组合[Moussouris等，1986，Kane，1987]。该方法基本上使用具有最长等待时间的子计算作为参考，并尝试将具有较短延迟的其他子计算分组为具有与参考相当的等待时间的新子计算。基于这四个子计算，可以实现四级指令流水线; 见图2.8（a）。事实上，在MIPS R2000IR3000流水线处理器中采用IF和ID子计算的组合[Moussouris等，1986，Kane，1987]。该方法基本上使用具有最长等待时间的子计算作为参考，并尝试将具有较短延迟的其他子计算分组为具有与参考相当的等待时间的新子计算。基于这四个子计算，可以实现四级指令流水线; 见图2.8（a）。事实上，在MIPS R2000IR3000流水线处理器中采用IF和ID子计算的组合[Moussouris等，1986，Kane，1987]。该方法基本上使用具有最长等待时间的子计算作为参考，并尝试将具有较短延迟的其他子计算分组为具有与参考相当的等待时间的新子计算。
这将导致更粗粒度的机器循环和更低程度的流水线操作。

不是将子计算与短延迟相结合，而是采取相反的方法来平衡流水线阶段。具有超长延迟的给定子计算可以进一步划分为具有较短延迟的多个子计算。该方法使用具有最短等待时间的子计算作为参考，并尝试将长延迟子计算细分为许多具有与参考相当的延迟的精细化子计算。这将导致更细粒度的机器周期和更高程度的流水线操作。例如，如果ISA采用复杂的寻址模式，其可能涉及访问OF和OS子计算的存储器，则这两个子计算可能产生长的延迟，因此可以进一步细分为多个子计算。
另外，在EX子计算中要进行的一些操作可能非常复杂，并且还可以进一步细分为多个子计算。
图2.8（b）说明了具有II级设计的这种指令流水线。OF和OS子计算都映射到三个流水线级，而IF和EX子计算映射到两个流水线级。本质上，ID子计算用作实现平衡阶段的参考。

提出用于阶段量化的两种方法是（1）将多个子计算合并为一个，以及（2）将子计算细分为多个子计算。两种方法的组合也可用于指令流水线的设计。如前面的讨论所示，指令集架构可能对阶段量化产生重大影响。在所有情况下，阶段量化的目标是最小化整体内部碎片。例如，假设五个通用子计算的总延迟为280 ns，图2.8（a）的4阶段设计和图2.8（b）的ll阶段设计的最终机器周期时间为80，分别为30 ns。所以，4级流水线的总延迟为320 ns（SO ns x 4），11级流水线的总延迟为330 ns（30 ns x II）。新的总延迟与2S0 ns的原始总延迟之间的差异表示内部碎片。
因此，4级设计的内部碎片为40 ns（320 ns  -  2S0 ns），II级设计的内部碎片为50 ns（330 ns  -  2S0 ns）。可以得出结论，由于内部碎片导致较少的开销，4级设计比II级设计更有效。当然，II级设计的吞吐量是非流水线设计的9.3（2S0 ns / 30 ns）倍，而4级设计的吞吐量仅为非流水线设计的3.5（2S0 nsf SO ns）倍。从两种设计中可以看出，内部碎片分别阻碍了II级和4级管道的理想吞吐量增加11和4的因子。



#### 2.2.1.2硬件要求。  
在最现实的工程设计中，目标不仅仅是实现最佳性能，而是实现最佳性能/成本比。因此，除了简单地最大化指令流水线的吞吐量（性能）之外，还必须考虑硬件要求（成本）。通常，较高程度的流水线操作将导致硬件要求方面的成本增加。显然，由于管道阶段之间的额外缓冲，增加了成本。我们已经在2.1.1.3节中提到的模型中已经看到，由于管道阶段之间的缓冲开销，进一步的流水线操作会产生收益递减的点。除了这种缓冲开销之外，对于高度流水线设计还有其他更重要的硬件要求。

在评估指令流水线的硬件要求时，首先要记住的是，对于k阶段指令流水线，在最坏的情况下，或者在性能方面实际上是最好的情况，在流水线中同时存在k个指令。在每个流水线阶段将驻留一条指令，总共有k条指令都处于指令周期的不同阶段。因此，整个流水线必须具有足够的硬件来支持k个流水线级中的k个指令的并发处理。硬件要求分为三类：（1）每个阶段中控制和数据操作所需的逻辑，（2）支持多级并发寄存器访问的寄存器文件端口，以及（3）支持并发内存访问的内存端口通过多个阶段。

我们首先检查图2.S（a）的四阶段指令流水线。假设一个加载/存储架构，典型的寄存器寄存器指令需要在第一级读取两个寄存器操作数，并将结果存储回第四级的寄存器。加载指令需要在第二阶段从存储器读取，而存储指令需要在第四阶段写入存储器。结合所有四个阶段的要求，将需要具有两个读端口和一个写端口的寄存器文件，并且将需要能够在每个机器周期中执行一次存储器读取和一次存储器写入的数据存储器接口。另外，第一阶段需要在每个周期中从指令存储器读取以进行指令获取。如果使用统一（指令和数据）存储器，

可以对图2.8（b）的II级指令流水线进行类似的硬件要求分析。为了适应慢速指令存储器，IF通用子计算被细分并映射到两个流水线级，即IFI和IF2级。指令获取在IFI中启动并在IF2中完成。即使指令获取需要两个机器周期，它也是流水线的; 也就是说，当第一条指令在IF2中完成提取时，第二条指令可以在IF1中开始提取。这意味着指令存储器必须能够在每个机器周期中通过IF1和IF2流水线级支持两个并发访问。类似地，OF和OS通用子计算到三个流水线阶段的映射每个都意味着在任何时候管道中最多可能有六条指令，所有在访问数据存储器的过程中。因此，数据存储器必须能够支持六个独立的并发访问，而不会在每个机器周期中发生冲突。这可能需要六端口数据存储器。此外，如果指令存储器和数据存储器统一到一个存储器单元中，则可能需要八端口存储器单元。
这种多端口存储器单元的实现非常昂贵。较便宜的解决方案，例如使用具有多个存储体的交叉存储器，试图模拟真正的多端口功能通常无法始终保证无冲突的并发访问。

随着流水线的程度或流水线深度的增加，支持这种流水线所需的硬件资源量显着增加。硬件资源的最显着增加是支持对这些数据存储单元的并发访问的增加程度所需的寄存器文件和存储器单元的附加端口。此外，为了适应长存储器访问延迟，存储器访问子计算必须是流水线的。但是，访问超过两个机器周期的内存访问的物理流水线操作可能会变得非常复杂，并且经常无冲突的并发访问必须受到损害。



#### 2.2.1.3示例指令管道。  
这里给出了两个商用流水线处理器的级量化，以提供实际指令流水线的说明。MIPS R20001R3000 RISe处理器采用五级指令流水线，如图2.9（a）所示。MIPS架构是一种加载/存储架构。IF和ID通用子计算被合并到IF阶段，这将需要在每个机器周期中读取一个存储器（I-cache）。OF通用子计算在RD和MEM阶段中执行。对于仅访问寄存器操作数的ALU指令，操作数提取在RD阶段完成，需要读取两个寄存器。对于加载指令，操作数提取还需要访问存储器（D-cache），并在MEM阶段执行，MEM阶段是管道中唯一可以访问D-cache的阶段。OS通用子计算在MEM和WB阶段中执行。存储指令必须访问D-cache，并在MEM阶段完成。ALU和加载指令将其结果写回WB阶段的寄存器文件。

MIPS处理器通常使用单独的指令和数据缓存。在每个机器周期中，R2000 / R3000管道必须支持IF阶段读取的一个I-cache的并发访问，以及MEM阶段的一个D-cache读取（用于加载指令）或写入（用于存储指令）。请注意，使用拆分缓存配置时，I缓存和D缓存都不需要多端口化。另一方面，如果指令和数据都存储在同一缓存中，则统一缓存将需要双端口以支持此管道。寄存器文件必须提供足够的端口以支持RD级的两次寄存器读取和WB级在每个机器周期中的一次寄存器写入。

图2.9（b）显示了AMDAHL 470V17的12级指令流水线。IF通用子计算在前三个阶段实施。
由于必须支持复杂的寻址模式，OF通用子计算被映射为四个阶段。EX和OS通用子计算都分为两个流水线阶段。在该12级流水线的阶段1中，计算下一个顺序指令的地址。阶段2启动高速缓存访问以读取指令; 阶段3将来自高速缓存的指令加载到I单元（指令单元）。阶段4解码指令。在第5阶段读取两个通用寄存器; 这些寄存器用作地址寄存器。阶段6计算内存中操作数的地址。阶段7启动缓存访问以读取内存操作数; 阶段8将操作数从高速缓存加载到I单元中，并且还读取寄存器操作数。阶段9和10是E单元（执行单元）中的两个执行阶段。在阶段11中，对计算结果执行错误检查。最终结果存储在阶段12的目标寄存器中。

该12级流水线必须支持在每个机器周期中由级5和一级寄存器12写入的两个寄存器读取的并发访问，以及在每个机器周期中由级2,3,7和8的四个高速缓冲存储器读取。这种流水线处理器的内存子系统显然比MIPS R2000 / R3000管道复杂得多。

流水线处理器设计的当前趋势是更高的流水线度，更深的管道深度。这样可以生成更细粒度的流水线级，可以以更高的速率进行计时。虽然第一代流水线RISC处理器中有四到五个阶段，但十阶段的指令流水线正变得司空见惯。还存在实现具有不同阶段数的多个管道的趋势。这是超标量处理器设计的主题，将在第4章中讨论。



### 2.2.2统一指令类型流水线理想主义的第二点假设管道重复执行相同的计算。 
对于大多数指令流水线而言，这种重复相同计算的理想化假设并不成立。当指令流水线重复处理指令时，涉及不同类型的指令。尽管指令周期一遍又一遍地重复，但指令周期的重复可能涉及不同指令类型的处理。

不同的指令类型具有不同的资源要求，并且可能不需要完全相同的子计算序列。指令流水线必须能够支持不同的要求，并且必须提供所有指令类型所需的所有子计算的超集。每种指令类型可能不需要指令流水线中的所有流水线级。对于每种指令类型，不必要的流水线阶段成为该指令类型的低效率或开销的形式; 这种低效率或开销在第2.1.3.2节中被称为管道的外部碎片。统一指令类型的目标，即流水线理想主义的第二点产生的关键挑战，是最小化所有指令类型的外部分段。



#### 2.2.2.1指令类型的分类。  

要执行计算，计算机必须执行三个通用任务：

1.算术运算
2.数据移动
3.指令排序

这三个通用任务通过处理器中的指令处理来执行。算术运算任务涉及对指定的操作数执行算术和逻辑运算。这是执行计算最明显的部分，通常等同于计算。处理器可以支持各种算术运算。数据移动任务负责在存储位置之间移动操作数和结果。通常存在存储位置的层次结构，并且使用显式指令来在这些位置之间移动数据。指令排序任务负责指令的排序。通常，计算在由许多指令组成的程序中指定。计算的性能涉及一系列指令的处理。指令的顺序或程序流程可以由指令本身明确指定。

如何将这三个通用任务分配给ISA的各种指令是指令集设计的关键组成部分。可以指定一个非常复杂的指令，实际执行所有这三个通用任务。在典型的水平微编码机器中，每个微指令都具有用于指定所有这三个通用任务的字段。在称为复杂指令集计算机（CISC）体系结构的更传统的指令集体系结构中，许多指令执行这三个通用任务中的多于一个。

受20世纪80年代RISC研究的影响，最新的指令集架构都有一些共同的属性。这些最新架构包括Hewlett-Packard的Precision架构，IBM的Power架构，IBM / Motorola的PowerPC架构以及Digital的Alpha架构。这些现代IS As倾向于具有固定长度指令，对称指令格式，加载/存储架构和简单寻址模式。大多数这些属性与指令流水线非常兼容。在大多数情况下，本书在其示例和插图中采用并假设了这种典型的RISC架构。

在典型的调制解调器RISC架构中，指令集对三个通用任务中的每一个采用专用指令类型; 每条指令只执行三个通用任务中的一个。根据三个通用任务，指令可分为三种类型：

1. ALU指令。用于执行算术和逻辑运算。
2.加载/存储指令。用于在寄存器和存储器位置之间移动数据
3.分支指示。用于控制指令排序。

ALU指令严格地对寄存器操作数执行算术和逻辑运算。只有加载和存储指令才能访问数据存储器。加载/存储和分支指令都采用相当简单的寻址模式。通常，仅支持具有偏移寻址模式的寄存器间接。分支指令通常也支持PC相对寻址模式。在以下三种指令类型的详细说明中，还假设使用指令高速缓存（I高速缓存）和数据高速缓存（D高速缓存）。

可以基于由该指令类型执行的子计算的顺序来指定三种指令类型中的每一种的语义。该规范可以从五个通用子计算（第2.2.1节）开始，随后进一步改进。最终，这些子计算指定了用于硬件实现的寄存器传输序列。为方便起见，ALU指令进一步分为整数和浮点指令。ALU指令的语义在表2.2中规定。

在加载/存储体系结构中，加载和存储指令是访问数据存储器的唯一指令。加载指令将数据从存储器位置移动到寄存器中; 存储指令将数据从寄存器移动到存储器位置。在表2.3中的加载和存储指令的语义规范中，假设唯一的寻址模式是寄存器间接的，具有偏移量。该寻址模式通过将寄存器的内容与指令的立即字段中指定的偏移量相加来计算有效地址。

比较表2.2和表2.3中的规范，我们可以观察到ALU和加载/存储指令类型所需的子计算序列相似但不完全相同。ALU指令不需要生成内存地址。另一方面，除了必须生成有效地址之外，加载/存储指令不必执行显式算术或逻辑运算。它们只是在寄存器和存储单元之间移动数据。即使在加载和存储指令之间也存在细微差别。对于加载指令，OF通用子计算扩展为三个sUbcomputation，包括访问基址的寄存器文件，生成有效地址和访问存储器位置。同样对于商店指令，OS通用子计算包括两个子计算，包括生成有效地址和将寄存器操作数存储到存储器位置。这假设在OF通用子计算期间从寄存器文件访问基址和寄存器操作数。

最后，表2.4列出了指定无条件跳转和条件分支指令的子计算序列。对于分支指令采用与加载/存储指令类似的寻址模式。还可以支持PC相对寻址模式。在该寻址模式中，通过向程序计数器的当前内容添加位移来生成分支（或跳转）指令的目标的地址。通常，该位移可以是正值或负值，以便于前向和后向分支。

检查表2.2到2.4中三种主要指令类型的规范，我们看到所有三种类型的初始子计算非常相似。
但是，后来的子计算存在差异。例如，ALU指令不访问数据存储器，因此对于它们不需要生成存储器地址。另一方面，加载/存储和分支指令类型共享相同的有效地址生成所需的子计算。加载/存储指令必须访问数据存储器，而分支指令必须提供目标指令的地址。我们还看到，对于条件分支指令，除了生成有效地址之外，还必须执行分支条件的评估。这可以简单地检查由先前指令生成的状态位，或者它可能需要在寄存器操作数上执行算术运算，作为分支指令处理的一部分，

基于指令语义的上述规范，可以确定三种主要指令类型的资源需求。虽然三种指令类型在指令的提取和解码方面具有一些共性，但指令类型之间存在差异。指令语义的这些差异将导致资源需求的差异。




#### 2.2.2.2合并资源需求。  
统一不同指令类型的挑战涉及将不同资源需求有效地合并到一个可容纳所有指令类型的指令流水线中。目标是最小化管道所需的总资源，同时最大限度地利用管道中的所有资源。统一不同指令类型的过程可以非正式地表述为由以下三个步骤组成。

1.分析每种指令类型的子计算顺序，和 
确定相应的资源需求。
2.找到指令类型之间的共性，并合并公共子计算以共享相同的管道阶段。
3.如果存在灵活性，在不违反指令语义的情况下，对子计算进行移位或重新排序以便于进一步合并。

统一指令类型的过程可以通过将其应用于表2.2至2.4中指定的指令类型来说明。为简单和清楚起见，不考虑浮点指令和无条件跳转。ALU，加载，存储和分支指令类型的摘要规范在图2.10中重复。这四种指令类型所需的四个子计算序列取自表2.2至2.4，并总结在图2.10左侧的四列中。我们现在通过检查四个子计算序列以及支持它们所需的相关ALU硬件资源，从上到下应用统一过程。此过程导致定义指令管道的各个阶段。

所有四种指令类型共享IF和ID的相同公共子计算。因此，所有四种指令类型的前两个子计算可以容易地合并并用于定义前两个流水线级，标记为IF和ID，用于指令获取和指令解码。
所有四种指令类型也从OF通用子计算的寄存器文件中读取。ALU指令访问两个寄存器操作数。加载和分支指令访问寄存器以获得基址。存储指令访问寄存器以获取寄存器操作数和另一个寄存器作为基址。在所有四种情况下，读取一个或两个寄存器。这些类似的子计算可以合并到管道的第三级，称为RD，用于从寄存器文件中读取最多两个寄存器。寄存器文件必须能够在每个机器周期中支持两个独立和并发读取。

ALU指令需要ALU功能单元来执行必要的算术和逻辑运算。虽然加载，存储和分支指令不需要执行此类操作，但它们确实需要生成用于访问内存的有效地址。可以观察到，地址生成任务可以由ALU功能单元执行。因此，这些子计算可以合并到流水线的第四级，称为ALU，其主要由ALU功能单元组成，用于执行算术/逻辑运算或有效地址生成。

加载和存储指令类型都需要访问数据存储器。
因此，必须将流水线阶段用于此子计算。为此目的，包括标记为MEM的管道的第五阶段。

ALU和加载指令类型都必须将结果写回寄存器文件作为其最后一个子计算。ALU指令将对寄存器操作数执行的操作的结果写入目标寄存器。加载指令将从内存中获取的数据加载到目标寄存器中。ALU指令不需要存储器访问; 因此，理论上可以在ALU阶段之后立即写回目标寄存器。然而，为了与加载指令类型的寄存器回写子计算统一，ALU指令的寄存器回写子计算被延迟一个流水线级并且发生在称为WB的第六流水线级中。这导致MEM流水线级中的ALU指令的一个空闲机器周期。

对于条件分支指令，必须在更新程序计数器之前确定分支条件。由于ALU功能单元用于执行有效地址生成，因此不能用于执行分支条件评估。如果分支条件评估仅涉及检查寄存器以确定它是否等于零，或者它是正还是负，那么只需要一个简单的比较器。可以添加该比较器，并且可以添加它的最早流水线级是ALU级，即在RD级中读取参考寄存器之后。因此，假设采用条件分支，可以使用分支目标地址更新程序计数器的最早流水线阶段是在MEM阶段期间，即，

前面对不同指令类型的资源需求的合并导致了图2.10右侧所示的六级指令流水线。该指令流水线被标识为TYPICAL（TYP）指令流水线，并在本章的其余部分中用作说明工具。除了用于ALU指令的一个空闲流水线级（MEM）之外，存储和分支指令类型也会引起一些外部碎片。存储和分支指令都不需要写回寄存器并且在WB阶段期间空闲。
总的来说，这个六阶段指令管道非常有效。加载指令使用管道的所有六个阶段; 其他三种指令类型使用六个阶段中的五个。

在将不同的指令类型统一到一个指令流水线中时，有三个优化目标。第一种是最小化支持所有指令类型所需的总资源。在某种程度上，目标是确定类似于所有不同资源需求的最小公倍数的流水线。第二个目标是通过不同的指令类型最大化所有流水线级的利用率，换句话说，最小化每个指令类型引起的空闲级。空闲阶段导致外部碎片并导致低效率和吞吐量损失。第三个目标是最小化每种指令类型的总延迟。因此，如果某个特定指令类型的空转阶段是不可避免的，并且在空闲阶段的位置方面存在灵活性，那么最好将它放在管道的末端。这将允许指令有效地提前完成并减少该指令类型的总延迟。



#### 2.2.2.3指令管道实施。  
在六阶段TYP指令流水线中（图2.10），在任何时候，管道中可能同时存在六个不同的指令或“在飞行中”。六条指令中的每条指令都经过一个流水线阶段。寄存器文件必须在每个机器周期中支持两次读取（通过RD级中的指令）和一次写入（通过WB级中的指令）。I-cache必须在每个机器周期中支持一次读取。除非被分支指令中断，否则IF阶段不断递增程序计数器并从I-cache取出下一个顺序指令。D-cache必须在每个机器周期中支持一次内存读取或内存写入。只有MEM阶段访问D-cache; 因此，在任何时候，管道中只有一条指令可以访问数据存储器。

图2.10中的流水线图仅是六阶段TYP指令流水线的逻辑表示，仅说明了六个流水线级的排序。TYP指令流水线的实际物理组织如图2.11所示，这是TYP流水线处理器实现的功能框图。在该图中，明确标识了流水线级之间的缓冲区。两个特定流水线级之间的逻辑缓冲区实际上可能涉及在该图中分布的多个物理缓冲区。按顺序遍历六个流水线级的单个逻辑路径实际上涉及该图中的多个物理路径。必须沿着这些物理路径跟踪每条指令通过管道的进展。

图2.11中的六阶段TYP指令管道的物理组织看起来比实际更复杂。为了帮助消化它，我们可以首先检查管道与寄存器文件和内存子系统的接口。
假设存在分离缓存组织，即用于存储指令和数据的单独缓存，则需要两个单端口缓存，一个I缓存和一个D缓存。
TYP管道的内存子系统接口非常简单有效，类似于大多数标量流水线处理器。IF阶段访问I-cache，MEM阶段访问D-cache，如图2.12所示。I-cache可以支持在每个机器周期中获取一条指令; I-cache中的错误将使管道停滞。在流水线的MEM阶段，加载（存储）指令执行从（到）D缓存的读（写）。注意，这里假设访问D-cache和I-cache的延迟在一个机器周期内。

随着缓存变得更大并且处理器逻辑变得更加流畅，维护缓存的这一个机器周期延迟将变得更加困难。
多端口寄存器文件的接口如图2.13所示。只有RD和WB阶段访问寄存器文件。在每个机器周期中，寄存器文件必须支持RD阶段的两个寄存器读取和WB阶段的一个寄存器写入。因此，需要具有两个读端口和一个写端口的多端口寄存器文件。这样的寄存器文件如图2.13所示。它有三个地址端口，两个数据输出端口和一个数据输入端口，用于在每个机器周期中支持两次读取和一次写入。执行寄存器写入的指令在WB阶段中，并且在执行寄存器的指令之前在RD阶段读取三个机器周期或中间指令。所以，

三端口寄存器文件不是很复杂。但是，随着端口数量增加超过三个，硬件复杂性增加得非常快。由于电路设计的限制，这对于增加写端口的数量尤其如此。具有多达20个端口的多端口寄存器文件是可行的，可以在一些高端微处理器中找到。

如果我们查看图2.10的六级TYP指令流水线的逻辑图，看起来每条指令都流过单个线性路径通过六个流水线级。但是，图2.11的TYP指令流水线的物理组织中的不同物理路径集由不同的指令类型遍历。一些流路段在图2.11中标出，以显示它们与哪些流水线级相关联。基本上，一些管道阶段物理地分布在管道的物理组织图中。

六级TYP指令流水线非常类似于其他两条指令流水线，即MIPS R20001R3000和John Hennessy和David Patterson [2003]在流行教科书中使用的教学DLX处理器。两者都是五阶段管道。MIPS流水线将TYP流水线的IF和ID级组合成一个流水线级。DLX流水线将TYP流水线的ID和RD阶段组合成一个流水线阶段。所有三个管道的其他四个阶段基本相同。TYP管道在本章的其余部分中用作运行示例。



### 2.2.3最小化管道失速 
流水线理想主义的第三点假设管道执行的计算是相互独立的。在k阶段管道中，任何时候都可以进行k种不同的计算。对于指令流水线，任何时候在流水线中可以存在多达k个不同的指令。这些说明可能不是彼此独立的; 事实上，通常在飞行中的指令之间存在依赖关系。在管道中具有独立指令有助于流水线的流动; 也就是说，指令在管道中移动而不会遇到任何管道停顿。当存在指令间依赖性时，必须检测并解决它们。这些依赖性的解决可能需要停止管道。



#### 2.2.3.1程序依赖性和管道危害。在ISA抽象
level，程序被指定为汇编语言指令序列。典型指令可以被指定为函数i：T f-Slop S2，其中指令i的域是DO）= {SI，S2 j，范围是R（i）= {T j，并且来自域的范围由op，操作定义。给定两个指令i和j，其中j跟随i在两个指令的词法排序中，i和j之间可以存在数据依赖性，或者j可以依赖于数据i，表示为i <> j，如果其中一个存在以下三个条件。

第一个条件意味着指令j需要一个在指令i范围内的操作数。这被称为写后读（RAW）或真数据依赖性并且表示为i <> d j。真正的数据依赖性的含义是指令j在指令i完成之前不能开始执行。第二个条件表示i所需的操作数在j的范围内，或者指令j将修改作为i的操作数的变量。这被称为写后读（WAR）或反数据依赖性，并且表示为i <> a j。反依赖的存在要求指令j在执行指令i之前不完整; 否则，指令我将得到错误的操作数。第三个条件表明指令i和j在它们的范围内共享一个公共变量，这意味着两者都将修改同一个变量。这被称为写后写（W AW）或输出数据依赖性并且表示为i OaJ。输出依赖的存在要求指令j在指令i完成之前未完成; 否则，j之后在其域中具有相同变量的指令将收到错误的操作数。显然，read-afterread情况涉及指令i和j访问相同的操作数，并且无论两次访问的相对顺序如何都是无害的。


两个指令的域和范围重叠的这三种可能方式引起两个指令之间的三种可能的数据依赖性，即真（RAW），反（WAR）和输出（WAW）数据依赖。因为在汇编代码中，域和指令范围可以是驻留在寄存器或存储器位置中的变量，所以依赖中的公共变量可以涉及寄存器或存储器位置。我们将它们称为寄存器依赖和存储器依赖。在本章中，我们主要关注寄存器依赖性。图2.14说明了RA W，WAR和W AW寄存器数据的相关性。

除了数据依赖性之外，两个指令之间可以存在控制依赖性。给定指令i和j，其中j跟随i，j是依赖于i的控制，表示为iOj，如果指令j是否被执行则取决于指令i的执行结果。控制依赖性是程序的控制流结构的结果。条件分支指令导致指令排序的不确定性。条件分支之后的指令可以具有对分支指令的控制依赖性。

汇编语言程序由一系列指令组成。该程序的语义假设并依赖于指令的顺序执行。指令的顺序列表意味着相邻指令之间的顺序优先级。如果指令i之后是程序列表中的指令i + 1，则假设执行第一指令i，然后执行指令i + 1。如果遵循这样的顺序执行，则保证程序的语义正确性。更确切地说，由于指令周期可能涉及多个子计算，因此隐含的假设是指令i的所有子计算都在指令i + 1的任何子计算可以开始之前执行。我们将此称为程序的完全顺序执行; 那是，

给定具有k个流水线级的流水线处理器，k个指令的处理在流水线中重叠。一旦指令i完成其第一次子计算并开始其第二次计算，指令i + 1就开始其第一次sUbcomputation。对应于特定指令的k个流水线级的k个子计算与其他指令的子计算重叠。
因此，总顺序执行不成立。虽然总顺序执行足以确保语义正确性，但它不是语义正确性的必要条件。顺序列表指令所暗示的总顺序执行是程序语义的过度规范。确保不违反程序语义的基本要求是不违反所有的指令间依赖性。换句话说，如果在程序列表中i跟随i，则存在两个指令i和j之间的依赖关系，则通过指令i和j读取/写入公共变量必须以原始顺序顺序发生。在流水线处理器中，如果不注意，可能会违反程序依赖性。这种可能违反计划依赖性的行为被称为管道危害。必须检测并解决所有管道危险，以便正确执行程序。



#### 2.2.3.2管道危险的识别。  
一旦将所有指令类型统一到指令流水线中并且定义了所有流水线级的功能，就可以执行对指令流水线的分析以识别可能在该流水线中发生的所有流水线危险。管道危害是管道组织和指令间依赖性的结果。本章的重点是标量指令流水线。根据定义，标量指令流水线是具有以线性顺序顺序组织的多个流水线级的单个流水线。指令根据程序列表指定的顺序进入管道。除非发生流水线停顿，否则指令以锁步方式流过标量指令流水线; 那是，每个指令在每个机器周期进入下一个流水线阶段。对于标量指令流水线，可以确定管道组织中由于数据依赖性而发生管道危险的必要条件。

管道危险可能违反程序依赖性。管道危险可以根据所涉及的程序依赖类型进行分类。
AW AW危险可能违反输出依赖性。WAR危险可能违反反依赖性。RAW危险可能违反真正的数据依赖性。数据依赖涉及通过两个指令读取和/或写入公共变量。为了发生危险，管道中必须存在至少两个管道阶段，其中可以包含两个可以同时访问公共变量的指令。

图2.15说明了管道组织发生WAW，WAR和RAW危险的必要条件。这些必要条件适用于由存储器和寄存器数据依赖性引起的危险（图中仅示出了寄存器依赖性）。为了由于输出依赖性（ba）而发生WA W危险，必须存在至少两个可以对公共变量执行两次同时写入的流水线级; 见图2.15（a）。如果管道中只有一个阶段可以写入该变量，那么就不会发生危险，因为两个写入事实上所有写入该变量的写入都将由该管道阶段根据程序列表指定的原始顺序执行。

图2.15（b）规定，为了发生WAR危险，管道中必须至少存在两个阶段，前一阶段x和后一阶段y，这样阶段x可以写入该变量和阶段y可以读取该变量。为了违反反依赖性iDa j，指令j必须在执行读取或到达阶段y的指令之前执行写入，即到达阶段x。如果该必要条件不成立，则指令j（尾随指令）不可能在指令i完成其读取之前执行写入。例如，如果只存在一个可以对该变量执行读取和写入的管道阶段，则对该变量的所有访问都按原始顺序执行，因此不会发生WAR危险。在执行读取的阶段在流水线中比执行写入的阶段更早的情况下，前导指令i必须在尾随指令j可能在流水线的稍后阶段执行写入之前完成其读取。同样，在这样的管道中不会发生WAR危险。实际上，图2.15中所示的必要条件也是充分条件，可以视为发生WAW，WAR和RAW管道危险的特征条件。

图2.15（c）规定，为了由于真正的数据依赖性iD dj而发生RAW危险，必须存在两个流水线阶段x和y，其中x出现在管道中比y更早，这样阶段x可以执行读取和阶段y可以执行对公共变量的写入。利用该流水线组织，如果尾随指令j在前导指令i到达阶段y之前到达阶段x，则可以违反依赖性iD，ti。类似于用于WAR危险的参数可用于表明如果这种必要条件不成立，则不会发生RAW危险。例如，如果只有一个管道阶段执行所有读取和写入，则执行有效的总顺序执行，并且不会发生危险。如果执行读取的阶段位于管道中的后期，而不是执行写入的阶段，则RAW危险永远不会发生; 原因是前导指令的所有写操作都将在尾随指令执行读操作之前完成。

由于管道危害是由潜在的程序依赖性违规引起的，因此可以通过依次考虑每种依赖类型来制定识别指令管道中可能发生的所有管道危险的系统程序。本章中使用的特定过程按以下顺序检查程序依赖性。

1.内存数据依赖
   1.产出依赖
   2.反依赖
   3.真正的数据依赖
2.注册数据依赖
   1.产出依赖
   2.反依赖
   3.真正的数据依赖
3.控制依赖

我们通过将其应用于六阶段TYP指令流水线来说明此过程。首先，考虑存储器数据依赖性。存储器数据依赖涉及存储在存储器中的公共变量，该公共变量由两个指令访问（读或写）。给定加载/存储架构，内存数据依赖性只能在加载/存储指令之间发生。为了确定是否由于存储器数据依赖性而发生管道危险，必须检查管道对加载/存储指令的处理。假设分割缓存设计，在TYP管道中，只有MEM阶段可以访问D缓存。因此，加载/存储指令对存储器位置的所有访问必须且只能在MEM阶段中进行; 管道中只有一个阶段执行对数据存储器的读写操作。根据图2.15中所示的必要条件，TYP管道中不会出现因内存数据依赖而导致的管道危险。实质上，对数据存储器的所有访问都是顺序执行的，并且所有加载/存储指令的处理都是在整个顺序执行模式中完成的。因此，对于TYP管道，由于存储器数据依赖性，不存在管道危险。

接下来考虑寄存器数据依赖性。要确定由于寄存器数据依赖性而可能发生的管道危险，必须识别可以访问寄存器文件的所有管道阶段。在TYP流水线中，所有寄存器读取都发生在RD阶段，所有寄存器写入都发生在WB阶段。表示为iOo的输出（W AW）依赖性表示指令i和后续指令j都共享相同的目的地寄存器。为了强制执行输出依赖，指令i必须先写入该寄存器; 然后指令j可以写入同一个寄存器。在TYP管道中，只有WB阶段可以执行对寄存器文件的写入。因此，所有寄存器写入由WB阶段按顺序执行; 并根据图2.15（a）的必要条件，

表示i Ba j的反（WAR）依赖性表示指令i正在从作为后续指令j的目的地寄存器的寄存器读取。必须确保指令i在指令j写入该寄存器之前读取该寄存器。反依赖性可能导致流水线危险的唯一方法是，如果尾随指令j可以比指令i执行其寄存器读取更早地执行寄存器写入。这在TYP流水线中是不可能的，因为所有寄存器读取都发生在RD阶段，该阶段在流水线中早于WB阶段，WB阶段是可以发生寄存器写入的唯一阶段。因此，TYP管道中不存在图2.15（b）的必要条件。因此，TYP管道中不会发生由于反依赖导致的管道危险。

可能导致TYP管道中的管道危险的唯一类型的寄存器数据依赖性是真正的数据依赖性。图2.15（c）的必要条件存在于TYP流水线中，因为执行寄存器读取的流水线级RD位于流水线中比执行寄存器写入的WB级更早的位置。真实的数据依赖性，表示为iB dj，涉及写入寄存器的指令和从同一寄存器读取的尾随指令j。如果指令j紧跟在指令i之后，则当j到达RD阶段时，指令i仍将处于ALU阶段。因此，j无法读取作为指令i结果的寄存器操作数，直到我到达WB阶段。要强制执行此数据依赖，必须防止指令j进入RD阶段，直到指令i完成WB阶段。由于在前导指令完成流水线中的寄存器写入阶段之前，尾随指令可以到达流水线中的寄存器读取阶段，因此可能出现真正数据依赖性的RAW流水线危险。

最后，考虑控制依赖性。控制依赖性涉及控制流改变指令，即条件分支指令。条件分支指令的结果确定要提取的下一指令是下一顺序指令还是条件分支指令的目标。基本上有两个候选指令可以遵循条件分支。在指令流水线中，在正常操作下，指令获取级使用程序计数器的内容来获取下一条指令，然后递增程序计数器的内容以指向下一条顺序指令。

通过指令获取阶段在每个机器周期中重复该任务以保持管道填充。当获取条件分支指令时，可能发生该顺序流的潜在中断。如果不采用条件分支，则下一顺序指令的指令获取阶段的继续提取是正确的。但是，如果实际采用了条件分支，那么由指令获取阶段提取下一个顺序指令将是不正确的。问题是在知道分支条件之前无法解决这种模糊性。

控制依赖性可以被视为涉及程序计数器（PC）的寄存器数据（RA W）依赖性的形式。条件分支指令写入PC，而下一条指令的取出涉及读取Pc。
如果采用分支，条件分支指令用目标指令的地址更新PC; 否则，PC将使用下一个顺序指令的地址进行更新。在TYP流水线中，使用目标指令地址更新PC在MEM阶段执行，而IF阶段使用PC的内容来获取下一条指令。因此，IF级对PC寄存器执行读取，并且稍后在管线中发生的MEM级执行对PC寄存器的写入。根据图2.1S（c），IF和MEM级的这种排序满足了涉及PC寄存器的RAW危险发生的必要条件。因此，TYP管道中存在控制危险，并且可以将其视为涉及Pc的RA W危险的一种形式。




#### 2.2.3.3管道危险的解决方案。  
鉴于TYP管道的组织，由于可能发生数据依赖而导致的唯一类型的管道危险是RAW危险。此外，可能发生由于控制依赖性导致的管道危险。所有这些危险都涉及写入寄存器（或PC）的前导指令i和读取该寄存器的尾随指令j。由于存在管道危险，必须提供机制来解决这些危害，即确保不违反相应的数据依赖性。关于TYP流水线中的每个RA W危险，必须确保在写入公共寄存器或危险寄存器之后发生读取。

为了解决RAW危险，必须防止跟踪指令j进入由j读取危险寄存器的流水线级，直到引导指令i已经遍历由i写入危险寄存器的流水线级。这是通过停止流水线的早期阶段，即在执行寄存器读取的阶段之前的所有阶段来实现的，从而防止指令j进入关键寄存器读取阶段。在最坏的情况下，指令j必须被保持的机器周期数等于管道的两个关键级之间的距离，即执行对危险寄存器的读和写的级。在TYP管道的情况下，如果前导指令i是ALU或加载指令，关键寄存器写入阶段是WB阶段，所有尾随指令类型的关键寄存器读取阶段是RD阶段。这两个关键阶段之间的距离是三个周期; 因此，最坏情况的惩罚是三个周期，如表2.5所示。当指令j紧跟在原始程序列表中的指令i之后，会发生最坏情况惩罚; 也就是说，j等于i + 1.在这种情况下，指令j必须在ID级中停止三个周期，并且当指令i退出WB级时，允许三个周期后进入RD级。如果尾随指令j没有紧跟在指令i之后，也就是说，如果在i和j之间存在中间指令，那么惩罚将小于三个周期。假设介入指令不依赖于指令i。因此，所发生的惩罚周期的实际数量等于3-s，其中s是中间指令的数量。例如，如果i和j之间有三条指令，则不会产生惩罚周期。在这种情况下，指令j将进入RD阶段，就像指令i退出WB阶段一样，并且不需要停止来满足RAW依赖性。

对于控制危险，前导指令i是分支指令，其在MEM阶段更新PC。获取尾随指令j需要在IF阶段读取PC。这两个阶段之间的距离是四个周期; 因此，最坏情况的惩罚是四个周期。当遇到条件分支指令时，通过停止IF阶段来停止所有进一步的指令取出，直到条件分支指令完成MEM阶段，其中用分支目标地址更新PC。这需要将IF级停止四个周期。进一步分析表明，只有在实际采用条件分支时才需要停止。如果结果是没有采用条件分支，则IF阶段可以继续获取下一个顺序指令。

实际上，管道假定不会采取分支。在采用分支的情况下，使用MEM阶段中的分支目标更新PC，并且删除或刷新驻留在较早流水线阶段中的所有指令，并且获取的下一指令是分支目标。通过这样的设计，仅在实际采用条件分支时才产生四周期惩罚，否则不存在惩罚周期。

与由于寄存器数据依赖性引起的RAW危险类似，控制危险引起的四周期惩罚可被视为最坏情况惩罚。如果可以在指令i和指令j之间插入非控制依赖于指令i的指令，则依赖于控制的指令，然后可以通过插入的指令数减少所引起的实际惩罚周期数。这是延迟分支的概念。本质上，这些惩罚周期由必须执行的有用指令填充，无论是否采用条件分支。惩罚周期的实际数量是4-s，其中s是可以在指令i和j之间插入的与控制无关的指令的数量。

原因是必须提供机制以将填充的指令与实际的正常顺序指令区分开。如果实际采用了分支，则不需要删除填充的指令，但必须删除正常的顺序指令，因为它们不应该被执行。



#### 2.2.3.4通过转发路径减少罚款。到目前为止，我们已经隐含了
假设可用于处理危险解决方案的唯一机制是停止相关尾随指令并确保危险寄存器的写入和读取按正常顺序完成。在管道的实际实施中可以使用更积极的技术，这有助于减少管道危险引起的惩罚周期。一种这样的技术涉及在管道中并入约束路径。

关于管道危险，前导指令i是尾随指令j所依赖的指令。对于RAW危险，指令j需要指令i的结果作为其操作数。图2.16说明了当i是ALU指令或加载指令时前导指令i的处理。

如果前导指令i是ALU指令，则指令j所需的结果实际上由ALU级产生，并且在指令i完成ALU级时可用。换句话说，当指令i退出ALU级时，指令j所需的操作数实际上在ALU级的输出处可用，并且j不需要再等待两个周期以使i退出WB级。如果ALU级的输出可以通过物理转发路径可用于ALU级的输入侧，则一旦前导指令离开ALU级，就可以允许尾随指令j进入ALU级。在这种情况下，指令j不需要通过读取RD阶段中的寄存器文件来访问从属操作数; 相反，它可以通过访问ALU阶段的输出来获得从属操作数。通过添加该转发路径和相关的控制逻辑，当前导指令是ALU指令时，所引起的最坏情况惩罚现在是零周期。即使尾随指令是指令i + 1，也不需要停止，因为指令i + 1可以进入ALU级，因为指令i离开ALU级就像正常的流水线操作一样。

在前导指令是加载指令而不是ALU指令的情况下，可以并入类似的转发路径以减少由于前导加载指令和从属跟踪指令而引起的惩罚周期。检查图2.16显示，如果前导指令是加载指令，则当加载指令完成时，该加载指令的结果，即加载到寄存器中的存储单元的内容，可在MEM阶段的输出处获得。 MEM阶段。同样，可以从MEM级的输出向ALU级的输入添加转发路径，以支持尾随指令的要求。一旦前导加载指令完成MEM阶段，尾随指令就可以进入ALU阶段。这有效地减少了由于从三个周期到一个周期的前导加载指令而导致的最坏情况损失。在最坏的情况下，从属指令是指令i + 1，即j = i + 1.在正常流水线处理中，当指令i处于ALU级时，指令i + 1将处于RD级。当指令i前进到MEM级时，必须通过停止流水线的早期阶段将指令i + 1保持在RD级。然而，在指令i退出MEM阶段的下一个周期中，利用从MEM阶段的输出到ALU阶段的输入的转发路径，可以允许指令i + 1进入ALU阶段。实际上，指令i + 1仅在RD阶段中停止一个周期; 因此，最坏情况的惩罚是一个周期。

以ALU指令作为主要指令的RAW危险导致的惩罚被称为ALU惩罚。类似地，由于前导加载指令引起的代价被称为负载代价。对于TYP管道，添加了转发路径，ALU惩罚为零周期。实际上，当前导指令是ALU指令时，不会产生任何惩罚。注意，转发路径的源是ALU级的输出，这是指令i的结果可用的最早点。转发路径的目的地是ALU级的输入，这是指令j需要指令i的结果的最新点。

除了关键转发路径之外，还需要其他转发路径。例如，需要从MEM和WB级的输出开始并且在ALU级的输入处结束的转发路径。需要这两个额外的转发路径，因为相关指令j可能是指令i + 2或指令i + 3.如果j = i + 2，那么当指令j准备好进入ALU阶段时，指令i将退出MEM阶段。因此，指令i的结果仍然没有被写回目标寄存器并且是指令j所需的，现在可以在MEM级的输出处获得，并且必须被转发到ALU级的输入以允许指令j在下一个周期进入该阶段。同样，如果j = i + 3，指令i的结果必须从WB级的输出转发到ALU级的输入。在这种情况下，尽管指令i已完成对目标寄存器的写回，但指令j已经遍历RD阶段并准备进入ALU阶段。

当然，在j = i + 4的情况下，通过j的正常读取寄存器文件很容易满足RAW依赖性，而不需要使用任何转发路径。到j到达RD阶段时，我将完成WB阶段。
如果前导指令是加载指令，则指令i的结果可用的最早点在MEM阶段的输出处，并且需要该结果的最新点是在ALU阶段的输入处。因此，前导加载指令的关键转发路径是从MEM级的输出到ALU级的输入。这代表了可以做到的最好，并且在这种情况下，产生一个周期惩罚是不可避免的。同样，在指令i退出WB阶段时，在从属跟踪指令准备好进入ALU阶段的情况下，需要从WB阶段的输出到ALU阶段的输入的另一个转发路径。

表2.6表明没有转发路径用于减少由于分支指令引起的惩罚。如果前导指令i是分支指令并且给定TYP流水线的寻址模式，则结果可用的最早点在MEM阶段的输出处。对于分支指令，在ALU阶段中生成分支目标地址和分支条件。直到MEM阶段才检查分支条件并且分支的目标地址被加载到Pc中。因此，只有在MEM阶段之后才能使用PC来获取分支目标。另一方面，PC必须在IF阶段的开始处可用，以允许获取下一条指令。

因此，需要结果的最新点是IF阶段的开始。
因此，关键转发路径或可以完成的最佳路径是在MEM阶段使用分支目标更新PC的当前惩罚路径，并且如果采用分支，则在下一个周期中开始获取分支目标。但是，如果可以在ALU阶段足够早地生成分支条件，以允许在ALU阶段结束时用分支目标地址更新PC，那么在这种情况下，分支惩罚可以从四个周期减少到三个周期。



#### 2.2.3.5管道互锁的实现。  
通过硬件机制解决管道危险被称为管道互锁。管道互锁硬件必须检测所有管道危险并确保满足所有依赖性。管道互锁可涉及停止管道的某些阶段以及通过转发路径控制数据的转发。

通过添加转发路径，标量流水线不再是简单的流水线序列，数据从第一级流向最后一级。
现在，转发路径提供了从后期输出到早期阶段输入的潜在反馈路径。例如，支持管道危险中涉及的前导ALU指令所需的三个转发路径如图2.17所示。这些被称为ALU转发路径。当前导ALU指令i遍历流水线级时，可能存在多个尾随指令，其是依赖于指令i的数据（RAW）。图2.17的右侧说明了在三个连续的机器周期内如何满足多个相关的尾随指令。在周期t1期间，指令i通过转发路径a将其结果转发到从属指令i + 1。在下一个周期t2期间，指令i通过转发路径b将其结果转发到从属指令i + 2。如果指令i + 2也需要指令i + 1的结果，则该结果也可以在该周期期间通过转发路径a由i + 1转发到i + 2。在周期t3期间，指令i可以通过转发路径c将其结果转发到指令i + 3。同样，如果指令i + 3也分别需要i + 2或i + 1的结果，则在该周期期间也可以激活路径a或路径b。



图2.17逻辑图的物理实现如图2.18所示。请注意，使用比较连续指令的寄存器指定符的比较器检测RAW危险。四个5位（假设32个寄存器）比较器如图2.18所示。如果尾随指令j当前处于RD阶段，即尝试读取其两个寄存器操作数，那么前两个比较器（左边）正在检查指令j和指令j-1之间可能的RAW依赖性，现在是ALU阶段。这两个比较器将j的两个源寄存器指定符与j  -  1的目标寄存器指定符进行比较。同时，另外两个比较器（右侧）检查j和j  -  2之间可能的RAW依赖性，这是现在处于MEM阶段。

如果在指令j和j-1之间检测到任何RAW依赖性，则由第一对比较器激活转发路径a。类似地，转发路径b由第二对比较器的输出激活，以满足指令j和j之间的任何依赖性。 -  2.如果j取决于j-1和j-2，则可以同时激活两个路径。

图2.17中的转发路径c未在图2.18中显示; 原因是如果在多端口寄存器文件的设计中采取适当的谨慎，则可能不需要该转发路径。如果三端口（两个读取和一个写入）寄存器文件的物理设计首先执行写入，然后在每个周期中执行两次读取，则不需要第三个转发路径。基本上，指令j将在遍历RD阶段时读取相关寄存器的新值和正确值。换句话说，转发在寄存器文件内部执行。无需再等待一个周期来读取从属寄存器或将其从WB级的输出转发到ALU级的输入。这是一个合理的设计选择，

为了减少由于涉及领先加载指令的管道危险而造成的损失，需要另一组转发路径。图2.19说明了当管道危险中涉及的前导指令是加载指令时所需的两个转发路径。这些被称为loadfOlwarding路径。转发路径d将MEM级的输出转发到ALU级的输入，而路径e将WB级的输出转发到ALU级的输入。当前导指令i到达ALU级时，如果指令i + 1依赖于指令i，则它必须在RD级中停止一个周期。在下一个周期中，当指令i退出MEM级时，其结果可以通过路径d转发到ALU级，以允许指令i + 1进入ALU级。在指令i + 2也取决于指令i的情况下，相同的结果在下一个周期中经由路径e从WB级转发到ALU级，以允许指令i + 2进入ALU级而不会引起另一个停顿周期。同样，如果多端口寄存器文件首先执行写操作然后执行读操作，则不需要转发路径e。例如，指令i + 2将读取RD阶段中的指令i的结果，而指令i同时在WB阶段中执行寄存器写入。那么转发路径e就没有必要了。例如，指令i + 2将读取RD阶段中的指令i的结果，而指令i同时在WB阶段中执行寄存器写入。那么转发路径e就没有必要了。例如，指令i + 2将读取RD阶段中的指令i的结果，而指令i同时在WB阶段中执行寄存器写入。

图2.20显示了由ALU和负载引导指令引起的支持管道危险的所有转发路径的物理实现。假设寄存器文件被设计为首先执行写入然后在每个周期中执行读取，则未示出转发路径e。注意，虽然ALU转发路径b和负载转发路径d分别如图2.17和图2.19所示，从MEM阶段的输出到ALU阶段的输入，这些实际上是两个不同的物理路径，如如图2.20所示。这两条路径馈入第一对多路复用器，并且根据MEM级中的前导指令是ALU还是加载指令，只能选择其中一条。

转发路径b源自MEM阶段中的缓冲区，其包含来自先前机器周期的ALU的输出。转发路径d源自MEM阶段中的缓冲区，其包含从D-cache访问的数据。
无论前导指令是ALU还是加载指令，相同的两对比较器用于检测寄存器依赖性。需要两对比较器，因为互锁硬件必须检测指令i和i + 1之间以及指令i和i + 2之间的可能依赖性。当寄存器文件被设计为在每个周期中首先执行写入然后读取时，当它们分别遍历WB和RD阶段时，自动满足指令i和i + 3之间的依赖性。第一对比较器的输出与来自ID级的信号一起使用，指示前导指令是负载以产生控制信号，用于如果在指令之间检测到依赖性，则将管线的前三个阶段停止一个周期我和我+ 1，

TYP管道的管道互锁硬件还必须处理由于控制依赖性导致的管道危险。用于支持涉及主要分支指令的控制危险的互锁机制的实现如图2.21所示。通常，在每个周期中，IF级访问I-cache以获取下一条指令，同时递增PC以准备获取下一条顺序指令。当在IF阶段中取出分支指令然后在1D阶段解码为这样的指令时，IF阶段可以停止，直到分支指令遍历ALU阶段，其中分支条件和目标地址都生成。在下一个周期中，对应于分支指令的MEM阶段，如果采用分支，则分支条件用于通过PC多路复用器的右侧将分支目标地址加载到PC中。每当遇到分支指令时，这会导致四个周期的惩罚。或者，可以假设不采用分支指令，并且IF级继续沿顺序路径获取后续指令。在确定采用分支指令的情况下，在分支指令的MEM阶段期间用分支目标更新PC，并且IF，ID，RD和ALU阶段中的顺序指令被无效并从中刷新。管道。在这种情况下，仅在实际采用分支时才会产生四周惩罚。如果分支结果未被采用，则不会产生惩罚周期。



### 2.2.4商用流水线处理器 

管衬处理器设计已成为一种成熟且广泛采用的技术。
RISC理念与指令流水线的兼容性是众所周知的并且被很好地利用。管道衬里也已成功应用于CISC架构。本小节重点介绍两个有代表性的流水线处理器 MIPS R20001R3000管道作为RISC流水线处理器的代表[Moussouris et al。，1986; 凯恩，1987年]。英特尔i486是CISC流水线处理器的代表[Crawford，1990]。来自Tilak Agerwala和John Cocke于1987年完成的一项关于RISC流水线处理器的IBM研究的实验数据被作为标量流水线处理器的特性和性能的代表[Agerwala和Cocke，1987]。



#### 2.2.4.1 RISC流水线处理器示例。  
MIPS是一种具有32位指令的RISC架构。有三种不同的inst
说明书可分为四种类型。
•计算指令对寄存器操作数执行算术，逻辑和移位操作。如果所有操作数和结果都是寄存器，则它们可以使用R型格式;如果在指令的立即字段中指定了其中一个操作数，则它们可以使用I型格式。
•加载/存储指令在存储器和寄存器之间移动数据。他们采用I型格式。唯一的寻址模式是基址寄存器加上存储在立即数字段中的有符号偏移量。
•跳转和分支指令控制程序的控制流程。跳转是无条件的，并使用J类型格式跳转到由26位目标和Pc的高4位组成的绝对地址。分支是有条件的，并使用I类型格式将目标地址指定为PC加上立即数字段中的16位偏移量。

•指令集中的其他指令用于在协处理器和其他特殊系统功能中执行操作。协处理器0（CPO）是系统控制协处理器。CPO指令操纵内存管理和异常处理设施。浮点指令作为协处理器指令实现，由单独的浮点处理器执行。

MIPS R20001R3000流水线是一个与TYP流水线非常相似的五级指令流水线。然而，每个流水线阶段进一步分为两个单独的阶段，分别为阶段一（P1）和阶段二（P2）。表2.7中描述了由五个阶段及其阶段中的每一个执行的功能。

这个五阶段管道中有许多有趣的功能。需要整个周期的I-cache访问实际上发生在P2期间

IF阶段和RD阶段的I 1。一个转换后备缓冲器（TLB）用于为I-cache和D-cache进行地址转换。在IF阶段的P1期间访问TLB，用于支持I-cache访问，并且在ALU阶段的P2期间访问TLB，以支持在MEM周期期间发生的D-cache访问。寄存器文件首先执行写入（WB阶段的P1），然后在每个机器周期中执行读取（RD阶段的P2）。该管道需要一个三端口（两个读和一个写）寄存器文件和一个单端口I-cache和一个单端口D-cache，分别支持IF和MEM阶段。

通过从ALU和MEM级的输出返回到ALU级输入的转发路径，没有ALU引导危险将导致惩罚周期。
负载损失，即负载引导危险引起的最坏情况损失，仅是一个周期，具有从MEM级输出到ALU级输入的转发路径。分支罚款也只有一个周期。由于R20001R3000管道的多个功能，因此可以实现这一点。首先，分支指令仅使用PC相对寻址模式。与在RD阶段必须访问的寄存器不同，PC在IF阶段之后可用。因此，在RD阶段期间，虽然使用单独的加法器，但是可以计算分支目标地址。第二个特征是没有生成和存储明确的条件码位。通过比较参考寄存器的内容，在ALU阶段的P1期间生成分支条件。通常，在ALU阶段（阶段3）中生成分支条件并且在IF阶段（阶段1）中完成指令获取，预期的惩罚将是两个循环。但是，在这个特定的流水线设计中，I-cache访问实际上直到IF阶段的P2才开始。由于分支条件在ALU阶段的P1结束时可用，并且因为I-cache访问直到IF阶段的P2才开始，所以在RD阶段结束时产生的分支目标地址可以由分支引导在IF阶段中间开始I-cache访问之前进入PC。因此，分支指令仅产生一个周期的惩罚。在这个特定的流水线设计中，I-cache访问实际上直到IF阶段的P2才开始。由于分支条件在ALU阶段的P1结束时可用，并且因为I-cache访问直到IF阶段的P2才开始，所以在RD阶段结束时产生的分支目标地址可以由分支引导在IF阶段中间开始I-cache访问之前进入PC。因此，分支指令仅产生一个周期的惩罚。在这个特定的流水线设计中，I-cache访问实际上直到IF阶段的P2才开始。由于分支条件在ALU阶段的P1结束时可用，并且因为I-cache访问直到IF阶段的P2才开始，所以在RD阶段结束时产生的分支目标地址可以由分支引导在IF阶段中间开始I-cache访问之前进入PC。因此，分支指令仅产生一个周期的惩罚。在IF阶段中间开始I-cache访问之前，可以通过分支条件将在RD阶段结束时产生的分支目标地址引导到PC中。因此，分支指令仅产生一个周期的惩罚。在IF阶段中间开始I-cache访问之前，可以通过分支条件将在RD阶段结束时产生的分支目标地址引导到PC中。因此，分支指令仅产生一个周期的惩罚。

与六级TYP管道相比，五级MIPS R2000 / R3000管道在管道危险造成的处罚方面是更好的设计。两条管道分别具有相同的ALU和零周期和一个周期的负载损失。但是，由于其设计中的上述特性，MIPS R20001R3000管道仅因其分支损失而仅产生一个周期而不是四个周期。受斯坦福大学RISC研究影响并从中受益，MIPS R2000 / R3000设计非常简洁，是一种高效的流水线处理器。




#### 2.2.4.2 CISC流水线处理器示例。1978年，英特尔推出了首批16位微处理器之一，即英特尔8086。
虽然先前有来自英特尔（8080和8085）的早期8位微处理器，但8086开始发展，最终将导致英特尔IA32系列目标代码兼容的微处理器。英特尔IA32是一种CISC架构，具有可变长度指令和复杂寻址模式，就销售量和随附的应用软件库而言，它是目前最主要的架构。1985年，推出了英特尔386，即32位版本的IA32系列[Crawford，1986]。

IA32系列的第一个流水线版本Intel 486于1989年推出。
表2.8
Intel 486五级流水线的功能 
|舞台名称| 功能执行
|  -  |  -  |
| 1.Instructi on fetch |从32字节预取队列获取指令（预取单元填充和流量预取q ueue）。
| 2.制造解码-1 | 将指令转换为控制信号或microcode add ress。初始化地址生成和m emory访问。
| 3.使用decode-2 |检测cti 访问microcode内存。输出微指令执行单元。
| 4.执行| 执行ALU和内存访问操作。
| S. Register回写|将结果写回register。

虽然最初的8086芯片的晶体管数量少于30K，但486芯片的晶体管数量超过1M。486是与IA32系列的所有先前成员兼容的目标代码，并且它成为20世纪90年代早期用于个人计算机的最流行的微处理器[Crawford，1990]。

486实现了五阶段指令管道。表2.8中描述了流水线阶段的功能。指令预取单元通过总线接口单元将16字节指令块预取到预取队列中。在取指令阶段，每个指令都从32字节的预取队列中取出。指令解码分两个阶段执行。在指令解码期间产生硬连线控制信号以及微指令。执行阶段执行ALU操作以及缓存访问。在指令解码期间执行地址转换和有效地址生成; 内存访问在执行阶段完成。

因此，紧接着使用后的存储器负载不会产生任何惩罚周期; 执行阶段的输出被转发到其输入。但是，如果产生寄存器结果的指令紧跟另一个使用相同寄存器产生地址的指令，则需要一个惩罚周期，因为在指令解码期间完成了地址产生。管道中的第五阶段执行寄存器回写。浮点运算由片上浮点单元执行，可能会产生多个周期。

利用五级指令流水线，486可以在一个周期内执行许多IA32指令而无需使用微码。某些指令需要访问微指令和多个周期。486清楚地证明了通过指令流水线可以获得的性能改进。基于典型的指令组合和常用IA32指令的执行时间，英特尔386能够实现4.9的平均每指令周期数（CPI）[Crawford，1986]。流水线型英特尔486的平均CPI约为1.95。

这代表加速约2.5倍。在我们的术语中，五阶段i486实现了2.5的有效流水线操作。显然，涉及显着的流水线开销，主要是由于IA32指令集架构的复杂性和确保目标代码兼容性的负担。尽管如此，对于CISC架构，获得的加速是非常可观的。486清楚地证明了流水线化CISC架构的可行性。




#### 2.2.4.3标量流水线处理器性能。报告记录的报告
IBM于2014年使用Tilak Agerwala和John Cocke对管道式RISC机器的经验评估了标量流水线RISC处理器的性能[Agerwala和Cocke，1987]。该报告中提出了一些关键意见。在本研究中，假设I-cache和D-cache是分开的。I-cache可以为处理器提供每个周期一条指令。只有加载/存储指令才能访问D-cache。在这项研究中，两个缓存的命中率假定为100％。两个缓存的默认延迟是一个周期。本研究使用以下特征和统计数据。

1.动态指令组合
   1. ALU：40％（寄存器寄存器）b。负荷：25％
   2.商店：15％
   3.分支机构：20％
2.动态分支指令组合 
   1.无条件：33.3％（总是被带走） 
   2.有条件：33.3％
   3.有条件的 - 未采取：33.3％ 
3.加载计划
   1.无法安排：25％（没有延迟插槽填写） 
   2.可以向后移动一个或两个指令：65％（填充两个延迟槽） 
   3.可以向后移动一条指令：10％（填一个延迟槽） 
4.分支机构安排
   1.无条件：100％可调度（填充一个延迟槽） 
   2.条件：50％可调度（填充一个延迟槽） 

可以使用每条指令的平均周期来估计处理器的性能。标量流水线处理器的理想目标是实现CPI = 1。
这意味着管道平均在每个周期中处理或完成一条指令。IBM的研究试图量化这种理想化目标的接近程度。最初，假设没有ALU惩罚，并且负载和分支惩罚都是两个周期。给定动态指令混合，可以计算由于这两个惩罚导致的CPI开销。

* 负载惩罚开销：0.25 x 2 = 0.5 CPI
* 分支罚款开销：0.20 x 0.66 x 2 = 0.27 CPI 
* 结果CPI：1.0 + 0.5 + 0.27 = 1.77 CPI

由于25％的动态指令是负载，如果我们假设每个负载都会产生两个周期的损失，则CPI开销为0.5。如果管道假设没有采用分支指令，或者没有采用偏差指令，那么只有66.6％的分支指令将导致双周期分支惩罚。

考虑到负荷和分支处罚，预期CPI为1.77。
这远不是CPI = 1的理想目标。
假设可以添加转发路径以绕过寄存器文件以获取加载指令，则可以将负载损失从两个周期减少到仅一个周期。通过添加此转发路径，CPI可以降低到1.0 + 0.25 + 0.27 = 1.52。

此外，可以使用编译器将指令调度到加载和分支惩罚时隙中。假设前面的文本中提供了统计数据，由于65％的负载可以通过一条或两条指令移回，10％的负载可以通过一条指令移回，因此可以安排总共75％的负载指令，或者向后移动，以消除一个周期的负载损失。对于33.3％的无条件分支指令，它们都可以被调度以减少它们从两个周期到一个周期的分支惩罚。由于管道偏向于没有采取分支，33.3％的分支是有条件的而不采取分支惩罚。对于剩余的33.3％的有条件和分支的分支，假设其中50％是可调度的，即 可以移回一条指令。因此，50％的条件分支只会产生一个周期的罚款，而另外50％会产生正常的两个 - 周期惩罚。此处显示了新的CPI开销和由此产生的CPI。

* 负载惩罚开销：0.25 x 0.25 x 1 = 0.0625 CPI
* 分支罚款开销：0.20 x [0.33 x 1 + 0.33 x 0.5 x 1 + 0.33 x 0.5 x 2] = 0.167 CPI
* 结果CPI：1.0 + 0.063 + 0.167 = 1.23 CPI 

通过调度负载和分支惩罚时隙，由于负载和分支惩罚而导致的CPI开销显着降低。由此产生的CPI为1.23，接近CPI = 1的理想目标。由于分支罚款导致的CPI开销仍然很大。进一步减少此开销的一种方法是考虑减少两个周期的分支惩罚的方法。从IBM研究中，不是使用寄存器间接寻址模式，而是90％的分支可以编码为PC相对。使用PC相对寻址模式，可以在不必访问寄存器文件的情况下完成分支目标地址生成。可以包括单独的加法器以与寄存器读取级并行地生成目标地址。因此，对于采用PC相对寻址的分支指令，分支惩罚可以减少一个周期。对于33.3％的无条件分支，它们是100％可调度的。因此，分支惩罚只是一个周期。如果它们中的90％可以与PC相关并因此消除分支惩罚，那么只有剩余的10％的无条件分支将导致一个循环的分支惩罚。相应的表2.9

考虑PC相对寻址和惩罚时隙调度的条件分支惩罚
| PC-relative Addressing | Schedulable | Branch Penalty
|  -  |  -  |  - 
|是（90％）|是（50％）| 0周期 
|是（90％）|否（50％）| 1个周期 
|否（10％）|是（50％）| 1个周期 
|否（10％）|否（50％）| 2个周期

然后，无条件分支的CPI开销为0.20 x 0.33 x 0.10 x 1 = 0.0066 CPI。

通过使用PC相对寻址模式，获取阶段不再对未采用的分支进行偏置。因此，无论是否采用它们，都可以以相同的方式处理所有条件分支。根据条件分支是否可以与PC相关以及是否可以进行调度，有四种可能的情况。表2.9列出了对条件分支的这四种可能情况的处罚。

包括已采取和未采取的分支，66.6％的分支是有条件的。由于条件分支导致的CPI开销是通过考虑表2.9中的情况得出的并且等于

 0.20 x 0.66 x {[0.9 x 0.5 x 1] + [0.1 x 0.5 xl] + [0.1 x 0.5 x 2]} = 0.079 CPI

由于无条件和条件分支导致的CPI开销的组合导致总CPI开销，因为分支罚分为0.0066 + 0.079 = 0.0856 CPI。
除了原始负载损失之外，此处还显示了新的开销和由此产生的总体CPI。
* 负载罚款开销：0.0625 CPI 
* 分支罚款：0.0856 CPI 
* 结果CPI：1.0 + 0.0625 + 0.0856 = 1.149 CPI 

因此，经过一系列改进后，1.77的原始CPI降至1.15。这非常接近CPI = 1的理想目标。一种观察方式是CPI = 1表示理想的指令流水线，其中在每个循环中将新指令输入流水线。只有当流水线理想主义的第三点成立时，这是可以实现的，即所有指令都是独立的。在实际程序中，存在指令间依赖性。CPI = 1.15表示在设计可以处理指令间依赖性的现实指令流水线时仅产生15％的开销或低效率。这非常令人印象深刻，反映了指令流水线的有效性。


## 2.3深度流水线处理器

流水线技术是提高处理器性能的一种非常有效的方法，并且采用深度流水线的动机很强。更深的流水线增加了流水线级的数量，并减少了每个流水线级的逻辑门级数。更深管道的主要好处是能够缩短机器周期时间，从而提高时钟频率。在20世纪80年代，大多数流水线微处理器有四到六个管道阶段。当代高端微处理器的时钟频率在几千兆赫兹范围内，管道深度已增加到20多个流水线级。管道不仅更深，而且更宽，如超标量处理器。随着流水线越来越宽，每个流水线阶段的复杂性都会增加，这会增加每个流水线阶段的延迟。

更深层的管道存在不利因素。通过更深的管道，管道危险解决所产生的惩罚可能会变得更大。图2.23说明了当管道变得更宽和更深时，ALU，负载和分支处罚会发生什么。比较浅管道和深管道，我们看到ALU惩罚从零周期增加到一个周期，负载惩罚从一个周期增加到四个周期，最重要的是，分支惩罚从三个周期变为十一个周期。随着管道处罚的增加，平均CPI增加。由于CPI的增加，可以改善由于较深管道的较高时钟频率而导致的潜在性能增益。为了确保通过更深的流水线提高整体性能，时钟频率的增加必须超过CPI的增长。

有两种方法可用于减轻深管道中增加的分支惩罚的负面影响; 见图2.24。在三个管道处罚中，分支罚款是最严重的，因为它跨越所有前端管道阶段。如果错误预测分支，则必须刷新前端管道阶段中的所有指令。

惩罚是减少前端的流水线级数,例如，具有可变指令长度的CISe架构可能需要非常复杂的指令解码逻辑，这可能需要多个流水线级。通过使用RISe架构，降低了解码复杂度，从而减少了前端流水线级。另一个例子是在将指令加载到I-cache之前使用预解码逻辑。从I高速缓存取出的预解码指令需要较少的解码逻辑，因此需要较少的解码级。

第二种方法是将一些前端复杂性移动到管道的后端，导致前端较浅，因此分支损失较小。这是一个活跃的研究领域。当管道重复执行一系列指令时，前端流水线级在相同的指令上重复执行相同的提取，解码和分派工作。有人建议完成工作的结果可以缓存和重用，而不必重复相同的工作。例如，解码指令块可以存储在特殊高速缓存中。可以通过访问该高速缓存来完成对这些相同指令的后续提取，并且可以绕过解码流水线级。除了缓存这些解码的指令之外，还可以对这些指令执行其他优化，导致进一步消除对一些前端管道阶段的需求。缓存和优化都可以在管道的后端实现，而不会影响前端深度和相关的分支惩罚。为了使深度流水线能够获得更高时钟频率的性能优势，必须保持流水线损失控制在设计深度流水线时存在不同形式的权衡。

如2.1节所示，k阶段流水线可能会使吞吐量增加k倍，与非流水线设计相关。在考虑成本时，需要权衡成本和性能。这种权衡要求k的最佳值不是任意大的。如图2.3所示。这种形式的权衡涉及实施管道的硬件成本，并且它表明存在管道深度，超过该管道深度，管道衬里的额外成本不能通过性能增益的递减收益来证明。

基于上述深管道引起的CPI影响分析，还有另一种权衡形式。这种权衡涉及时钟频率的增加与CPI的增加。根据处理器性能的铁律（第1.3.1节，方程1.1），性能取决于时钟频率和平均IPC或Jrequency / CPI比率的乘积。随着管道越来越深，频率也在增加，但CPI也是如此。只要增加的管道深度带来性能的净增加，增加管道深度就是有利可图的。有一点可以说，任何更深层次的流水线操作都会导致很少或没有性能提升。有趣的问题是，在我们达到收益递减点之前，管道有多深？最近的一些研究集中在确定最佳管道深度[Hartstein和Puzak，2002,2003; Sprangle和Carmean，2002年; Srinivasan等，2002，用于微处理器。随着管道深度的增加，频率可以增加。然而，频率不会相对于管道深度的增加而线性增加。频率的次线性增加是由于添加锁存器的开销。随着管道深度的增加，CPI也会因分支和负载损失的增加而增加。结合频率和CPI行为可以产生整体性能。随着管道深度的增加，由于频率增加的好处，整体性能趋于增加。然而，当管道深度进一步增加时，达到了CPI开销克服频率增加的好处的程度; 超过这一点的管道深度的任何进一步增加实际上可以导致整体性能的逐渐降低。在最近的一项研究中，Hartstein和Puzak [2003]表明，基于它们的性能模型，这一点的收益递减，因此最佳的管道深度，发生在-25级的管道深度周围。使用更积极的假设，Sprangle和Carmean [2002]表明，最佳管道深度实际上约为50个阶段。这一点的收益递减，因而最佳的管道深度，发生在-25级的管道深度附近。

如果考虑功耗，则最佳管道深度显着小于25或50个管段。较深管道的较高频率导致功耗的显着增加。即使有更多的性能需要收获，功耗也会变得过高，从而导致深层管道不可行。在同一项研究中，Hartstein和Puzak [2003]通过考虑除性能之外的功耗，开发了一种新的最佳管道深度模型。他们使用基于BIPSI \ I \ 3IW度量的模型，其中BIPSI \ I \ 3是每秒数十亿指令到第三个功率，W是瓦特。该模型基本上有利于性能（BIPS）与功率（W）之比为3比1.在他们的模型中，最佳管道深度现在更多地在6-9个管段的范围内。假设较低的闭锁开销和增加的泄漏功率，他们表明最佳的管道深度可能在10-15个管段的范围内。虽然近年来我们目睹了对更高时钟频率和更深管道的不懈追求，但由于功耗和散热造成的限制可能成为这种无情推动的严重障碍。




## 2.4摘要

流水线技术是一种微架构技术，可应用于任何ISA。确实，RISC架构的功能使流水线更容易，并产生更高效的流水线设计。但是，流水线技术在CISC架构上同样有效。流水线技术已被证明是提高处理器性能的一种非常强大的技术，在管道深度方面仍有很大的空间。我们可以期待更深层次的管道。

管道式处理器性能的主要障碍是由于指令间依赖性导致的流水线停滞。由于控制依赖而导致的分支惩罚是最大的罪魁祸首。动态分支预测可以缓解该问题，以便仅在发生分支错误预测时引起分支惩罚。当正确预测分支时，管道没有停顿; 但是，当检测到分支错误预测时，必须刷新管道。

随着管道越来越深，分支处罚增加并成为关键挑战。一种策略是通过减小管道前端的深度来减少分支惩罚，即，取指令阶段与解析分支指令的阶段之间的距离。另一种方法是提高动态分支预测算法的准确性，以减少分支误预测的频率; 因此，导致分支罚款的频率也降低了。我们在本章中没有介绍动态分支预测。这是一个非常重要的主题，我们选择在超标量处理器的背景下呈现分支预测。我们将在第5章中介绍它。

流水线处理器设计改变了CPU设计的经典视图的相关性。经典视图将处理器的设计划分为数据路径设计和控制路径设计。数据路径设计侧重于ALU和其他功能单元的设计以及寄存器的访问。控制路径设计侧重于状态机的设计，以解码指令并生成适当操纵数据路径所需的控制信号序列。

这种观点已不再适用。在流水线处理器中，此分区不再明显。指令在解码级中被解码，并且包括相关控制信号的解码指令沿着流水线传播并由各种后续流水线级使用。每个流水线级简单地使用解码指令和相关控制信号的适当字段。

实质上，控制路径不再执行集中控制。相反，使用通过管线级传播控制信号的分布式控制形式。通过多个控制路径状态来处理指令的传统排序现在被遍历各个流水线阶段的遍历所取代。实质上，不仅数据路径是流水线的，而且控制路径也是如此。此外，传统的数据路径和控制路径现在集成到同一管道中。

##参考文献

Agerwala，T。和J. Cocke：“高性能精简指令集处理器”，技术报告，IBM计算机科学，1987年。

Bloch，E。：“STRETCH计算机的工程设计”，Proc。Fall Joint Computer Coni，1959，pp.48-59。

Bucholtz，W。：规划计算机系统：Project Stretch。纽约：McGraw-Hill，1962年。

克劳福德，J。：“英特尔80386的架构”，Proc。IEEE Int。Coni on Computer Design：VLSI in Computers，1986，pp.155-160。

克劳福德，1：“英特尔i486 CPU的执行管道”，Proc。COMPCON Spring '90，1990，pp.254-258。

Hartstein，A。和TR Puzak：“最佳功率/性能管道深度”，Proc。第36届国际微架构研讨会（MICRO），2003年12月。

Hartstein，A。和TR Puzak：“微处理器的最佳管道深度，”Proc。第29届国际计算机体系结构研讨会（ISCA），2002年6月。

Hennessy，J。和D. Patterson：Computer Architecture：A Quantitative Approach，3rd ed。，San Mateo，CA：Morgan Kaufmann Publishers，2003。

Kane，G .: MIPS R2000lR3000 RISC架构。Englewood Cliffs，NJ：Prentice Hall，1987。

Kogge，P .:管道计算机的体系结构。纽约：McGraw-Hill，1981。

Moussouris，J.，L。Crudele，D。Frietas，C。Hansen，E。Hudson，R。March，S。Przybylski和T. Riordan：“具有集成系统功能的CMOS RISC处理器”，Proc。COMPCON，1986，pp.126-131。

Sprang Ie，E。和D. Carmean：“通过实施更深层的管道来提高处理器性能，”Proc。第29届国际计算机体系结构研讨会（ISCA），2002年6月。

Srinivasan，V.，D。Brooks，M。Gschwind，P。Bose，V。Zyuban，PN Strenski和PG Emma：“优化管道的动力和性能，”Proc。第35届国际微架构研讨会（MICRO），2002年12月。

Thornton，JE：“Control Data 6600中的并行操作”，AFlPS Proc。FJCC第2部分，第一卷。1964年26日，第33-40页。

Waser，S。和M. Flynn：数字系统设计师算术简介。纽约：霍尔特，莱因哈特和温斯顿，1982年。


##家庭作业问题

P2.t公式（2.4）将理想管道的性能与管道深度联系起来，与Amdahl定律非常相似。描述这两个方程中的项之间的关系，并为两个方程如此相似的原因提供直观的解释。

P2.2使用公式（2.7），可以使用参数G，T，L和S计算成本/性能最佳流水线深度k oP'。使用芯片计算2.1节中流水线浮点乘法器示例的kOPf计算成本项（G = 175个码片，L = 82/2 =每个级间锁存器41个码片）和T和S所示的延迟（T = 400 ns，S = 22 ns）。k opt与拟议的流水线设计有何不同？P2.3确定并讨论为什么方程（2.4）仅对流水线的潜在加速的天真近似有用的两个原因。

P2.4考虑您要向TYP指令集和管道添加加载立即指令。该指令从指令字中提取16位立即值，将立即值符号扩展为32位，并将结果存储在指令字中指定的目标寄存器中。由于可以在没有ALU的情况下完成提取和符号扩展，因此您的同事建议此类指令能够将其结果写入解码（ID）阶段的寄存器中。使用图2.15中描述的危险检测算法，确定可能引入的其他危险。

P2.S忽略管道互锁硬件（在问题6中讨论），问题4中列出的变更需要哪些额外的管道资源？讨论这些资源及其成本。

P2.6考虑问题4中概述的变化，重新绘制图2.18中所示的管道互锁硬件，以正确处理loadimmediate指令。

P2.7考虑您要将字节宽的ALU指令添加到TYP指令集和流水线。这些指令具有与现有字宽ALU指令相同的语义，除了源操作数仅为1字节宽且目标操作数仅为1字节宽。字节宽的操作数存储在与字宽指令相同的寄存器中，在低位字节中，寄存器写操作只能影响低位字节（即高位字节必须保持不变）。重新绘制图2.18中所示的RAW管道互锁检测硬件，以正确处理这些额外的ALU指令。

P2.8考虑将带有索引寻址模式的存储指令添加到TYP管道。该存储器与具有寄存器+立即寻址模式的现有存储器不同，它通过将其有效地址计算为两个源寄存器的总和，即stx r3，r4，r5执行r3f-MEM [r4 + r5]。描述在TYP管道中支持此类指令所需的额外管道资源。讨论这种指令的优缺点。

P2.9考虑使用register + immediate和postupdate寻址模式添加加载更新指令。在该寻址模式中，负载的有效地址计算为寄存器+立即数，并将得到的地址写回基址寄存器。也就是说，lwu r3,8（r4）执行r3f-MEM [r4 + 8]; R4F-R4 + 8。描述TYP管道。

P2.10鉴于问题9中概述的变化，重新绘制图2.20中所示的管道互锁硬件，以正确处理负载更新指令。

P2.11旁路网络设计：给定以下10个EX，MEM和WB流水线配置，绘制所有必要的MuxO和Muxl旁路路径以解决RAW数据危险。假设加载指令总是由读取加载寄存器的任何指令中的至少一个独立指令[可能是无操作指令（NOP）]分开（因此您不会因RAW危险而停止）。

P2.12给定问题11中的转发路径，绘制MuxO和Muxl的详细设计，清楚地识别在哪些控制条件下选择哪些旁路路径。识别每个Mux的每个输入1.布尔方程的可能输入是：
•ID.OP，EX.OP，MEM.OP = {'load'，'store'，'alu'，'other'}•ID.ReadRegO，ID.ReadRegl = [0 .. 31,32]其中32表示此指令不读取寄存器•EX.ReadRegO等，如ID阶段•MEM.ReadRegO等，如ID阶段•ID.WriteReg，EX.WriteReg，MEM.WriteReg = [0 .. 31 ，33]其中33表示该指令不写入寄存器•用标记输入绘制MuxO和Muxl; 您不需要使用门显示控件。简单地使用符号OP比较等来写出控制方程[例如，Ctrll =（ID.op ='load'）＆（ID.WriteReg = MEM.ReadRegO）]。

P2.13根据第2.2.4.3节中概述的IBM经验，计算添加零级数据高速缓存的CPI影响，该高速缓存能够在单个周期内提供数据操作数，但只有75％的时间。并行访问级别零和一级高速缓存，以便当零级高速缓存未命中时，一级高速缓存在下一个周期中返回结果，从而产生一个加载延迟时隙。假设在可以填充和不能填充的负载延迟槽中均匀分布零级命中。展示你的作品。

P2.14给定问题13的假设，如果仅在零级高速缓存未命中之后顺序访问第一级高速缓存，则计算CPI影响，从而产生两个负载延迟时隙而不是一个。展示你的作品。

P2.15 IBM对流水线处理器性能的研究假定了基于20世纪80年代使用的流行C程序的指令组合。
从那时起，像C ++和Java这样的面向对象语言变得越来越普遍。这些语言的一个影响是对象继承和多态可用于用虚函数调用替换条件分支。鉴于下表中显示的IBM指令组合和CPI，执行以下转换以反映C ++和Java的使用，并重新计算由于此更改导致的总体CPI和加速或减速：

*用加载指令后跟跳转寄存器指令替换50％的条件分支（加载和跳转寄存器实现虚函数调用）。
*使用加载指令替换25％的未采用分支，然后执行跳转寄存器指令。类型加载


P2.16在具有数据高速缓存的基于TYP的流水线设计中，加载指令检查标记数组以查找与访问数据数组并读取相应存储单元并行的高速缓存命中。将存储流水线化到这样的缓存更加困难，因为处理器必须首先检查标记，然后才覆盖数据数组。否则，在高速缓存未命中的情况下，存储器可能会覆盖错误的存储器位置。设计一个解决这个问题的方法，不需要将存储器向下发送两次，或者为每个存储指令停止管道，或者双重移植数据缓存。参考图2.15，是否有任何新的RAW，WAR和/或WAW内存危险？

P2.17表2.7中所示的MIPS流水线采用两阶段时钟方案，有效利用共享TLB，因为指令获取在第一阶段访问TLB，在第二阶段访问数据。
但是，在解析条件分支时，分支目标地址和分支直通地址都需要在第一阶段转换 - 与ALU阶段的第一阶段中的分支条件检查并行 - 以启用从任一个的指令获取目标或第二阶段的堕落。这似乎意味着双端口TLB。

建议这个问题的架构解决方案，避免双端口TLB。


问题18到24：指令流水线设计
这个问题探讨了管道设计。如前所述，管道衬砌涉及平衡管道阶段。良好的流水线实施可最大限度地减少内部和外部碎片，从而创建简单平衡 下面是一个简单的微处理器的非流水线实现，它只执行ALU指令，没有数据危险：

最小化内部碎片的数字。图中的每个子块都是一个原始单元，不能进一步划分为较小的子单元。必须在流水线实现中维护原始功能。显示流水线实现的图表。

流水线寄存器具有以下时序要求：

* OS-ns设置时间
* I-ns延迟时间（从时钟到输出）P2.19计算非流水线和管道实现的指令周期的延迟（以纳秒为单位）。

P2.20计算非流水线和流水线实现的机器周期时间（以纳秒为单位）。

P2.21计算问题18-20中管道实施的（潜在）加速比原始非流水线实施。

P2.22可以使用哪些微架构技术来进一步缩短流水线设计的机器周期时间？解释机器循环时间如何减少。

P2.23绘制问题18中管道阶段的简化图; 您应该包括所有必要的数据转发路径。该图应类似于图2.16。

P2.24讨论问题23中数据转发路径对问题18中流水线实施的影响。时间如何受到影响？添加这些转发路径后，管道是否会保持平衡？可能需要对问题18的原始管道组织进行哪些更改？
