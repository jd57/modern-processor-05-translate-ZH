# Processor Design
John Paul Shen

Welcome to contemporary microprocessor design. In its relatively brief lifetime of 30+ years, the microprocessor has undergone phenomenal advances. Its performance has improved at the astounding rate of doubling every 18 months. In the past three decades, microprocessors have been responsible for inspiring and facilitating some of the major innovations in computer systems. These innovations include embedded microcontrollers, personal computers, advanced workstations, handheld and mobile devices, application and file servers, web servers for the Internet, low-cost supercomputers, and large-scale computing clusters. Currently more than 100 million microprocessors are sold each year for the mobile, desktop, and server markets. Including embedded microprocessors and microcontrollers, the total number of microprocessors shipped each year is well over one billion units.

Microprocessors are instruction set processors (ISPs). An ISP executes instructions from a predefined instruction set. A microprocessor's functionality is fully characterized by the instruction set that it is capable of executing. All the programs that run on a microprocessor are encoded in that instruction set. This predefined instruction set is also called the instruction set architecture (ISA). An ISA serves as an interface between software and hardware, or between programs and processors. In terms of processor design methodology, an ISA is the specification of a design while a microprocessor or ISP is the implementation of a design. As with all forms of engineering design, microprocessor design is inherently a creative process that involves subtle tradeoffs and requires good intuition and clever insights.

This book focuses on contemporary superscalar microprocessor design at the microarchitecture level. It presents existing and proposed microarchitecture techniques in a systematic way and imparts foundational principles and insights, with the hope of training new microarchitects who can contribute to the effective design of future-generation microprocessors.


## The Evolution of Microprocessors

The first microprocessor, the Intel 4004, was introduced in 1971 . The 4004 was a 4-bit processor consisting of approximately 2300 transistors with a clock frequency of just over 100 kilohertz (kHz). Its primary application was for building calculators. The year 2001 marks the thirtieth anniversary of the birth of microprocessors. High-end microprocessors, containing up to 100 million transistors with a clock frequency reaching 2 gigahertz (GHz), are now the building blocks for supercomputer systems and powerful client and server systems that populate the Internet. Within a few years microprocessors will be clocked at close to 10 GHz and each will contain several hundred million transistors.

The three decades of the history of microprocessors tell a truly remarkable story of technological advances in the computer industry; see Table 1.1 . The evolution of the microprocessor has pretty much followed the famed Moore's law, observed by Gordon Moore in 1965, that the number of devices that can be integrated on a single piece of silicon will double roughly every 18 to 24 months. In a little more than 30 years, the number of transistors in a microprocessor chip has increased by more than four orders of magnitude. In that same period, microprocessor performance has increased by more than five orders of magnitude. In the past two decades, microprocessor performance has been doubling every 18 months, or an increase by a factor of 100 in each decade. Such phenomenal performance improvement is unmatched by that in any other industry.


Table 1.1
The amazing decades of the evolution of microprocessors

||1970-1980 |1980-1990 |1990-2000 |2000-2010 
|-|-|-|-|-
|Transistor count |2K- l00K |lOOK- 1M |1M- 100M |100M- 2B 
|Clock frequency |0. 1-3 MHz |3-30 MHz |30 M Hz-1 GHz |1-1 5G Hz
|Instructions/cycle |0.1 |0.1-0.9 |0.9- 1.9 |1.9-2.9

In each of the three decades of its existence, the microprocessor has played major roles in the most critical advances in the computer industry. During the first decade, the advent of the 4-bit microprocessor quickly led to the introduction of the 8-bit microprocessor. 
These narrow bit-width microprocessors evolved into selfcontained microcontrollers that were produced in huge volumes and deployed in numerous embedded applications ranging from washing machines, to elevators, to jet engines. The 8-bit microprocessor also became the heart of a new popular computing platform called the personal computer (PC) and ushered in the PC era of computing.

The decade of the 1980s witnessed major advances in the architecture and microarchitecture of 32-bit microprocessors. Instruction set design issues became the focus of both academic and industrial researchers. The importance of having an instruction set architecture that facilitates efficient hardware implementation and that can leverage compiler optimizations was recognized. Instruction pipelining and fast cache memories became standard microarchitecture techniques. Powerful scientific and engineering workstations based on 32-bit microprocessors were introduced. These workstations in turn became the workhorses for the design of subsequent generations of even more powerful microprocessors.

During the decade of the 1990s, microprocessors became the most powerful and most popular form of computers. The clock frequency of the fastest microprocessors exceeded that of the fastest supercomputers. Personal computers and workstations became ubiquitous and essential tools for productivity and communication.
Extremely aggressive microarchitecture techniques were devised to achieve unprecedented levels of microprocessor performance. Deeply pipelined machines capable of achieving extremely high clock frequencies and sustaining multiple instructions executed per cycle became popular. Out-of-order execution of instructions and aggressive branch prediction techniques were introduced to avoid or reduce the number of pipeline stalls. By the end of the third decade of microprocessors, almost all forms of computing platforms ranging from personal handheld devices to mainstream desktop and server computers to the most powerful parallel and clustered computers are based on the building blocks of microprocessors.

We are now heading into the fourth decade of microprocessors, and the momentum shows no sign of abating. Most technologists agree that Moore's law will continue to rule for at least 10 to 15 years more. By 2010, we can expect microprocessors to contain more than 1 billion transistors with clocking frequencies greater than 10 GHz. We can also expect new innovations in a number of areas. The current focus on instruction-level parallelism (ILP) will expand to include thread-level parallelism (TLP) as well as memory-level parallelism (MLP). Architectural features that historically belong to large systems, for example, mUltiprocessors and memory hierarchies, will be implemented on a single chip. Many traditional "macroarchitecture" issues will now become microarchitecture issues. Power consumption will become a dominant performance impediment and will require new solutions at all levels of the design hierarchy, including fabrication process, circuit design, logic design, microarchitecture design, and software run-time environment, in order to sustain the same rate of performance improvements that we have witnessed in the past three decades.

The objective of this book is to introduce the fundamental principles of microprocessor design at the microarchitecture level. Major techniques that have been developed and deployed in the past three decades are presented in a comprehensive way. This book attempts to codify a large body of knowledge into a systematic framework. Concepts and techniques that may appear quite complex and difficult to decipher are distilled into a format that is intuitive and insightful. A number of innovative techniques recently proposed by researchers are also highlighted. We hope this book will play a role in producing a new generation of microprocessor designers who will help write the history for the fourth decade of microprocessors.


## 1.2 Instruction Set Processor Design

The focus of this book is on designing instruction set processors. Critical to an instruction set processor is the instruction set architecture, which specifies the functionality that must be implemented by the instruction set processor. The ISA plays several crucial roles in instruction set processor design.

### 1.2.1 Digital Systems Design

Any engineering design starts with a specification with the objective of obtaining a good design or an implementation. Specification is a behavioral description of what is desired and answers the question "What does it do?" while implementation is a structural description of the resultant design and answers the question "How is it constructed?" Typically the design process involves two fundamental tasks: synthesis and analysis. Synthesis attempts to find an implementation based on the specification. Analysis examines an implementation to determine whether and how well it meets the specification. Synthesis is the more creative task that searches for possible solutions and performs various tradeoffs and design optimizations to arrive at the best solution. The critical task of analysis is essential in determining the correctness and effectiveness of a design; it frequently employs simulation tools to perform design validation and performance evaluation. A typical design process can require the traversing of the analysis-synthesis cycle numerous times in order to arrive at the final best design; see Figure 1.1.

In digital systems design, specifications are quite rigorous and design optimizations rely on the use of powerful software tools. Specification for a combinational logic circuit takes the form of boolean functions that specify the relationship between input and output variables. The implementation is typically an optimized two-level AND-OR design or a multilevel network of logic gates. The optimization attempts to reduce the number of logic gates and the number of levels of logic used in the design. For sequential circuit design, the specification is in the form of state machine descriptions that include the specification of the state variables as well as the output and next state functions. Optimization objectives include the reduction of the number of states and the complexity of the associated combinational logic circuits. Logic minimization and state minimization software tools are essential. Logic and state machine simulation tools are used to assist the analysis task. These tools can verify the logic correctness of a design and determine the critical delay path and hence the maximum clocking rate of the state machine.

The design process for a microprocessor is more complex and less straightforward. The specification of a microprocessor design is the instruction set architecture, which specifies a set of instructions that the microprocessor must be able to execute. The implementation is the actual hardware design described using a hardware description language (HDL). The primitives of an HDL can range from logic gates and flip-flops, to more complex modules, such as decoders and multiplexers, to entire functional modules, such as adders and multipliers. A design is described as a schematic, or interconnected organization, of these primitives.

The process of designing a modern high-end microprocessor typically involves two major steps: microarchitecture design and logic design. Microarchitecture design involves developing and defining the key techniques for achieving the targeted performance. Usually a performance model is used as an analysis tool to assess the effectiveness of these techniques. The performance model accurately models the behavior of the machine at the clock cycle granularity and is able to quantify the number of machine cycles required to execute a benchmark program.

The end result of microarchitecture design is a high-level description of the organization of the microprocessor. This description typically uses a register transfer language (RTL) to specify all the major modules in the machine organization and the interactions between these modules. During the logic design step, the RTL description is successively refined by the incorporation of implementation details to eventually yield the HDL description of the actual hardware design. Both the RTL and the HDL descriptions can potentially use the same description language. For example, Verilog is one such language. The primary focus of this book is on microarchitecture design.

### 1.2.2 Architecture, Implementation, and Realization

In a classic textbook on computer architecture by Blaauw and Brooks [1997] the authors defined three fundamental and distinct levels of abstraction: architecture, implementation, and realization. Architecture specifies the functional behavior of a processor. Implementation is the logical structure or organization that performs the architecture. Realization is the physical structure that embodies the implementation.

Architecture is also referred to as the instruction set architecture. It specifies an instruction set that characterizes the functional behavior of an instruction set processor. All software must be mapped to or encoded in this instruction set in order to be executed by the processor. Every program is compiled into a sequence of instructions in this instruction set. Examples of some well-known architectures are IBM 360, DEC VAX, Motorola 68K, PowerPC, and Intel IA32. Attributes associated with an architecture include the assembly language, instruction format, addressing modes, and programming model. These attributes are all part of the ISA and exposed to the software as perceived by the compiler or the programmer.

An implementation is a specific design of an architecture, and it is also referred to as the microarchitecture. An architecture can have many implementations in the lifetime of that ISA. All implementations of an architecture can execute any program encoded in that ISA. Examples of some well-known implementations of the above-listed architecture are IBM 360/91 , VAX 111780, Motorola 68040, 
PowerPC 604, and Intel P6. Attributes associated with an implementation include pipeline design, cache memories, and branch predictors. Implementation or microarchitecture features are generally implemented in hardware and hidden from the software. To develop these features is the job of the microprocessor designer or the microarchitect.

A realization of an implementation is a specific physical embodiment of a design. For a microprocessor, this physical embodiment is usually a chip or a multichip package. For a given implementation, there can be various realizations of that implementation. These realizations can vary and differ in terms of the clock frequency, cache memory capacity, bus interface, fabrication technology, packaging, etc. Attributes associated with a realization include die size, physical form factor, power, cooling, and reliability. These attributes are the concerns of the chip designer and the system designer who uses the chip.
The primary focus of this book is on the implementation of modern microprocessors. Issues related to architecture and realization are also important. Architecture serves as the specification for the implementation. Attributes of an architecture can significantly impact the design complexity and the design effort of an implementation. Attributes of a realization, such as die size and power, must be considered in the design process and used as part of the design objectives.

### 1.2.3 Instruction Set Architecture

Instruction set architecture plays a very crucial role and has been defined as a contract between the software and the hardware, or between the program and the machine. By having the ISA as a contract, programs and machines can be developed independently. Programs can be developed that target the ISA without requiring knowledge of the actual machine implementation. Similarly, machines can be designed that implement the ISA without concern for what programs will run on them. Any program written for a particular ISA should be able to run on any machine implementing that same ISA. The notion of maintaining the same ISA across multiple implementations of that ISA was first introduced with the IBM S/360 line of computers [Amdahl et aI., 1964].

Having the ISA also ensures software portability. A program written for a particular ISA can run on all the implementations of that same ISA. Typically given an IS A, many implementations will be developed over the lifetime of that ISA, or multiple implementations that provide different levels of cost and performance can be simultaneously developed. A program only needs to be developed once for that ISA, and then it can run on all these implementations. Such program portability significantly reduces the cost of software development and increases the longevity of software. Unfortunately this same benefit also makes migration to a new ISA very difficult. Successful ISAs, or more specifically IS As with a large software installed base, tend to stay around for quite a while. Two examples are the IBM 360/370 and the Intel IA32.

Besides serving as a reference targeted by software developers or compilers, ISA serves as the specification for processor designers. Microprocessor design starts with the ISA and produces a microarchitecture that meets this specification.
Every new microarchitecture must be validated against the ISA to ensure that it performs the functional requirements specified by the ISA. This is extremely important to ensure that existing software can run correctly on the new microarchitecture.

Since the advent of computers, a wide variety of ISAs have been developed and used. They differ in how operations and operands are specified. Typically an ISA defines a set of instructions called assembly instructions. Each instruction specifies an operation and one or more operands. Each ISA uniquely defines an assembly language. An assembly language program constitutes a sequence of assembly instructions. IS As have been differentiated according to the number of operands that can be explicitly specified in each instruction, for example twoaddress or three-address architectures. Some early ISAs use an accumulator as an implicit operand. In an accumulator-based architecture, the accumulator is used as an implicit source operand and the destination. Other early IS As assume that operands are stored in a stack [last in, first out (LIFO)] structure and operations are performed on the top one or two entries of the stack. Most modern IS As assume that operands are stored in a multientry register file, and that all arithmetic and logical operations are perfonned on operands stored in the registers. Special instructions, such as load and store instructions, are devised to move operands between the register file and the main memory. Some traditional ISAs allow operands to come directly from both the register file and the main memory.

ISAs tend to evolve very slowly due to the inertia against recompiling or redeveloping software. Typically a twofold performance increase is needed before software developers will be willing to pay the overhead to recompile their existing applications. While new extensions to an existing ISA can occur from time to time to accommodate new emerging applications, the introduction of a brand new ISA is a tall order. The development of effective compilers and operating systems for a new ISA can take on the order of 10+ years. The longer an ISA has been in existence and the larger the installed base of software based on that ISA, the more difficult it is to replace that ISA. One possible exception might be in certain special application domains where a specialized new ISA might be able to provide significant performance boost, such as on the order of lO-fold.

Unlike the glacial creep of IS A innovations, significantly new microarchitectures can be and have been developed every 3 to 5 years. During the 1980s, there were widespread interests in ISA design and passionate debates about what constituted the best ISA features. However, since the 1990s the focus has shifted to the implementation and to innovative microarchitecture techniques that are applicable to most, if not all, ISAs. It is quite likely that the few ISAs that have dominated the microprocessor landscape in the past decades will continue to do so for the coming decade. On the other hand, we can expect to see radically different and innovative microarchitectures for these IS As in the coming decade.

### 1.2.4 Dynamic-Static Interface

So far we have discussed two critical roles played by the ISA. First, it provides a contract between the software and the hardware, which facilitates the independent development of programs and machines. Second, an ISA serves as the specification for microprocessor design. All implementations must meet the requirements and support the functionality specified in the ISA. In addition to these two critical roles, each ISA has a third role. Inherent in the definition of every ISA is an associated definition of an interface that separates what is done statically at compile time versus what is done dynamically at run time. This interface has been called the dynamic-static inteiface (DSI) by Yale Patt and is illustrated in Figure 1.2 [Melvin and Patt, 1987].

The DSI is a direct consequence of having the ISA serve as a contract between the software and the hardware. Traditionally, all the tasks and optimizations done in the static domain at compile time involve the software and the compiler, and are considered above the OS!. Conversely, all the tasks and optimizations done in the dynamic domain at run time involve the hardware and are considered below the DSI. All the architecture features are specified in the ISA and are therefore exposed to the software above the DSI in the static domain. On the other hand, all the implementation features of the microarchitecture are below the DSI and operate in the dynamic domain at run time; usually these are completely hidden from the software and the compiler in the static domain. As stated earlier, software development can take place above the DSI independent of the development of the microarchitecture features below the OS!.

A key issue in the design of an ISA is the placement of the OS!. In between the application program written in a high-level language at the top and the actual hardware of the machine at the bottom, there can be different levels of abstractions where the DSI can potentially be placed. The placement of the DSI is correlated with the decision of what to place above the DSI and what to place below the DSI.
For example, performance can be achieved through optimizations that are carried out above the DSI by the compiler as well as through optimizations that are performed below the DSI in the microarchitecture. Ideally the DSI should be placed at a level that achieves the best synergy between static techniques and dynamic techniques, i.e., leveraging the best combination of compiler complexity and hardware complexity to obtain the desired performance. This DSI placement becomes a real challenge because of the constantly evolving hardware technology and compiler technology.

In the history of ISA design, a number of different placements of the DSI have been proposed and some have led to commercially successful ISAs. A conceptual illustration of possible placements of the DSI is shown in Figure 1.3. This figure is intended not to be highly rigorous but simply to illustrate that the DSI can be placed at different levels. For example, Mike Flynn has proposed placing the DSI very high and doing everything below the DSI, such that a program written in a high-level language can be directly executed by a directly executable language machine [Flynn and Hoevel, 1983]. A complex instruction set computer (CISC) ISA places the DSI at the traditional assembly language, or macrocode, level. In contrast, a reduced instruction set computer (RISC) ISA lowers the DSI and expects to perform more of the optimizations above the DSI via the compiler. The lowering of the DSI effectively exposes and elevates what would have been considered microarchitecture features in a CISC ISA to the ISA level. The purpose of doing this is to reduce the hardware complexity and thus achieve a much faster machine [Colwell et aI., 1985].

The DSI provides an important separation between architecture and implementation. Violation of this separation can become problematic. As an ISA evolves and extensions are added, the placement of the DSI is implicitly shifted. The lowering of the DSI by promoting a former implementation feature to the architecture level effectively exposes part of the original microarchitecture to the software. This can facilitate optimizations by the compiler that lead to reduced hardware complexity.
However, hardware technology changes rapidly and implementations must adapt and evolve to take advantage of the technological changes. As implementation styles and techniques change, some of the older techniques or microarchitecture features may become ineffective or even undesirable. If some of these older features were promoted to the ISA level, then they become part of the ISA and there will exist installed software base or legacy code containing these features. Since all future implementations must support the entire ISA to ensure the portability of all existing code, the unfortunate consequence is that all future implementations must continue to support those ISA features that had been promoted earlier, even if they are now ineffective and even undesirable. Such mistakes have been made with real ISAs. The lesson learned from these mistakes is that a strict separation of architecture and microarchitecture must be maintained in a disciplined fashion. Ideally, the architecture or ISA should only contain features necessary to express the functionality or the semantics of the software algorithm, whereas all the features that are employed to facilitate better program performance should be relegated to the implementation or the microarchitecture domain.

The focus of this book is not on ISA design but on microarchitecture techniques, with almost exclusive emphasis on performance. ISA features can influence the design effort and the design complexity needed to achieve high levels of performance. However, our view is that in contemporary high-end microprocessor design, it is the microarchitecture, and not the ISA, that is the dominant determinant of microprocessor performance. Hence, the focus of this book is on microarchitecture techniques for achieving high performance. There are other important design objectives, such as power, cost, and reliability. However, historically performance has received the most attention, and there is a large body of knowledge on techniques for enhancing performance. It is this body of knowledge that this book is attempting to codify.

## 1.3 Principles of Processor Performance

The primary design objective for new leading-edge microprocessors has been performance. Each new generation of microarchitecture seeks to significantly improve on the performance of the previous generation. In recent years, reducing power consumption has emerged as another, potentially equally important design objective. However, the demand for greater performance will always be there, and processor performance will continue to be a key design objective.

### 1.3.1 Processor Performance Equation

During the 1980s several researchers independently discovered or formulated an equation that clearly defines processor performance and cleanly characterizes the fundamental factors that contribute to processor performance. This equation has come to be known as the iron law of processor performance, and it is shown in
Equation (1.1). First, the processor performance equation indicates that a processor's performance is measured in terms of how long it takes to execute a particular program (time/program). Second, this measure of time/program or execution time can be formulated as a product of three terms: instructions/program, cycles/ instruction, and timelcycle. The first term indicates the total number of dynamic instructions that need to be executed for a particular program; this term is also referred to as the instruction count. The second term indicates on average (averaging over the entire execution of the program) how many machine cycles are consumed to execute each instruction; typically this term is denoted as the CPI (cycles per instruction). The third term indicates the length of time of each machine cycle, namely, the cycle time of the machine.

The shorter the program's execution time, the better the performance. Looking at Equation 1.1, we can conclude that processor performance can be improved by reducing the magnitude of anyone of the three terms in this equation. If the instruction count can be reduced, there will be fewer instructions to execute and the execution time will be reduced. If CPI is reduced, then on average each instruction will consume fewer machine cycles. If cycle time can be reduced, then each cycle will consume less time and the overall execution time is reduced. It might seem from this equation that improving performance is quite trivial. Unfortunately, it is not that straightforward. The three terms are not all independent, and there are complex interactions between them. The reduction of anyone term can potentially increase the magnitude of the other two terms. The relationship between the three terms cannot be easily characterized. Improving performance becomes a real challenge involving subtle tradeoffs and delicate balancing acts. It is exactly this challenge that makes processor design fascinating and at times more of an art than a science. Section l.3.2 will examine more closely different ways to improve processor performance.

### 1.3.2 Processor Performance Optimizations

It can be said that all performance optimization techniques boil down to reducing one or more of the three terms in the processor performance equation. Some techniques can reduce one term while leaving the other two unchanged. For example, when a compiler performs optimizations that eliminate redundant and useless instructions in the object code, the instruction count can be reduced without impacting the CPI or the cycle time. As another example, when a faster circuit technology or a more advanced fabrication process is used that reduces signal propagation delays, the machine cycle time can potentially be reduced without impacting the instruction count or the CPI. Such types of performance optimization techniques are always desirable and should be employed if the cost is not prohibitive.

Other techniques that reduce one of the terms can at the same time increase one or both of the other terms. For these techniques, there is performance gain only if the reduction in one term is not overwhelmed by the increase in the other terms. We can examine these techniques by looking at the reduction of each of the three terms in the processor performance equation.

There are a number of ways to reduce the instruction count. First, the instruction set can include more complex instructions that perform more work per instruction. The total number of instructions executed can decrease significantly.
For example, a program in a RISC ISA can require twice as many instructions as one in a CISC ISA. While the instruction count may go down, the complexity of the execution unit can increase, leading to a potential increase of the cycle time. If deeper pipelining is used to avoid increasing the cycle time, then a higher branch misprediction penalty can result in higher CPI. Second, certain compiler optimizations can result in fewer instructions being executed. For example, unrolling loops can reduce the number of loop closing instructions executed. However, this can lead to an increase in the static code size, which can in turn impact the instruction cache hit rate, which can in turn increase the CPI. Another similar example is the in-lining of function calls. By eliminating calls and returns, fewer instructions are executed, but the code size can significantly expand. Third, more recently researchers have proposed the dynamic elimination of redundant computations via microarchitecture techniques. They have observed that during program execution, there are frequent repeated executions of the same computation with the same data set. Hence, the result of the earlier computation can be buffered and directly used without repeating the same computation [Sodani and Sohi, 1997]. Such computation reuse techniques can reduce the instruction count, but can potentially increase the complexity in the hardware implementation which can lead to the increase of cycle time. We see that decreasing the instruction count can potentially lead to increasing the CPI and/or cycle time.

The desire to reduce CPI has inspired many architectural and microarchitectural techniques. One of the key motivations for RISC was to reduce the complexity of each instruction in order to reduce the number of machine cycles required to process each instruction. As we have already mentioned, this comes with the overhead of an increased instruction count. Another key technique to reduce CPI is instruction pipelining. A pipelined processor can overlap the processing of multiple instructions. Compared to a nonpipelined design and assuming identical cycle times, a pipelined design can significantly reduce the CPI. A shallower pipeline, that is, a pipeline with fewer pipe stages, can yield a lower CPI than a deeper pipeline, but at the expense of increased cycle time. The use of cache memory to reduce the average memory access latency (in terms of number of clock cycles) will also reduce the CPI. When a conditional branch is taken, staI1ed cycles can result from having to fetch the next instruction from a nonsequential location. Branch prediction techniques can reduce the number of such stalled cycles, leading to a reduction of CPI. However, adding branch predictors can potentiaI1y increase the cycle time due to the added complexity in the fetch pipe stage, or even increase the CPI if a deeper pipeline is required to maintain the same cycle time. The emergence of superscalar processors aI10ws the processor pipeline to simultaneously process multiple instructions in each pipe stage. By being able to sustain the execution of multiple instructions in every machine cycle, the CPI can be significantly reduced.
Of course, the complexity of each pipe stage can increase, leading to a potential increase of cycle time or the pipeline depth, which can in turn increase the CPI.

The key microarchitecture technique for reducing cycle time is pipelining.
Pipelining effectively partitions the task of processing an instruction into multiple stages. The latency (in terms of signal propagation delay) of each pipe stage determines the machine cycle time. By employing deeper pipelines, the latency of each pipe stage, and hence the cycle time, can be reduced. In recent years, aggressive pipelining has been the major technique used in achieving phenomenal increases of clock frequency of high-end microprocessors. As can be seen in Table 1.1 , during the most recent decade, most of the performance increase has been due to the increase of the clock frequency.

There is a downside to increasing the clock frequency through deeper pipelining. As a pipeline gets deeper, CPI can go up in three ways. First, as the front end of the pipeline gets deeper, the number of pipe stages between fetch and execute increases. This increases the number of penalty cycles incurred when branches are mispredicted, resulting in the increase of CPI. Second, if the pipeline is so deep that a primitive arithmetic-logic unit (ALU) operation requires multiple cycles, then the necessary latency between two dependent instructions, even with resultforwarding hardware, will be multiple cycles. Third, as the clock frequency increases with deeper central processing unit (CPU) pipelines, the latency of memory, in terms of number of clock cycles, can significantly increase. This can increase the average latency of memory operations and thus increase the overall CPI. Finally, there is hardware and latency overhead in pipelining that can lead to diminishing returns on performance gains. This technique of getting higher frequency via deeper pipelining has served us well for more than a decade. It is not clear how much further we can push it before the requisite complexity and power consumption become prohibitive.

As can be concluded from this discussion, achieving a performance improvement is not a straightforward task. It requires interesting tradeoffs involving many and sometimes very subtle issues. The most talented microarchitects and processor designers in the industry all seem to possess the intuition and the insights that enable them to make such tradeoffs better than others. It is the goal, or perhaps the dream, of this book to impart not only the concepts and techniques of superscalar processor design but also the intuitions and insights of superb microarchitects.

### 1.3.3 Performance Evaluation Method

In modern microprocessor design, hardware prototyping is infeasible; most designers use simulators to do performance projection and ensure functional correctness during the design process. Typically two types of simulators are used: functional simulators and performance simulators. Functional simulators model a machine at the architecture (ISA) level and are used to verify the correct execution of a program. Functional simulators actually interpret or execute the instructions of a program. Performance simulators model the microarchitecture of a design and are used to measure the number of machine cycles required to execute a program.
Usually performance simulators are concerned not with the semantic correctness of instruction execution, but only with the timing of instruction execution.

Performance simulators can be either trace-driven or execution-driven; as illustrated in Figure 1.4. Trace-driven performance simulators process pregenerated traces to determine the cycle count for executing the instructions in the traces. A trace captures the dynamic sequence of instructions executed and can be generated in three different ways; see Figure 1.4(a). One way is via software instrumentation, which inserts special instructions into a program prior to run time so that when the instrumented program is executed on a physical system, the inserted instructions will produce the dynamic execution trace. Another way is via hardware instrumentation. which involves putting special hardware probes to monitor the system bus and to record the actual execution trace when a program is executed on the system.
Software instrumentation can significantly increase the code size and the program execution time. Hardware instrumentation requires the monitoring hardware and is seriously limited by the buffering capacity of the monitoring hardware. The third trace generation method uses afunctional simulator to simulate the execution of a program. During simulation, hooks are embedded in the simulator to record the dynamic execution trace. For all three methods, once traces are generated, they can be stored for subsequent repeated use by trace-driven performance simulators.

Execution-driven performance simulators overcome some of the limitations of trace-driven performance simulators; see Figure l.4(b). Instead of using pregenerated traces, an execution-driven performance simulator is interfaced to a functional simulator, and the two simulators work in tandem. During simulation, the functional simulator executes the instructions and passes information associated with the executed instructions to the performance simulator. The performance simulator then tracks the timing of these instructions and their movement through the pipeline stages. It has the ability to issue directives to the functional simulator to checkpoint the simulation state and to later resume from the checkpointed state. The checkpoint capability allows the simulation of speculative instructions, such as instructions following a branch prediction. More specifically, execution-driven simulation can simulate the mis-speculated instructions, such as the instructions following a mispredicted branch, going through the pipeline. In trace-driven simulation, the pregenerated trace contains only the actual (nonspeculative) instructions executed, and a trace-driven simulator cannot account for the instructions on a mis-speculated path and their potential contention for resources with other (nonspeculative) instructions.
Execution-driven simulators also alleviate the need to store long traces. Most modem performance simulators employ the execution-driven paradigm. The most advanced execution-driven performance simulators are supported by functional simulators that are capable of performing full-system simulation, that is, the simulation of both application and operating system instructions, the memory hierarchy, and even input/output devices.

The actual implementation of the microarchitecture model in a performance simulator can vary widely in terms of the amount and details of machine resources that are explicitly modeled. Some performance models are merely cycle counters that assume unlimited resources and simply calculate the total number of cycles needed for the execution of a trace, taking into account inter-instruction dependences. Others explicitly model the organization of the machine with all its component modules. These performance models actually simulate the movement of instructions through the various pipeline stages, including the allocation of limited machine resources in each machine cycle. While many performance simulators claim to be "cycle-accurate," the methods they use to model and track the activities in each machine cycle can be quite different.

While there is heavy reliance on performance simulators during the early design stages of a microprocessor, the validation of the accuracy of performance simulators is an extremely difficult task. Typically the performance model or simulator is implemented in the early phase of the design and is used to do initial tradeoffs of various microarchitecture features. During this phase there isn't a reference that can be used to validate the performance model. As the design progresses and an RTL model of the design is developed, the RTL model can be used as a reference to validate the accuracy of the performance model. However, simulation using the RTL model is very slow, and therefore only very short traces can be used. During the entire design process, discipline is essential to concurrently evolve the performance model and the RTL model to ensure that the performance model is tracking all the changes made in the RTL model. It is also important to do post-silicon validation of the performance model so that it can be used as a good starting point for the next-generation design. Most performance simulators used in academic research are never validated. These simulators can be quite complex and, just like all large pieces of software, can contain many bugs that are difficult to eliminate. It is quite likely that a large fraction of the performance data published in many research papers using unvalidated performance models is completely erroneous. Black argues convincingly for more rigorous validation of processor simulators [Black and Shen, 1998].

Other than the difficulty of validating their accuracy, another problem associated with performance simulators is the extremely long simulation times that are often required. Most contemporary performance evaluations involve the simulation of many benchmarks and a total of tens to hundreds of billion instructions. During the early phase of the design, performance simulators are used extensively to support the exploration of numerous tradeoffs, which require many simulation runs using different sets of parameters in the simulation model. For execution-driven performance simulators that have fairly detailed models of a complex machine, a slowdown factor of four to five orders of magnitude is rather common. In other words, to simulate a single machine cycle of the target machine, that is the machine being modeled, can require the execution of 10,000 to 100,000 machine cycles on the host machine. A large set of simulation runs can sometimes take many days to complete, even using a large pool of simulation machines.

## 1.4 Instruction-Level Parallel Processing

Instruction-level parallel processing can be informally defined as the concurrent processing of multiple instructions. Traditional sequential processors execute one instruction at a time. A leading instruction is completed before the next instruction is processed. To a certain extent, pipelined processors achieve a form of instructionlevel parallel processing by overlapping the processing of multiple instructions. As many instructions as there are pipeline stages can be concurrently in flight at any one time. Traditional sequential (CISC) processors can require an average of about 10 machine cycles for processing each instruction, that is CPI = 10. With pipelined (RISC) processors, even though each instruction may still require multiple cycles to complete, by overlapping the processing of multiple instructions in the pipeline, the effective average CPI can be reduced to close to one if a new instruction can be initiated every machine cycle.

With scalar pipelined processors, there is still the limitation of fetching and initiating at most one instruction into the pipeline every machine cycle. With this limitation, the best possible CPI that can be achieved is one; or inversely, the best possible throughput of a scalar processor is one instruction per cycle (lPC). A more aggressive form of instruction-level parallel processing is possible that involves fetching and initiating multiple instructions into a wider pipelined processor every machine cycle. While the decade of the 1980s adopted CPI = 1 as its design objective for single-chip microprocessors, the goal for the decade of the 1990s was to reduce CPI to below one, or to achieve a throughput of IPC greater than one. Processors capable of IPC greater than one are termed superscalar processors. This section presents the overview of instruction-level parallel processing and provides the bridge between scalar pipelined processors and their natural descendants, the superscalar processors.

## 1.4.1 From Scalar to Superscalar

Scalar processors are pipelined processors that are designed to fetch and issue at most one instruction every machine cycle. Superscalar processors are those that are designed to fetch and issue multiple instructions every machine cycle. This subsection presents the basis and motivation for evolving from scalar to superscalar processor implementations.

#### 1.4.1.1 Processor Performance. 

In Section 1.3.1 we introduced the iron law of processor performance, as shown in Equation (1.1). That equation actually represents the inverse of performance as a product of instruction count, average CPI, and the clock cycle time. We can rewrite that equation to directly represent performance as a product of the inverse of instruction count, average fPC (I PC = lICPI), and the clock frequency, as shown in Equation (1.2). Looking at this equation, we see that performance can be increased by increasing the IPC, increasing the frequency, or decreasing the instruction count.

Instruction count is determined by three contributing factors: the instruction set architecture, the compiler, and the operating system. The ISA and the amount of work encoded into each instruction can strongly influence the total number of instructions executed for a program. The effectiveness of the compiler can also strongly influence the number of instructions executed. The operating system functions that are invoked by the application program effectively increase the total number of instructions executed in carrying out the execution of the program.

Average IPC (instructions per cycle) reflects the average instruction throughput achieved by the processor and is a key measure of microarchitecture effectiveness.
Historically, the inverse of IPC, that is, CPI (cycles per instruction), has been used to indicate the average number of machine cycles needed to process each instruction.
The use of CPI was popular during the days of scalar pipelined processors. The performance penalties due to various forms of pipeline stalls can be cleanly stated as different CPI overheads. Back then, the ultimate performance goal for scalar pipelined processors was to reduce the average CPI to one. As we move into the superscalar domain, it becomes more convenient to use IPC. The new performance goal for superscalar processors is to achieve an average IPC greater than one. The bulk of the microarchitecture techniques presented in this book target the improvement of IPC.

Frequency is strongly affected by the fabrication technology and circuit techniques. Increasing the number of pipeline stages can also facilitate higher clocking frequencies by reducing the number of logic gate levels in each pipe stage. Traditional pipelines can have up to 20 levels of logic gates in each pipe stage; most contemporary pipelines have only 10 or fewer levels. To achieve high IPC in superscalar designs, the pipeline must be made wider to allow simultaneous processing of multiple instructions in each pipe stage. The widening of the pipeline increases the hardware complexity and the signal propagation delay of each pipe stage. Hence, with a wider pipeline, in order to maintain the same frequency an even deeper pipeline may be required. There is a complex tradeoff between making pipelines wider and making them deeper.

#### 1.4.1.2 Parallel Processor Performance. 
As we consider the parallel processing of instructions in increasing processor performance, it is insightful to revisit the classic observation on parallel processing commonly referred to as Amdahl's law [Amdahl, 1967]. Traditional supercomputers are parallel processors that perform both scalar and vector computations. During scalar computation only one processor is used. During vector computation all N processors are used to perform operations on array data. The computation performed by such a parallel machine can be depicted as shown in Figure l.5, where N is the number of processors in the machine and h is the fraction of time the machine spends in scalar computation. Conversely, 1 - h is the fraction of the time the machine spends in vector computation.
One formulation of Amdahl's law states that the efficiency E of the parallel machine is measured by the overall utilization of the N processors or the fraction of time the N processors are busy. Efficiency E can be modeled as

As the number of processors N becomes very large, the efficiency E approaches 1 - h, which is the fraction of time the machine spends in vector computation. As N becomes large, the amount of time spent in vector computation becomes smaller and smaller and approaches zero. Hence, as N becomes very large, the efficiency E approaches zero. This means that almost all the computation time is taken up with scalar computation, and further increase of N makes very little impact on reducing the overall execution time.

Another formulation of this same principle is based on the amount of work that can be done in the vector computation mode, or the vectorizability of the program. As shown in Figure l.5,frepresents the fraction of the program that can be parallelized to run in vector computation mode. Therefore, 1 - f represents the fraction of the program that must be executed sequentially. If T is the total time required to run the program, then the relative speedup S can be represented as

where T is the sum of (1 - j), the time required to execute the sequential part, and f i N, the time required to execute the parallelizable part of the program. As N becomes very large, the second term of this sum approaches zero, and the total execution time is dictated by the amount of time required to execute the sequential part. This is commonly referred to as the sequential bottleneck; that is, the time spent in sequential execution or scalar computation becomes a limit to how much overall performance improvement can be achieved via the exploitation of parallelism. As N increases or as the machine parallelism increases, the performance will become more and more sensitive to and dictated by the sequential part of the program.

The efficiency of a parallel processor drops off very quickly as the number of processors is increased. Furthermore, as the vectorizability, i.e., the fraction of the program that can be parallelized, of a program drops off slightly from 100%, the efficiency drop-off rate increases. Similarly the overall speedup drops off very quickly when f, the vectorizability of the program, drops even just very slightly from 100%. Hence, the overall performance improvement is very sensitive to the vectorizability of the program; or to state it another way, the overall speedup due to parallel processing is strongly dictated by the sequential part of the program as the machine parallelism increases.

#### 1.4.1.3 Pipelined Processor Performance. 
Harold Stone proposed that a performance model similar to that for parallel processors can be developed for pipelined processors [Stone, 1987]. A typical execution profile of a pipelined processor is shown in Figure 1.6(a). The machine parallelism parameter N is now the depth of the pipeline, that is, the number of stages in the pipeline. There are three phases in this execution profile. The first phase is the pipeline filling phase during which the first sequence of N instructions enters the pipeline. The second phase is the pipeline full phase, during which the pipeline is full and represents the steady state of the pipeline. This is assuming that there is no pipeline disruption, and therefore represents the perfect pipeline execution profile. The third phase is the pipeline draining phase, during which no new instruction is entering the pipeline and the pipeline is finishing the instructions still present in the pipeline stages.

For modeling purposes, we can modify the execution profile of Figure 1.6(a) to the execution profile of Figure 1.6(b) by moving some of the work done during the pipeline filling phase to the pipeline draining phase. The total amount of work remains the same; that is, the areas within the two profiles are equal. The number of pipeline stages is N, the fraction of the time that all N pipeline stages are utilized is g, and 1 - g is the fraction of time when only one pipeline stage is utilized. Essentially 1 - g can be viewed as the fraction of time when only one instruction is moving through the pipeline; that is, there is no overlapping of instructions in the pipeline.

Unlike the idealized pipeline execution profile, the realistic pipeline execution profile must account for the stalling cycles. This can be done as shown in Figure 1.7(a). Instead of remaining in the pipeline full phase for the duration of the entire execution, this steady state is interrupted by pipeline stalls. Each stall effectively induces a new pipeline draining phase and a new pipeline filling phase, as shown in Figure 1.7(a), due to the break in the pipeline full phase. Similar modification can be performed on this execution profile to result in the modified profile of Figure 1.7(b) by moving part of the work done in the two pipeline filling phases to the two pipeline draining phases. Now the modified profile of Figure 1. 7(b) resembles the execution profile of parallel processors as shown in Figure 1.5.
With the similarity of the execution profiles, we can now borrow the performance model of parallel processors and apply it to pipe lined processors. Instead of being the number of processors, N is now the number of pipeline stages, or the maximum speedup possible. The parameter g now becomes the fraction of time when the pipeline is filled, and the parameter 1 - g now represents the fraction of time when the pipeline is stalled. The speedup S that can be obtained is now

Note that g, the fraction of time when the pipeline is full, is analogous to f, the vectorizability of the program in the parallel processor model. Therefore, Amdahl's law can be analogously applied to pipelined processors. As g drops off just slightly from 100%, the speedup or the performance of a pipelined processor can drop off very quickly. In other words, the actual performance gain that can be obtained through pipelining can be strongly degraded by just a small fraction of stall cycles.
As the degree of pipelining N increases, the fraction of stall cycles will become increasingly devastating to the actual speedup that can be achieved by a pipeline processor. Stall cycles in pipelined processors are now the key adversary and are analogous to the sequential bottleneck for parallel processors. Essentially, stall cycles constitute the pipelined processor's sequential bottleneck.

Equation (1.5) is a simple performance model for pipelined processors based on Amdahl's law for parallel processors. It is assumed in this model that whenever the pipeline is stalled, there is only one instruction in the pipeline, or it effectively becomes a sequential nonpipelined processor. The implication is that when a pipeline is stalled no overlapping of instructions is allowed; this is effectively equivalent to stalling the pipeline for N cycles to allow the instruction causing the stall to completely traverse the pipeline. We know, however, that with clever design of the pipeline, such as with the use of forwarding paths, to resolve a hazard that causes a pipeline stall, the number of penalty cycles incurred is not necessarily N and most likely less than N. Based on this observation, a refinement to the model of Equation (1.5) is possible. 


Equation (1.6) is a generalization of Equation (1.5) and provides a refined model for pipelined processor performance. In this model, gi represents the fraction of time when there are i instructions in the pipeline. In other words, g i represents the fraction of time when the pipeline is stalled for (N - i) penalty cycles. Of course, gN is the fraction of time when the pipeline is full.

This pipelined processor performance model is illustrated by applying it to the six-stage TYP pipeline in Chapter 2. Note that the TYP pipeline has a load penalty of one cycle and a branch penalty of four cycles. Based on the statistics from the
IBM study presented in Chapter 2, the typical percentages of load and branch instructions are 25% and 20%, respectively. Assuming that the TYP pipeline is designed with a bias for a branch not taken, only 66.6% of the branch instructions, those that are actually taken, will incur the branch penalty. Therefore, only 13% of the instructions (branches) will incur the four-cycle penalty and 25 % of the instructions (loads) will incur the one-cycle penalty. The remaining instructions
(62%) will incur no penalty cycles. The performance of the TYP pipeline can be modeled as shown in Equation (1.7).


The resultant performance of the six-stage TYP pipeline processor is a factor of 4.5 over that of the sequential or nonpipelined processor. Note that the TYP is a six-stage pipeline with the theoretical speedup potential of 6. The actual speedup based on our model of Equation (1.6) is 4.5 , as shown in Equation (1.7), which can be viewed as the effective degree of pipe lining of the TYP pipeline. Essentially the six-stage TYP processor behaves as a perfect pipeline with 4.5 pipeline stages.
The difference between 6 and 4.5 reflects the difference between the potential (peak) pipeline parallelism and the achieved (actual) pipeline parallelism.

#### 1.4.1.4 The Superscalar Proposal. 
We now restate Amdahl's law that models the performance of a parallel processor:


This model gives the performance or speedup of a parallel system over that of a nonparallel system. The machine parallelism is measured by N, the number of processors in the machine, and reflects the maximum number of tasks that can be simultaneously performed by the system. The parameter f, however, is the vectorizability of the program which reflects the program parallelism. The formulation of this model is influenced by traditional supercomputers that contain a scalar unit and a vector unit. The vector unit, consisting of N processors, executes the vectorizable portion of the program by performing N tasks at a time. The nonvectorizable portion of the program is then executed in the scalar unit in a sequential fashion . We have already observed the oppressive tyranny of the nonvectorizable portion of the program on the overall performance that can be obtained through parallel processing.

The assumption that the nonvectorizable portion of the program must be executed sequentially is overly pessimistic and not necessary. If some, even low, level of parallelism can be achieved for the nonvectorizable portion of the program, the severe impact of the sequential bottleneck can be significantly moderated. Figure 1.8 illustrates this principle. This figure, taken from an IBM technical report coauthored by Agerwala and Cocke [1987], plots the speedup as a function off, the vectorizability of a program, for several values of N, the maximum parallelism of the machine.
Take the example of the case when N = 6. The speedup is

Examining the curve for Equation (1.9) in Figure 1.8, we see that the speedup is equal to 6 iff is 100%, that is, perfectly vectorizable. As f drops off from 100%, the speedup drops off very quickly; as f becomes 0%, the speedup is one; that is, no speedup is obtained. With higher values of N, this speedup drop-off rate gets significantly worse, and as f approaches 0%, all the speedups approach one, regardless of the value of N. Now assume that the minimum degree of parallelism of 2 can be achieved for the nonvectorizable portion of the program. The speedup now becomes

Examining the curve for Equation (LlO) in Figure 1.8, we see that it also starts at a speedup of 6 whenfis 100%, but drops off more slowly than the curve for Equation (1.9) whenfis lowered from 100%. In fact this curve crosses over the curve for Equation (1.8) with N = 100 whenfis approximately 75%. This means that for cases withfless than 75%, it is more beneficial to have a system with maximum parallelism of only 6, that is N = 6, but a minimum parallelism of two for the nonvectorizable portion, than a system with maximum parallelism of N = 100 with sequential execution of the nonvectorizable portion. The vectorizability of a programfis a complex function involving the application algorithm, the programming language, the compiler, and the architecture. Other than those for scientific applications involving mostly numerical computations, most programs for general-purpose computing tend not to have very high vectorizability. It is safe to say that most general-purpose programs havefless than 75%, and for many, significantly less.

One primary motivation for designing superscalar processors is to develop general-purpose processors that can achieve some (perhaps low relative to vectorizing) level of parallelism for a wide range of application programs. The goal is to ensure that some degree of instruction-level parallelism can be achieved for all portions of the program so as to moderate the severe impact of the sequential bottleneck. Of course, the highly vectorizable programs will continue to achieve good speedup via parallelism. Note that the curve for Equation (1.10) is always higher than that for Equation (1.9) even at high values off, and is higher than other curves for large values of N at lower values off The goal for superscalar processors is to achieve generalized instruction-level parallelism and the consequent speedup for all types of application programs, including those that are not necessarily vectorizable.

### 1.4.2 Limits of Instruction-Level Parallelism

In Equation (1.10), parallelism of degree 6 can be achieved for theffraction of the program and parallelism of degree 2 can be achieved for the remaining 1 - f fraction of the program. The speedup S can be viewed as the aggregate degree of parallelism that can be achieved for the entire program. For example, if the parameter f is 50% and the peak parallelism N is 6, then the speedup or the aggregate degree of parallelism is

The implication of Equation (1.11) is that effectively an overall or aggregate degree of parallelism of 3 is achieved for the entire program. Applying this result at the instruction level, we see that Equation (l.11) indicates that an average of three instructions can be simultaneously executed at a time. For traditional vector computation, the number of operations that can be simultaneously performed is largely determined by the size of the vectors or arrays, or essentially the data set size. For general-purpose unstructured programs, the key question is, what aggregate degree of instruction-level parallelism can potentially be achieved?

Instruction-level parallelism can be informally defined as the aggregate degree of parallelism (measured by the number of instructions) that can be achieved by the concurrent execution of multiple instructions. Possible limits of ILP have been investigated for almost three decades. Numerous experimental studies have been performed that yield widely varying results on purported limits of ILP. The following table provides a sample listing of reported limits in order of increasing degrees of ILP.

|Study |ILP Limit
|-|-
|Weiss and Smith, 1984 |1.58
|Sohi and Vajapeyam, 1987 |1.81
|Tjaden and Flynn, 1970 |1.86
|Tjaden and Flynn, 1973 |1.96
|Uht and Wedig, 1986 |2.0
|Smith et aI., 1989 |2.0
|Jouppi and Wall, 1989 |2.4
|Johnson, 1991 |2.5
|Acosta et aI., 1986 |2.79
|Wedig, 1982 |3.0
|Butler et aI., 1991 |5.8
|Melvin and Patt, 1991 |6
|Wall,1991 |7
|Kuck et aI., 1972 |8
|Riseman and Foster, 1972 |51
|Nicolau and Fisher, 1984 |90

This listing is certainly not exhaustive, but clearly illustrates the diversity and possible inconsistency of the research findings. Most of these are limit studies making various idealized assumptions. The real challenge is how to achieve these levels of ILP in realistic designs. The purported limits are also not monotonic with respect to chronological order. During the decade of the 1990s the debate on the limits of ILP replaced the RISC VS. CISC debate of the 1980s [Colwell et aI., 1985]. This new debate on the limit of ILP is still not settled.

#### 1.4.2.1 Flynn's Bottleneck. 
One of the earliest studies done at Stanford University by Tjaden and Flynn in 1970 concluded that the ILP for most programs is less than 2. This limit has been informally referred to as Flynn's bottleneck. This study focused on instruction-level parallelism that can be found within basic block boundaries. Since crossing basic block boundaries involves crossing control dependences, which can be dependent on run-time data, it is assumed that the basic blocks must be executed sequentially. Because of the small size of most basic blocks, typically the degree of parallelism found is less than 2. This result or Flynn's bottleneck has since been confirmed by several other studies.

One study in 1972 that confirmed this result was by Riseman and Foster [1972]. However, they extended their study to examine the degree of ILP that can be achieved if somehow control dependences can be surmounted. This study reported various degrees of parallelism that can be achieved if various numbers of control dependences can be overcome. If the number of control dependences that can be overcome is unlimited, then the limit of ILP is around 51 . This study highlights the strong influence of control dependences on the limits of ILP.

#### 1.4.2.2 Fisher's Optimism. 

At the other end of the spectrum is a study performed by Nicolau and Fisher in 1984 at Yale University. This study hints at almost unlimited amounts of ILP in many programs. The benchmarks used in this study tend to be more numerical, and some of the parallelisms measured were due to data parallelism resulting from array-type data sets. An idealized machine model capable of executing many instructions simultaneously was assumed. While some idealized assumptions were made in this study, it does present a refreshing optimistic outlook on the amount of ILP that can be harvested against the pessimism due to Flynn's bottleneck. We informally refer to this purported limit on ILP as Fisher's optimism.

Initially this optimism was received with a great deal of skepticism. A number of subsequent events somewhat vindicated this study. First a prototype machine model called the VLIW (very long instruction word) processor was developed along with a supporting compiler [Fisher, 1983]. Subsequently, a commercial venture (Multiflow, Inc.) was formed to develop a realistic VLIW machine, which resulted in the Multiflow TRACE computer. The TRACE machines were supported by a powerful VLIW compiler that employs trace scheduling (developed by Josh Fisher et a\.) to extract instruction-level parallelism [Fisher, 1981]. Multiflow, Inc., was reasonably successful and eventually had an installed base of more than 100 machines. More importantly, the short-lived commercial TRACE machines were the first general-purpose uniprocessors to achieve an average IPC greater than one. Although the actual levels of ILP achieved by the TRACE machines were far less than the limits published earlier by Nicolau and Fisher in 1984, they did substantiate the claims that there are significant amounts of ILP that can be harvested beyond the previously accepted limit of 2.


## 1.4.2.3 Contributing Factors. 
Many of the studies on the limits of ILP employ different experimental approaches and make different assumptions. Three key factors contribute to the wide range of experimental results: benchmarks used, machine models assumed, and compilation techniques employed. Each study adopts its own set of benchmarks, and frequently the results are strongly influenced by the benchmarks chosen . Recently, the Standard Performance Evaluation Corporation (SPEC) benchmark suites have become widely adopted, and most manufacturers of processors and computing systems provide SPEC ratings for their systems. While strict guidelines exist for manufacturers to report the SPEC ratings on their products (see www.spec.org), there are still quite nonuniform uses of the SPEC ratings by researchers. There are also strong indications that the SPEC benchmark suites are only appropriate for workstations running scientific and engineering applications, and are not relevant for other application domains such as commercial transaction processing and embedded real-time computing.

The second key factor that contributes to the confusion and controversy on the limits of ILP is the assumptions made by the various studies about the machine mode\. Most of the limit studies assume idealized machine models. For example, the cache memory is usually not considered or is assumed to have a 100% hit rate with one-cycle latency. Some models assume infinite-sized machines with infinite register files. Usually one-cycle latency is assumed for all operation and functional unit types. Other studies employ more realistic machine models, and these usually resulted in more pessimistic, and possibly unnecessarily pessimistic, limits. Of course, there is also a great deal of non uniformity in the instruction set architectures used. Some are fictitious architectures, and others use existing architectures. The architectures used also tend to have a strong influence on the experimental results.

Finally, the assumptions made about the compilation techniques used are quite diverse. Many of the studies do not include any consideration about the compiler; others assume infinitely powerful compilers. Frequently, these studies are based on dynamic traces collected on real machines. Simulation results based on such traces are not only dependent on the benchmarks and architectures chosen, but also strongly dependent on the compilers used to generate the object code. The potential contribution of the compilation techniques to the limits of ILP is an ongoing area of research. There is currently a significant gap between the assumed capabilities of all-powerful compilers and the capabilities of existing commercially available compilers. Many anticipate that many more advancements can be expected in the compilation domain.

Probably the safest conclusion drawn from the studies done so far is that the real limit of ILP is beyond that being achieved on current machines. There is room for more and better research. The assumption of any specific limit is likely to be premature. As more powerful and efficient microarchitectures are designed and more aggressive compilation techniques are developed, the previously made assumptions may have to be changed and previously purported limits may have to be adjusted upward.


## 1.4.3 Machines for Instruction-Level Parallelism

Instruction-level parallelism is referred to as fine-grained parallelism relative to other forms of coarse-grained parallelism involving the concurrent processing of multiple program fragments or computing tasks. Machines designed for exploiting general ILP are referred to as ILP machines and are typically uniprocessors with machine resource parallelisms at the functional unit level. A classification of ILP machines was presented by Norm Jouppi in 1989 [Jouppi and Wall, 1989].
ILP machines are classified according to a number of parameters.
* Operation latency (OL). The number of machine cycles until the result of an instruction is available for use by a subsequent instruction. The reference instruction used is a simple instruction that typifies most of the instructions in the instruction set. The operation latency is the number of machine cycles required for the execution of such an instruction.
* Machine parallelism (MP). The maximum number of simultaneously executing instructions the machine can support. Informally, this is the maximum number of instructions that can be simultaneously in flight in the pipeline at anyone time.
* Issue latency (IL). The number of machine cycles required between issuing two consecutive instructions. Again the reference instructions are simple instructions. In the present context, issuing means the initiating of a new instruction into the pipeline.
* Issue parallelism (IP). The maximum number of instructions that can be issued in every machine cycle.

In Jouppi's classification, the scalar pipelined processor is used as the baseline machine. The classification also uses a generic four-stage instruction pipeline for illustration. These stages are
1. IF (instruction fetch)
2. DE (instruction decode)
3. EX (execute)
4. WB (write back)

The EX stage is used as a reference for the determination of the operation latency.
The scalar pipelined processor, used as the baseline machine, is defined to be a machine with OL = 1 cycle and IL = 1 cycle. This baseline machine, with its instruction processing profile illustrated in Figure 1.9, can issue one new instruction into the pipeline in every cycle, and a typical instruction requires one machine cycle for its execution. The corresponding MP is equal to k, the number of stages in the pipeline; in Figure 1.9 MP = 4. The IP is equal to one instruction per cycle. Notice all four of these parameters are static parameters of the machine and do not take into account the dynamic behavior that depends on the program being executed.

When we discuss the performance or speedup of ILP machines, this baseline machine is used as the reference. Earlier in this chapter we referred to the speedup that can be obtained by a pipelined processor over that of a sequential nonpipelined processor that does not overlap the processing of multiple instructions. This form of speedup is restricted to comparison within the domain of scalar processors and focuses on the increased throughput that can be obtained by a (scalar) pipelined processor with respect to a (scalar) nonpipelined processor. Beginning with Chapter 3, which deals with ILP machines, the form of speedup referred to is the performance of an ILP machine compared to the scalar pipelined processor, which is used as the new reference machine.


## 1.4.3.1 Superpipelined Machines. 
A superpipelined machine is defined with respect to the baseline machine and is a machine with higher degrees of pipelining than the baseline machine. In a superpipelined machine, the machine cycle time is shorter than that of the baseline machine and is referred to as the minor cycle time.
The cycle time of a superpipelined machine is 11m of the baseline cycle time, or equivalently there are m minor cycles in the baseline cycle. A superpipelined machine is characterized by OL = 1 cycle = m minor cycles and IL = 1 minor cycle. In other words, the simple instruction still requires one baseline cycle, equal to m minor cycles, for execution, but the machine can issue a new instruction in every minor cycle. Consequently, IP = 1 instruction/minor cycle =m instructions/ cycle, and MP = m X k. The instruction processing profile of a superpipelined machine is shown in Figure 1.10.

A superpipelined machine is a pipe lined machine in which the degree of pipelining is beyond that dictated by the operation latency of the simple instructions.
Essentially superpipelining involves pipelining of the execution stage into multiple stages. An "underpipelined" machine cannot issue instructions as fast as they are executed. On the other hand, a superpipelined machine issues instructions faster than they are executed. A superpipelined machine of degree m, that is, one that takes m minor cycles to execute a simple operation, can potentially achieve better performance than that of the baseline machine by a factor of m. Technically, traditional pipelined computers that require multiple cycles for executing simple operations should be classified as superpipelined. For example, the latency for performing fixed-point addition is three cycles in both the CDC 6600 [Thornton, 1964] and the CRA Y-1 [Russell, 1978], and new instructions can be issued in every cycle.
Hence, these are really superpipelined machines.
In a way, the classification of superpipelined machines is somewhat artificial, because it depends on the choice of the baseline cycle and the definition of a simple operation. The key characteristic of a superpipelined machine is that the result of an instruction is not available to the next m - 1 instructions. Hence, a superpipelined processor can be viewed simply as a more deeply pipelined processor with some restrictions on the placement of forwarding paths. In a standard pipelined processor, the implicit assumption is that the sources and destinations of forwarding paths can be the outputs and inputs, respectively, of any of the pipeline stages. If a superpipelined machine is viewed as a deeply pipelined machine with m x k stages, then the outputs of some of the stages cannot be accessed for forwarding and the inputs of some of the stages cannot receive forwarded data. The reason for this is that some of the operations that require multiple minor cycles and multiple pipeline stages to complete are primitive operations, in the sense of being noninterruptible for the purpose of data forwarding. This is really the key distinction between pipelined and superpipelined machines. In this book, outside of this section, there is no special treatment of superpipelined machines as a separate class of processors distinct from pipelined machines.

The 64-bit MIPS R4000 processor is one of the first processors claimed to be "superpipelined." Internally, the R4000 has eight physical stages in its pipeline, as shown in Figure 1.11, with a physical machine cycle time of 10 nanoseconds (ns) [Bashteen et aI. , 1991 , Mirapuri et aI., 1992]. However, the chip requires a 50MHz clock input and has an on-chip clock doubler. Consequently, the R4000 uses 20 ns as its baseline cycle, and it is considered superpipelined of degree 2 with respect to a four-stage baseline machine with a 20-ns cycle time. There are two minor cycles to every baseline cycle. In the case of the R4000, the multicycle primitive operations are the cache access operations. For example, the first two physical stages (IF and IS) are required to perform the I-cache access, and similarly the DF and DS physical stages are required for D-cache access. These are non interruptible operations; no data forwarding can involve the buffers between the IF and IS stages or the buffers between the DF and DS stages. Cache accesses, here considered "simple" operations, are pipelined and require an operation latency of two (minor) cycles. The issue latency for the entire pipeline is one (minor) cycle; that is, one new instruction can be issued every 10 ns. Potentially the R4000 can achieve a speedup over the baseline four-stage pipeline by a factor of 2.


## 1.4.3.2 Superscalar Machines. 
Superscalar machines are extensions of the baseline scalar pipelined machines and are characterized by OL = 1 cycle, IL = 1 cycle, and IP = n instructions/cycle. The machine cycle is the same as the baseline cycle; there are no minor cycles. A simple operation is executed in one cycle.
In every cycle, multiple instructions can be issued. The superscalar degree is determined by the issue parallelism n, the maximum number of instructions that can be issued in every cycle. The instruction processing profile of a superscalar machine is illustrated in Figure 1.12. Compared to a scalar pipelined processor, a superscalar machine of degree n can be viewed as having n pipelines or a pipeline that is n times wider in the sense of being able to carry n instructions in each pipeline stage instead of one. A superscalar machine has MP = n X k . It has been shown that a superpipelined machine and a superscalar machine of the same degree have the same machine parallelism and can achieve roughly the same level of performance.

There is no reason why a superscalar machine cannot also be superpipelined.
The issue latency can be reduced to 11m of the (baseline) cycle while maintaining the issue parallelism of n instructions in every (minor) cycle. The total issue parallelism or throughput will be n x m instructions per (baseline) cycle. The resultant machine parallelism will become MP = n X m X k, where n is the superscalar degree, m is the superpipelined degree, and k is the degree of pipelining of the baseline machine. Alternatively the machine parallelism can be viewed as MP = n x (m x k), representing a superscalar machine with m X k pipeline stages. Such a machine can be equivalently viewed as a more deeply pipelined processor of m x k stages with superscalar degree n, without having to invoke the tedious term
"superscalar-superpipelined" machine; and we won't.


## 1.4.3.3 Very-Long-Instruction-Word Machines. 
Quite similar to the superscalar machines is another class of ILP machines called VLIW (very long instruction word) machines by Josh Fisher [Fisher, 1983]. The intent and performance objectives are very similar for these two classes of machines; the key difference lies in the placement of the dynamic-static interface (DSI) or the partitioning of what is done at run time via hardware mechanisms and what is done at compile time via software means. The instruction processing profile of a VLIW machine is illustrated in Figure 1.13.

Unlike in a superscalar machine, the IF and DE stages of a VLIW machine need not be replicated to support the simultaneous processing, that is, fetching and decoding, of n separate instructions. In a superscalar machine, the decision of which n instructions are to be issued into the execute stage is made at run time. For a VLIW machine, such an instruction-issuing decision is made at compile time, and the n instructions to be simultaneously issued into the execute stage are determined by the compiler and stored appropriately in the program memory as a very long instruction word.

Superscalar and VLIW machines represent two different approaches to the same ultimate goal, which is achieving high processor performance via instruction-level parallel processing. The two approaches have evolved through different historical paths and from different perspectives. It has been suggested that these two approaches are quite synergistic, and there is a strong motivation for pursuing potential integration of the two approaches. This book focuses on dynamic techniques implemented in the microarchitecture; hence, we will not address in depth
VLIW features that rely on aggressive compile-time techniques.



## 1.5 Summary

Microprocessors have had an unparalleled impact on the computer industry. The changes that have taken place during the lifetime of microprocessors (30+ years) have been phenomenal. Microprocessors are now entering their fourth decade. It is fascinating to speculate on what we can expect from microprocessors in this coming decade.

Although it was the fad of past decades, instruction set architecture (IS A) design is no longer a very interesting topic. We have learned a great deal about how to design an elegant and scalable ISA. However, code compatibility and the software installed base are more crucial in determining the longevity of an ISA. It has been amply shown that any ISA deficiency can be overcome by microarchitecture techniques. Furthermore, with the emergence of portable bytecodes and dynamic just-in-time (JIT) compilation, the meaning of ISA and the consequent placement of the dynamic-static interface (DSI) will become quite blurred.

In the coming decade, microarchitecture will be where the action is. As the chip integration density approaches 1 billion transistors on a die, many of the traditional (macro)architecture features, such as the memory subsystem, multiple processors, and input/output subsystem, will become on-die issues and hence become effectively microarchitecture issues. Traditional system-level architecture will become part of chip-level design. We can expect to see the integration of multiple processors, the cache memory hierarchy, the main memory controller (and possibly even the main memory), input/output devices, and network interface devices on one chip.

We can expect to see many new innovative microarchitecture techniques. As we approach and possibly exceed the IO-GHz clocking speed, we will need to rethink many of the fundamentals of microarchitecture design. A simple ALU operation may take multiple cycles. A sophisticated branch predictor can require up to 10 cycles. Main memory latency will be 1000+ cycles long. It may take tens of clock cycles to traverse the entire die. What we currently think of as very aggressive pipelining will be viewed as rather elementary.

Future microprocessors will become single-chip computing systems that will need to exploit various forms of parallelism. These systems will need to go beyond instruction-level parallelism to harvest thread-level parallelism (TLP) in the workload. Perhaps the most important will be the pursuit of memory-level parallelism (MLP) in being able to process many simultaneous memory accesses. As main memory latency becomes three orders of magnitude slower than the CPU cycle time, we will need to find clever ways of trading the memory bandwidth to mitigate the severe negative impact of long memory latency on overall performance. The main challenge will become the movement of data, not the operations performed on the data.

**REFERENCES**

Acosta, R., J. Kilestrup, and H. Torng: "An instruction issuing approach to enhancing performance in multiple functional unit processors," IEEE Trans. on Computers, C35, 9, 1986, pp. 815-828 .
Agerwala, T ., and J. Cocke: "High performance reduced instruction set processors," Technical report, IBM Computer Science, 1987.
Amdahl, G. : "Validity of the single processor approach to achieving large scale computing capabilities," AFlPS Con! Proc., 1967, pp. 483-485.
Amdahl, G., G. Blaauw, and F. P. Brooks, Jr.: "Architecture of the IBM Systeml360," IBM
Journal of Research and Development, 8, 1964, pp. 87-101.
Bashteen, A., 1. Lui, and J. Mullan: "A superpipeline approach to the MIPS architecture,"
Proc. COMPCON Spring 91, 1991, pp. 325-333 .
Blaauw, G., and F. P. Brooks, Jr.: Computer Architecture: Concepts and Evolution . Reading, MA: Addison-Wesley, 1997.
Black, B., and J. P. Shen: "Calibration of microprocessor performance models," Computer,
31,5,1998, pp. 59-65.
Butler, M., T.-Y. Yeh, Y. Patt, M. Alsup, H. Scales, and M. Shebanow: "Instruction level parallelism is greater than two," Proc. 18th Int. Symposium on Computer Architecture,
1991 , pp. 276-286.
Colwell, R., C. Hitchcock, E. Jensen, H. B. Sprunt, and C. Kollar: "Instructions sets and beyond: computers, complexity, and controversy," IEEE Computer. 18,9, 1985, pp. 8-19.
Fisher, J.: "Trace scheduling: A technique for global microcode compaction. IEEE Trans.
on Computers." C-30, 7,1981 , pp. 478-490.
Fisher, J. A. : "Very long instruction word architectures and the ELI-512," Technical Report
YLU 253, Yale University, 1983.
Flynn, M., and L. Hoevel: "Execution architecture: the DELtran experiment," iEEE Trans.
on Computers. C-32, 2, 1983, pp. 156-175.
Johnson, M.: Superscalar Microprocessor Design. Englewood Cliffs, NJ: Prentice Hall, 1991.
Jouppi, N. P., and D. W. Wall: "Available instruction-level parallelism for superscalar and superpipelined machines," Proc. Third Int. Can! on Architectural Support for Programming Languages and Operating Systems (ASPLOS-lll). 1989, pp. 272-282.
Kuck, D., Y. Muraoka, and S. Chen : "On the number of operations simultaneously executable in Fortran-like programs and their resulting speedup," IEEE Tran s. on Computers.
C-21 , 1972,p~ 1293-131Q
Melvin, S., and Y. Patt: "Exploiting fine-grained parallelism through a combination of hardware and software techniques," Proc. 181h Int. Symposium on Computer Architecture.
1991 , pp. 287-296.
Melvin, S. W., and Y. Patt: "A clarification of the dynamic/static interface," Proc. 20th
Annual Hawaii Int. Can! on System Sciences. 1987, pp. 218-226.
Mirapuri , S., M. Woodacre, and N. Vasseghi : "The MIPS R4000 processor," IEEE Micro,
12, 2, 1992, pp. 10-22.
Nicolau, A., and 1. Fisher: "Measuring the parallelism available for very long instruction word architectures," IEEE Transactions on Computers, C-33 , 1984, pp. 968-976.
Riseman, E. M., and C. C. Foster: "The inhibition of potential parallelism by conditional jumps," IEEE Transactions on Computers, 1972, pp. 1405-1411.
Russell , R. M.: "The Cray-I Computer System," Communications of the ACM, 21, I, 1978, pp. 63-72.
Smith, M. D. , M. Johnson, and M. A. Horowitz: "Limits on multiple instruction issue,"
Proc. Third into Can! on Architectural Support for Programming Languages and Operating
Systems (ASPLOS-lll). 1989, pp. 290-302.
Sodani, A. , and G. S. Sohi : "Dynamic instruction reuse," Proc. 24th Annual Int. Symposium on Computer Architecture, 1997, pp. 194- 205 .
Sohi, G., and S. Vajapeyam: "Instruction issue logic for high-performance, interruptible pipelined processors," Proc. 14th Annual Int. Symposium on Computer Architecture, 1987, pp. 27- 34.
Stone, H.: High-Performance Computer Architecture. Reading, MA: Addison-Wesley, 1987.
Thornton, J. E.: "Parallel operation in the Control Data 6600," AFlPS Proc. FlCC, part 2,
26, 1964, pp.33-40.
Tjaden, G., and M. Flynn : "Representation of concurrency with ordering matrices," IEEE
Trans. on Computers. C-22, 8, 1973, pp. 752- 761.
Tjaden, G. S., and M. J. Flynn: "Detection and parallel execution of independent instructions," IEEE Transactions on Computers, C 19, 10, 1970, pp. 889-895.
Uhl, A., and R. Wedig: "Hardware extraction of low-level concurrency from a serial instruction stream," Proc. Int. Con! on Parallel Processing, 1986, pp. 729- 736.
Wall, D.: "Limits of instruction-level parallelism," Proc. 4th Int. Con! on Architectural
Supportfor Programming Languages and Operating Systems, 1991, pp. 176-188.
Wedig, R.: Detection of Concurrency in Directly Executed Language Instruction Streams.
PhD thesis, Stanford University , 1982.
Weiss, S., and 1. Smith: "Instruction issue logic in pipelined supercomputers," Proc. 11th
Annual Symposium on Computer Architecture, 1984, pp. 110- 118.

**HOMEWORK PROBLEMS**
P1.1 Using the resources of the World Wide Web, list the top five reported benchmark results for SPECINT2000, SPECFP2000, and TPC-C.
P1.2 Graph SPECINT2000 vs. processor frequency for two different processor families (e.g., AMD Athlon and HP PA-RISC) for as many frequencies as are posted at www.spec.org. Comment on performance scaling with frequency , pointing out any anomalies and suggesting possible explanations for them.
P1.3 Explain the differences between architecture, implementation, and realization. Explain how each of these relates to processor performance as expressed in Equation (1.1).
P1.4 As silicon technology evolves, implementation constraints and tradeoffs change, which can affect the placement and definition of the dynamicstatic interface (DSI). Explain why architecting a branch delay slot [as in the millions of instructions per second (MIPS) architecture] was a reasonable thing to do when that architecture was introduced, but is less attractive today.

P1.5 Many times, implementation issues for a particular generation end up determining tradeoffs in instruction set architecture. Discuss at least one historical implementation constraint that explains why CISC instruction sets were a sensible choice in the 1970s.
P1.6 A program's run time is determined by the product of instructions per program, cycles per instruction, and clock frequency. Assume the following instruction mix for a MIPS-like RISC instruction set: 15% stores, 25% loads, 15% branches, and 35% integer arithmetic, 5% integer shift, and 5% integer multiply. Given that load instructions require two cycles, stores require one cycle, branches require four cycles, integer ALU instructions require one cycle, and integer multiplies require ten cycles, compute the overall CPI.

P1.7 Given the parameters of Problem 6, consider a strength-reducing optimization that converts multiplies by a compile-time constant into a
sequence of shifts and adds. For this instruction mix, 50% of the multiplies can be converted to shift-add sequences with an average length of three instructions. Assuming a fixed frequency, compute the change in instructions per program, cycles per instruction, and overall program speedup.

P1.8 Recent processors like the Pentium 4 processors do not implement singlecycle shifts. Given the scenario of Problem 7, assume that s = 50% of the additional instructions introduced by strength reduction are shifts, and shifts now take four cycles to execute. Recompute the cycles per instruction and overall program speedup. Is strength reduction still a good optimization?
P1.9 Given the assumptions of Problem 8, solve for the break-even ratio s
(percentage of additional instructions that are shifts). That is, find the value of s (if any) for which program performance is identical to the baseline case without strength reduction (Problem 6).
P1.10 Given the assumptions of Problem 8, assume you are designing the shift unit on the Pentium 4 processor. You have concluded there are two possible implementation options for the shift unit: four-cycle shift latency at a frequency of 2 GHz, or two-cycle shift latency at 1.9 GHz.
Assume the rest of the pipeline could run at 2 GHz, and hence the twocycle shifter would set the entire processor's frequency to 1.9 GHz.
Which option will provide better overall performance?
P1.11 Using Amdahl's law, compute speedups for a program that is 85% vectorizable for a system with 4, 8, 16, and 32 processors. What would be a reasonable number of processors to build into a system for running such an application?
P1.12 Using Amdahl's law, compute speedups for a program that is 98% vectorizable for a system with 16, 64, 256, and 1024 processors. What would be a reasonable number of processors to build into a system for running such an application?
P1.13 Replot the graph in Figure 1.8 on page 23 for each of the ILP limits shown in the list of studies in Section 1.4.2. What conclusions can you draw from the graphs you created?
P1.14 Compare and contrast these two ILP limit studies by reading the relevant papers and explaining why the limits are so different: Jouppi and Wall [1989] vs. Wall [1991].
P1.15 In 1995, the IBM AS/400 line of computers transitioned from a CISC instruction set to a RISC instruction set. Because of the simpler instruction set, the realizable clock frequency for a given technology generation and the CPI metric improved dramatically. However, for the same reason, the number of instructions per program also increased noticeably.
Given the following parameters, compute the total performance improvement that occurred with this transition. Furthermore, compute the break-even clock frequency, break-even cycles per instruction, and break-even code expansion ratios for this transition, assuming the other two factors are held constant.

P1.16 MIPS (millions of instructions per second) was commonly used to gauge computer system performance up until the 1980s. Explain why it can be a very poor measure of a processor's performance. Are there any circumstances under which it is a valid measure of performance? If so, describe those circumstances.
P1.17 MFLOPS (millions of floating-point operations per second) was commonly used to gauge computer system performance up until the 1980s.
Explain why it can be a very poor measure of a processor's performance. Are there any circumstances under which it is a valid measure of performance? If so, describe those circumstances.

**Terms and Buzzwords**
These problems are similar to the "Jeopardy Game" on TV. The answers are shown and you are to provide the best correct questions. For each answer there may be more than one appropriate question; you need to provide the best one.

P1.18 A: Instruction-level parallelism within a basic block is typically upper bounded by 2.
Q: What is _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ?

P1.19 A: It will significantly reduce the machine cycle time, but can increase the branch penalty.
Q: What is _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ?

P1.20 A: Describes the speedup achievable when some fraction of the program execution is not parallelizable.
Q:Whatis _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ?
P1.21 A: A widely used solution to Flynn's bottleneck.
Q: What is _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ?

P1.22 A: The best way to describe a computer system's performance.
Q: What is _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ?

Pl.23 A: This specifies the number of registers, available addressing modes, and instruction opcodes.
Q: What is _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ?

P1.24 A: This determines a processor's configuration and number of functional units.
Q:Whatis _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ?

P1.25 A: This is a type of processor that relies heavily on the compiler to statically schedule independent instructions.
Q: What is _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ?

P1.26 A: This is a type of processor where results of instructions are not available until two or more cycles after the instruction begins execution.
Q: What is _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ?

P1.27 A: This is a type of processor that attempts to execute more than one instruction at the same time.
Q: What is _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ?

P1.28 A: This important study showed that instruction-level parallelism was abundant, if only control dependences could somehow be overcome.
Q: What is _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ?

P1.29 A : This is a type of processor that executes high-level languages without the aid of a compiler.
Q: What is _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ?

P1.30 A: This approach to processor simulation requires substantial storage space.
Q: What is _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ?

