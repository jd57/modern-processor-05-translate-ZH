Intel's P6 Microarchitecture



* 7.1 Introduction 
* 7.2 Pipelining 
* 7.3 The In-Order Front End 
* 7.4 The Out-of-Order Core 
* 7.5 Retirement 
* 7.6 Memory Subsystem 
* 7.7 Summary 
* 7.8 Acknowledgments
* References
* Homework Problems

In 1990, Intel began development of a new 32-bit Intel Architecture (IA32) microarchitecture core known as the P6. Introduced as a product in 1995 [Colwell and Steck, 1995], it was named the Pentium Pro processor and became very popular in workstation and server systems. A desktop proliferation of the P6 core, the Pentium II processor, was launched in May 1997, which added the MMX instructions to the basic P6 engine. The P6-based Pentium III processor followed in 1998, which included MMX and SSE instructions. This chapter refers to the core as the P6 and to the products by their respective product names.

The P6 microarchitecture is a 32-bit Intel Architecture-compatible, highperformance, superpipelined dynamic execution engine. It is order-3 superscalar and uses out-of-order and speculative execution techniques around a micro-dataflow execution core. P6 includes nonblocking caches and a transactions-based snooping bus. This chapter describes the various components of the design and how they combine to deliver extraordinary performance on an economical die size.




## 7.1 Introduction

The basic block diagram of the P6 microarchitecture is shown in Figure 7.1. There are three basic sections to the microarchitecture: the in-order front end, an out-of-order middle, and an in-order back-end "retirement" process. To be Intel Architecturecompatible, the machine must obey certain conventions on execution of its program code. But to achieve high performance, it must relax other conventions, such as execution of the program's operators strictly in the order implied by the program itself.

True data dependences must be observed, but beyond that, only certain memory ordering constraints and the precise faulting semantics of the IA32 architecture must be guaranteed.
To maintain precise faulting semantics, the processor must ensure that asynchronous events such as interrupts and synchronous but awkward events such as faults and traps will be handled in exactly the same way as they would have in an i486 system. 1 This implies an in-order retirement process that reimposes the original program ordering to the commitment of instruction results to permanent architectural External bus

I Branches and faults use the same mechanism to recover state. However, for performance reasons, branches clear and restart the front end as early as possible. Page faults are handled speculatively, but floating-point faults are handled only when the machine is sure the faulted instructions were on the path of certain execution.details of all three sections of the machine in the remainder of this chapter.

There are many novel aspects to this microarchitecture. For instance, it is almost universal that processors have a central controller unit somewhere that monitors and controls the overall pipeline. This controller "understands" the state of the instructions flowing through the pipeline, and it governs and coordinates the changes of state that constitute the computation process. The P6 microarchitecture purposely avoids having such a centralized resource. To simplify the hardware in the rest of the machine, this microarchitecture translates the Intel Architecture instructions into simple, stylized atomic units of computation called micro-operations (micro-ops or Uops). All that the microarchitecture knows about the state of a program's execution, and the only way it can change its machine state, is through the manipulation of these Uops.

The P6 microarchitecture is very deeply pipelined, relative to competitive designs of its era. This deep pipeline is implemented as several short pipe segments connected by queues. This approach affords a much higher clock rate, and the negative effects of deep pipelining are ameliorated by an advanced branch predictor, very fast high-bandwidth access to the L2 cache, and a much higher clock rate (for a given semiconductor process technology).

This microarchitecture is a speculative, out-of-order engine. Any engine that speculates can also misspeculate and must provide means to detect and recover from that condition. To ensure that this fundamental microarchitecture feature would be implemented as error-free as humanly possible, we designed the recovery mechanism to be extremely simple. Taking advantage of that simplicity, and the fact that this mechanism would be very heavily validated, we mapped the machine's event-handling events (faults, traps, interrupts, breakpoints) onto the same set of protocols and mechanisms.

The front-side bus is a change from Intel' s Pentium processor family. It is transaction-oriented and designed for high-performance mUltiprocessing systems.
Figure 7.2 shows how up to four Pentium Pro processors can be connected to a single shared bus. The chipset provides for main memory, through the data path (DP) and data controller (DC) parts, and then through the memory interface controller (MIC) chip. I/O is provided via the industry standard PCI bus, with a bridge to the older Extended Industry Standard Architecture (EISA) standard bus.

Various proliferations of the P6 had chipsets and platform designs that were optimized for multiple market segments including the (1) high-volume, (2) workstation, (3) server, and (4) mobile market segments. These differed mainly in the amount and type of memory that could be accommodated, the number of CPUs that could be supported in a single platform, and L2 cache design and placement. The Pentium II processor does not use the two-die-in-a-package approach of the original Pentium Pro; that approach yielded a very fast system product but was expensive to manufacture due to the special ceramic dual-cavity package and the unusual manufacturing steps required. P6-based CPUs were packaged in several formats (see Figure 7.3):

* Slot 1 brought the P6 microarchitecture to volume price points, by combining one P6 CPU with two commodity cache RAMs and a tag chip on one FR4 fiberglass substrate cartridge. This substrate has all its electrical contacts contained in one edge connector, and a heat sink attached to one side of the packaged substrate. Slot 1' s L2 cache runs at one-half the clock frequency of the CPU.

* Slot 2 is physically larger than Slot 1, to allow up to four custom SRAMs to form the very large caches required by the high-performance workstation and server markets. Slot 2 cartridges are carefully designed so that, despite the higher number of loads on the L2 bus, they can access the large L2 cache at the full clock frequency of the CPU.

* With improved silicon process technology, in 1998 Intel returned to pingrid-array packaging on the Celeron processor, with the L2 caches contained on the CPU die itself. This obviated the need for the Pentium Pro' s two-die-in-a-package or the Slot I/Slot 2 cartridges.


### 7.1.1 Basics of the P6 Microarchitecture

In subsequent sections, the operation of the various components of the microarchitecture will be examined. But first, it may be helpful to consider the overall machine organization at a higher level.
A useful way to view the P6 microarchitecture is as a dataflow engine, fed by an aggressive front end, constrained by implementation and code compatibility. It is not difficult to design rnicroarchitectures that are capable of expressing instructionlevel parallelism; adding multiple execution units is trivial. Keeping those execution units gainfully employed is what is hard.

The P6 solution to this problem is to
* Extract useful work via deep speculation on the front end (instruction cache, decoder, and register renaming).
* Provide enough temporary storage that a lot of work can be "kept in the air." * Allow instructions that are ready to execute to pass others that are not (in the out-of-order middle section).
* Include enough memory bandwidth to keep up with all the work in progress.
When speculation is proceeding down the right path, the Uops generated in the front end flow smoothly into the reservation station (RS), execute when all their data operands have become available (often in an order other than that implied by the source program), take their place in the retirement line in the reorder buffer (ROB), and retire when it is their turn.

Micro-ops carry along with them all the information required for their scheduling, dispatch, execution, and retirement. Micro-ops have two source references, one destination, and an operation-type field. These logical references are renamed in the register alias table (RAT) to physical registers residing in the ROB.

When the inevitable misprediction occurs? a very simple protocol is exercised within the out-of-order core. This protocol ensures that the out-of-order core flushes the speculative state that is now known to be bogus, while keeping any other work that is not yet known to be good or bogus. This same protocol directs the front end to drop what it was doing and start over at the mispredicted target's correct address.

Memory operations are a special category of Uop. Because the IA32 3 instruction set architecture has so few registers, IA32 programs must access memory frequently. This means that the dependency chains that characterize a program generally start with a memory load, and this in turn means that it is important that loads be speculative. (If they were not, all the rest of the speculative engine would be starved while waiting for loads to go in order.) But not all loads can be speculative; consider a load in a memory-mapped 110 system where the load has a nonrecoverable side effect. Section 7.6 will cover some of these special cases. Stores are never speCUlative, there being no way to "put back the old data" if a misspeculated store were later found to have been in error. However, for performance reasons, store data can be forwarded from the store buffer (SB), before the data have actually 

2 For instance, on the first encounter with a branch, the branch predictor does not "know" there is a branch at all, much less which way the branch might go.

This chapter uses IA32 to refer to the standard 32-bit Intel Architecture, as embodied in processors such as the Intel 486, or the Pentium, Pentium II , Pentium 1II, and Pentium 4 processors.proceed. This is closely analogous to a writeback cache, where data can be loaded from a cache that has not yet written its data to main memory.

Because of IA32 coding semantics, it is important to carefully control the transfer of information from the out-of-order, speculative engine to the permanent machine state that is saved and restored in program context switches. We call this "retirement." Essentially, all the machine's activity up until this point can be undone. Retirement is the act of irrevocably committing changes to a program's state. The P6 microarchitecture can retire up to three Uops per clock cycle, and therefore can retire as many as three IA32 instructions' worth of changes to the permanent state. (If more than three ops are needed to express a given IA32 instruction, the retirement process makes sure the necessary all-or-none atomicity is obeyed.) 



## 7.2 Pipelining

We will examine the individual elements of the P6 micro-architecture in this chapter, but before we look at the pieces, it may help to see how they all fit together.
The pipeline diagram of Figure 7.4 may help put the pieces into perspective. The first thing to note about the figure is that it appears to show many separate pipelines, rather than one single pipeline. This is intentional; it reflects both the philosophy and the design of the microarchitecture.
The pipeline segments are in three clusters. First is the in-order front end, second is the out-of-order core, and third is the retirement. For reasons that should become clear, it is essential that these pipeline segments be separable operationally. For example, when recovering from a mispredicted branch, the front end of the machine will immediately flush the bogus information it had been processing from the mispredicted target address and will refetch the corrected stream from the corrected branch target, and all the while the out-of-order core continues working on previously fetched instructions (up until the mispredicted branch).

It is also important to separate the overall pipeline into independent segments so that when the various queues happen to fill up, and thus require their suppliers to stall until the tables have drained, only as little of the overall machine as necessary stalls, not the entire machine.


### 7.2.1 In-Order Front-End Pipeline

The first stage (pipe stage 114) of the in-order front-end pipeline is used by the branch target buffer (BTB) to generate a pointer for the instruction cache (I-cache) to use, in accessing what we hope will be the right set of instruction bytes.

Remember that the machine is always speCUlating, and this guess can be wrong; if it is, the error will be recognized at one of several places in the machine and a misprediction recovery sequence will be initiated at that time.

The second pipe stage in the in-order pipe (stage 12) initiates an I-cache fetch at the address that the BTB generated in pipe stage 11. The third pipe stage (stage 13) continues the I-cache access. The fourth pipe stage (stage 14) completes the I-cache fetch and transfers the newly fetched cache line to the instruction decoder (lD) so it can commence decoding.

Pipe stages 15 and 16 are used by the ID to align the instruction bytes, identify the ends of up to three IA32 instructions, and break these instructions down into sequences of their constituent Uops.

Pipe stage 17 is the stage where part of the ID can detect branches in the instructions it has just decoded. Under certain conditions (e.g., an unpredicted but unconditional branch), the ID can notice that a branch went unpredicted by the BTB (probably because the BTB had never seen that particular branch before) and can flush the in-order pipe and refetch from the branch target, without having to wait until the branch actually tries to retire many cycles in the future .Here the register alias table (RAT) renames Uop destination/source linkages to a large set of physical registers in the reorder buffer. 

In pipe stage 22, the RAT transfers the Uops (three at a time, since the P6 microarchitecture is an order-3 superscalar) to the out-of-order core. Pipe stage 22 marks the transition from the in-order section to the out-of-order section of the machine. The Uops making this transition are written into both the reservation station (where they will wait until they can execute in the appropriate execution unit) and the reorder buffer (where they "take a place in line," so that eventually they can commit their changes to the permanent machine state in the order implied by the original user program).




### 7.2.2 Out-of-Order Core Pipeline

Once the in-order front end has written a new set of (up to) three Uops into the reservation station, these Uops become possible candidates for execution. The RS takes several factors into account when deciding which Uops are ready for execution: The Uop must have all its operands available; the execution unit (EU) needed by that Uop must be available; a writeback bus must be ready in the cycle in which the EU will complete that Uop's execution; and the RS must not have other Uops that it thinks (for whatever reason) are more important to overall performance than the Uop under discussion. Remember that this is the out-of-order core of the machine. The RS does not know, and does not care about, the original program order. It only observes data dependences and tries to maximize overall performance while doing so.

One implication of this is that any given Uop can wait from zero to dozens or even hundreds of clock cycles after having been written into the RS. That is the point of the RS scheduling delay label on Figure 7.4. The scheduling delay can be as low as zero, if the machine is recovering from a rnispredicted branch, and these are the [lrst "known good" Uops from the new instruction stream. (There would be no point to writing the Uops into the RS, only to have the RS "discover" that they are data-ready two cycles later. The ftrst Uop to issue from the in-order section is guaranteed to be dependent on no speCUlative state, because there is no more speculative state at that point!) Normally, however, the Uops do get written into the RS, and there they stay until the RS notices that they are data-ready (and the other constraints previously listed are satisfied). It takes the RS two cycles to notice, and then dispatch, Uops to the execution units. These are pipe stages 31 and 32.

Simple, single-cycle-execution Uops such as logical operators or simple arithmetic operations execute in pipe stage 33. More complex operations, such as integer multiply, or floating-point operations, take as many cycles as needed.
One-cycle operators provide their results to the writeback bus at the end of pipe stage 33. The writeback busses are a shared resource, managed by the RS, so the RS must ensure that there will be a writeback bus available in some future cycle for a given Uop at the time the Uop is dispatched. Writeback bus scheduling occurs in pipe stage 82, with the writeback itself in the execution cycle, 83 (which is synonymous with pipe stage 33).

5 Why

do some pipe stages have more than one name? Because the pipe segments are independent. Sometimes part of one pipe segment lines up with one stage of a different pipe segment, and sometimes with another.
Memory operations are a bit more complicated. All memory operations must first generate the effective address, per the usual IA32 methods of combining segment base, offset, base, and index. The Uop that generates a memory address executes in the address generation unit (AGU) in pipe stage 33. The data cache (OCache) is accessed in the next two cycles, pipe stages 42 and 43. If the access is a cache hit, the accessed data return to the RS and become available as a source to other Uops .

If the OCache reference was a miss, the machine tries the L2 cache. If that misses, the load Uop is suspended (no sense trying it again any time soon; we must refill the miss from main memory, which is a slow operation). The memory ordering buffer (MOB) maintains the list of active memory operations and will keep this load Uop suspended until its cache line refill has arrived. This conserves cache access bandwidth for other Uop sequences that may be independent of the suspended Uop; these other Uops can go around the suspended load and continue making forward progress. Pipe stage 40 is used by the MOB to identify and "wake up" the suspended load. Pipe stage 41 re-dispatches the load to the OCache, and (as earlier) pipe stages 42 and 43 are used by the OCache in accessing the line. This MOB scheduling delay is labeled in Figure 7.4.




### 7.2.3  Retirement Pipeline
Retirement is the act of transferring the speculative state into the permanent, irrevocable architectural machine state. For instance, the speculative out-of-order core may have a Uop that wrote OxFA as its instruction result into the appropriate field of ROB entry 14. Eventually, if no mispredicted branch is found in the interim, it will become that Uop ' s tum to retire next, when it has become the oldest Uop in the machine. At that point, the Uop's original intention (to write OxFA into, e.g., the EAX register) is realized by transferring the OxFA data in ROB Slot 14 to the retirement register file's (RRF) EAX register.

There are several complicating factors to this simple idea. First, what the ROB is actually retiring should not be viewed as just a sequence of Uops, but rather a series of IA32 instructions. Since it is architecturally illegal to retire only part of an IA32 instruction, then either all Uops comprising an IA32 instruction retire, or none do. This atomicity requirement generally demands that the partially modified architectural state never be visible to the world outside the processor. So part of what the ROB must do is to detect the beginning and end of a given IA32 instruction and to make sure the atomicity rule is strictly obeyed. The ROB does this by observing some marks left on the Uops by the instruction decoder (10): some Uops are marked as the first Uop in an IA32 instruction, and others are marked as last.

(Obviously, others are not marked at all, implying they are somewhere in the middle of an IA32 Uop sequence.) While retiring a sequence of Uops that comprise an IA32 instruction, no external events can be handled. Those simply have to wait, just as they do in previous generations of the Intel Architecture (i486 and Pentium processors, for instance). But between two IA32 instructions, the machine must be capable of taking interrupts, breakpoints, traps, handling faults, and so on. The reorder buffer makes sure that these events are only possible at the right times and that multiple pending events are serviced in the priority order implied by the Intel instruction set architecture.through, switch to a microcode assist routine, perform some number of Uops, and then resume the flow at the point of interruption, however. In that sense, an instruction may be considered to be partially executed at the time the trap is taken.

The first part of the instruction cannot be discarded and restarted, because this would prevent forward progress. This kind of behavior occurs for TLB updates, some kinds of floating-point assists, and more.
The reorder buffer is implemented as a circular list of Uops, with one retirement pointer and one new-entry pointer. The reorder buffer writes the results of a justexecuted Uop into its array in pipe stage 22. The Uop results from the ROB are read in pipe stage 82 and committed to the permanent machine state in the RRF in pipe stage 93.




## 7.3 The In-Order Front End

The primary responsibility of the front end is to keep the execution engine full of useful work to do. On every clock cycle, the front end makes a new guess as to the best I-cache address from which to fetch a new line, and it sends the cache line guessed from the last clock to the decoders so they can get started. This guess can, of course, be discovered to have been incorrect, whereupon the front end will later be redirected to where the fetch really should have been from. A substantial performance penalty occurs when a mispredicted branch is discovered, and a key challenge for a microarchitecture such as this one is to ensure that branches are predicted correctly as often as possible, and to minimize the recovery time when they are found to have been mispredicted. This will be discussed in greater detail shortly.

The decoders convert up to three IA instructions into their corresponding Uops (or Uop flows , if the IA instructions are complex enough) and push these into a queue. A register renamer assigns new physical register designators to the source and destination references of these Uops , and from there the Uops issue to the outof-order core of the machine.

As implied by the pipelining diagram in Figure 7.4, the in-order front end of the P6 microarchitecture runs independently from the rest of the machine. When a mispredicted branch is detected in the out-of-order core [in the jump execution unit (JEU)] , the out-of-order core continues to retire Uops older than the mispredicted branch Uop, but flushes everything younger. Refer to Figure 7.5. Meanwhile, the front end is immediately flushed and begins to refetch and decode instructions starting at the correct branch target (supplied by the JEU). To simplify the handoff between the in-order front end and the out-of-order core, the new Uops from the corrected branch target are strictly quarantined from whatever Uops remain in the out-of-order core, until the out-of-order section has drained. Statistically, the out-of-order core will usually have drained by the time the new FE2 Uops get through the in-order front end.



### 7.3.1 Instruction Cache and ITLB

The on-chip instruction cache (I-cache) performs the usual function of serving as a repository of recently used instructions. Figure 7.6 shows the four pipe stages of the instruction fetch unit (IFU). In its first pipe stage (pipe stage 11), the IFU 2

selects the address of the next cache access. This address is selected from a number of competing fetch requests that arrive at the IFU from (among others) the BTB and branch address calculator (BAC). The IFU picks the request with the highest priority and schedules it for service by the second pipe stage (pipe stage 12).

In the second pipe stage, the IFU accesses its many caches and buffers using the fetch address selected by the previous stage. Among the caches and buffers accessed are the instruction cache and the instruction streaming buffer. If there is a hit in any of these caches or buffers, instructions are read out and forwarded to the third pipe stage. If there is a miss in all these buffers, an external fetch is initiated by sending a request to the external bus logic (EBL).

Two other caches are also accessed in pipe stage 12 using the same fetch address: the ITLB in the IFU and the branch target buffer (BTB). The ITLB access obtains the physical address and memory type of the fetch, and the BTB access obtains a branch prediction. The BTB takes two cycles to complete one access. In the third pipe stage (13), the IFU marks the instructions received from the previous stage (12). Marking is the process of determining instruction boundaries. Additional marks for predicted branches are delivered by the BTB by the end of pipe stage 13. Finally, in the fourth pipe stage (14), the instructions and their marks are written into the instruction buffer and optionally steered to the 10, if the instruction buffer is empty.Data from L2 address

The fetch address selected by pipe stage 11 for service in pipe stage 12 is a linear address, not a virtual or physical address. In fact, the IFU is oblivious to virtual addresses and indeed all segmentation. This allows the IFU to ignore segment boundaries while delaying the checking of segmentation-related violations to units downstream from the IFU in the P6 pipeline. The IFU does, however, deal with paging. When paging is turned off, the linear fetch address selected by pipe stage 11 is identical to the physical address and is directly used to search all caches and buffers in pipe stage 12. However, when paging is turned on, the linear address must be translated by the ITLB into a physical address. The virtual to linear to physical sequence is shown in Figure 7.7.

The IFU caches and buffers that require a physical address (actually, untranslated bits, with a match on physical address) for access are the instruction cache, the instruction streaming buffer, and the instruction victim cache. The branch target buffer is accessed using the linear fetch address. A block diagram of the front end, and the BTB's place in it, is shown in Figure 7.6.


### 7.3.2 Branch Prediction

The branch target buffer has two major functions: to predict branch direction and to predict branch targets. The BTB must operate early in the instruction pipeline to prevent the machine from executing down a wrong program stream. (In a speculative engine such as the P6, executing down the wrong stream is, of course, a performance issue, not a correctness issue. The machine will always execute correctly, the only question is how quickly.)

The branch decision (taken or not taken) is known when the jump execution unit (JEU) resolves the branch (pipe stage 33). Cycles would be wasted were the machine to wait until the branch is resolved to start fetching the instructions after the branch.
To avoid this delay, the BTB predicts the decision of the branch as the IFU fetches it (pipe stage 12). This prediction can be wrong. The machine is able to detect this case and recover. All predictions made by the BTB are verified downstream by either the branch address calculator (pipe stage 17) or the JEU (pipe stage 33).

The BTB takes the starting linear address of the instructions being fetched and produces the prediction and target address of the branch instructions being fetched. This information (prediction and target address) is sent to the IFU, and the next cache line fetch will be redirected if a branch is predicted taken. A branch's entry in the BTB is updated or allocated in the BTB cache only when the JEU resolves it. A branch update is sometimes too late to help the next instance of the branch in the instruction stream. To overcome this delayed update problem, branches are also speculatively updated (in a separately maintained BTB state) when the BTB makes a prediction (pipe stage 13).



#### 7.3.2.1  Branch Prediction Algorithm. 
Dynamic branch prediction in the P6
BTB is related to the two-level adaptive training algorithm proposed by Yeh and Patt [1991]. This algorithm uses two levels of branch history information to make predictions. The first level is the history of the branches. The second level is the branch behavior for a specific pattern of branch history. For each branch, the BTB keeps N bits of "real" branch history (i.e., the branch decision for the last N dynamic occurrences). This history is called the branch history register (BHR).(PT). The state for a given pattern is used to predict how the branch will act the next time it is seen. The states in the pattern table are updated using Lee and Smith's [1984] saturating up-down counter.

The BTB uses a 4-bit semilocal pattern table per set. This means 4 bits of history are kept for each entry, and all entries in a set use the same pattern table (the four branches in a set share the same pattern table). This has equivalent performance to a lO-bit global table, with less hardware complexity and a smaller die area. A speculative copy of the BHR is updated in pipe stage 13, and the real one is updated upon branch resolution in pipe stage 83. But the pattern table is updated only for conditional branches, as they are computed in the jump execution unit.

To obtain the prediction of a branch, the decision of the branch (taken or not taken) is shifted into the old history pattern of the branch, and this field is used to index the pattern table. The most significant bit of the state in the pattern table indicates the prediction used the next time it is seen. The old state indexed by the old history pattern is updated using the Lee and Smith state machine.

An example of how the algorithm works is shown in Figure 7.8. The history of the entry to be updated is 0010, and the branch decision was taken. 

Two processes occur in parallel:

1.  The new history is used to access the pattern table to get the new prediction bit. This prediction bit is written into the BTB in the next phase.
2. The old history is used to access the pattern table to get the state that has to be updated.
The updated state is then written back to the pattern table.

history 0101 is used to index into the pattern table and the new prediction 1 for the branch (the most significant bit of the state) is obtained. The old history 0010 is used to index the pattern table to get the old state 10. The old state 10 is sent to the state machine along with the branch decision, and the new state 11 is written back into the pattern table.

The BTB also maintains a 16-deep return stack buffer to help predict returns.
For circuit speed reasons, BTB accesses require two clocks. This causes predictedtaken branches to insert a one-clock fetch "bubble" into the front end. The doublebuffered fetch lines into the instruction decoder and the ID's output queue help eliminate most of these bubbles in normal execution. A block diagram of the BTB is shown in Figure 7.9.



### 7.3.3  Instruction Decoder
The first stage of the ID is known as the instruction steering block (lSB) and is responsible for latching instruction bytes from the IFU, picking off individual instructions in order, and steering them to each of the three decoders. The ISB !

quickly detects how many instructions are decoded each clock to make a fast determination of whether or not the instruction buffer is empty. If empty, it enables the latch to receive more instruction bytes from the IFU (refer to Figure 7.10).
There are other miscellaneous functions performed by this logic as the "front end" of the ID. It detects and generates the correct sequencing of predicted branches. In addition, the ID front end generates the valid bits for the Uops produced by the decode PLAs and detects stall conditions in the ID.

Next, the instruction buffer loads 16 bytes at a time from the IFU. These data are aligned such that the first byte in the buffer is guaranteed to be the first byte of a complete instruction. The average instruction length is 2.7 to 3.1 bytes. This means that on average five to six complete instructions will be loaded into the buffer. Loading a new batch of instruction bytes is enabled under any of the following conditions:

* A processor front-end reset occurs due to branch misprediction.
* All complete instructions currently in the buffer are successfully decoded.
* A BTB predicted-taken branch is successfully decoded in any of the three decoders.
Steering three properly aligned macro-instructions to three decoders in one clock is complicated due to the variable length of IA32 instructions. Even determining the length of one instruction itself is not straightforward, as the first bytes of an instruction must be decoded in order to interpret the bytes that follow. Since the process of steering three variable-length instructions is inherently serial, it is helpful to know beforehand the location of each macro-instruction's boundaries. The instruction length decoder (ILD), which resides in the IFU, performs this pre-decode function. It scans the bytes of the macro-instruction stream locating instruction boundaries and marking the first opcode and end-bytes of each. In addition, the IFU marks the bytes to indicate BTB branch predictions and code breakpoints.

There may be from 1 to 16 instructions loaded into the instruction buffer during each load. Each of the first three instructions is steered to one of three decoders. If the instruction buffer does not contain three complete instructions, then as many as possible are steered to the decoders. The steering logic uses the first opcode markers to align and steer the instructions in parallel.

Since there may be up to 16 instructions in the instruction buffer, it may take several clocks to decode all of them. The starting byte location of the three instructions steered in a given clock may lie anywhere in the buffer. Hardware aligns three instructions and steers them to the three decoders.

Even though three instructions may be steered to the decoders in one cycle, all three may not get successfully decoded. When an instruction is not successfully decoded, then that specific decoder is flushed and all Uops resulting from that decode attempt will be invalidated. It can take multiple cycles to consume (decode) all the instructions in the buffer. The following situations result in the invalidation of Uops and the resteering of their corresponding macro-instructions to another decoder during a subsequent cycle:

* If a complex macro-instruction is detected on decoder 0, requiring assis- 
tance from the microcode sequencer (MS) microcode read-only memory (UROM), then the Uops from all subsequent decoders are invalidated.
When the MS has completed sequencing the rest of the flow, 6 subsequent macro-instructions are decoded.
* If a macro-instruction is steered to a limited-functionality decoder (which is 
not able to decode it), then the macro-instructions and all subsequent macroinstructions are resteered to other decoders in the next cycle. Allllops produced by this and subsequent decoders are invalidated.
* If a branch is encountered, then all Uops produced by subsequent decoders 
are invalidated. Only one branch can be decoded per cycle.

Note that the number of macro-instructions that can be decoded simultaneously does not directly relate to the number of Uops that the ID can issue because the decoder queue can store Uops and issue them later.  refers to a sequence of I.l0ps emitted by the microcode ROM. Such sequences are commonly used by the microcode to express IA32 instructions, or microarchitectural housekeeping.



#### 7.3.3.1  Complex Instructions. 
Complex instructions are those requiring the
MS to sequence Uops from the UROM. Only decoder 0 can handle these instructions. There are two ways in which the MS microcode will be invoked:
* Long flows where decoder 0 generates up to the first four Uops of the flow and the MS sequences the remaining Uops.
* Low-performance instructions where decoder 0 issues no Uops but transfers control to the MS to sequence from the UROM.

Decoders 1 and 2 cannot decode complex instructions, a design tradeoff that reflects both the silicon expense of implementation as well as the statistics of dynamic IA32 code execution. Complex instructions will be resteered to the nextlower available decoder during subsequent clocks until they reach decoder O. The MS receives a UROM entry point vector from decoder 0 and begins sequencing Uops until the end of the microcode flow is encountered.




#### 7.3.3.2  Decoder Branch Prediction. 
When the macro-instruction buffer is loaded
from the IFU, the ID looks at the prediction byte marks to see if there are any predicted-taken branches (predicted dynamically by the BTB) in the set of complete instructions in the buffer. A proper prediction will be found on the byte corresponding to the last byte of a branch instruction. If a predicted-taken branch is found anywhere in the buffer, the ID indicates to the IFU that the ID has "grabbed" the predicted branch. The IFU can now let the 16-byte block, fetched at the target address of the branch, enter the buffer at the input of its rotator. The rotator then aligns the instruction at the branch target so that it will be the next instruction loaded into the ID's instruction buffer. The ID may decode the predicted branch immediately, or it may take several cycles (due to decoding all the instructions ahead of it).

After the branch is finally decoded, the ID will latch the instructions at the branch target in the next clock cycle.
Static branch prediction (prediction made without reference to run-time history) is made by the branch address calculator (BAC). If the BAC decides to take a branch, it gives the IFU a target IP where the IFU should start fetching instructions. The ID must not, of course, issue any Uops of instructions after the branch, until it decodes the branch target instruction. The BAC will make a static branch prediction under two conditions: It sees an absolute branch that the BTB did not make a prediction on, or it sees a conditional branch with a target address whose direction is "backward" (which suggests it is the return edge of a loop).



### 7.3.4  Register Alias Table
The register alias table (RAT) provides register renaming of integer and floatingpoint registers and flags to make available a larger register set than is explicitly provided in the Intel Architecture. As Uops are presented to the RAT, their logical sources and destination are mapped to the corresponding physical ROB addresses where the data are found. The mapping arrays are then updated with new physical destination addresses granted by the allocator for each new Uop.1 

Refer to Figures 7.11 and 7.12. In each clock cycle, the RAT must look up the physical ROB locations corresponding to the logical source references of each Uop. These physical designators become part of the Uop's overall state and travel with the Uop from this point on. Any machine state that will be modified by the Uop (its "destination" reference) is also renamed, via information provided by the allocator. This physical destination reference becomes part of the Uop's overall state and is written into the RAT for use by subsequent Uops whose sources refer to the same logical destination. Because the physical destination value is unique to each Uop, it is used as an identifier for the Uop throughout the out-of-order section.

All checks and references to a Uop are performed by using this physical destination (PDst) as its name.clock cycle. If there is a true dependency chain through these three Uops, then the RAT must supply the renamed source locations "on the fly," via logic, rather than just looking up the destination, as it does for dependences tracked across clock cycles. Bypass logic will directly supply Uop 1's source register, src 2, EAX, to avoid having to wait for UopO's EAX destination to be written into the RAT and then read as Uop 1' s src.

The state in the RAT is speculative, because the RAT is constantly updating its array entries per the Uop destinations flowing by. When the inevitable branch misprediction occurs, the RAT must flush the bogus state it has collected and revert to logical-to-physical mappings that will work with the next set of Uops. The P6' s branch misprediction recovery scheme guarantees that the RAT will have to do no new renamings until the out-of-order core has flushed all its bogus misspeculated state. That is useful, because it means that register references will now reside in the retirement register file until new speculative Uops begin to appear.

Therefore, to recover from a branch misprediction, all the RAT needs to do is to revert all its integer pointers to point directly to their counterparts in the RRF.


#### 7.3.4.1  RAT Implementation Details. 
The IA32 architecture allows partialwidth reads and writes to the general-purpose integer registers (i.e., EAX, AX, AH, AL), which presents a problem for register renaming. The problem occurs when a partial-width write is followed by a larger-width read. In this case, the data required by the larger-width read must be an assimilation of multiple previous writes to different pieces of the register.

The P6 solution to the problem requires that the RAT remember the width of each integer array entry. This is done by maintaining a 2-bit size field for each entry in the integer low and high banks. The 2-bit encoding will distinguish between the three register write sizes of 32, 16, and 8 bits. The RAT uses the register size information to determine if a larger register value is needed than has previously been written. In this case, the RAT must generate a partial-write stall.

Another case, common in 16-bit code, is the independent use of the 8-bit registers. If only one alias were maintained for all three sizes of an integer register access, then independent use of the 8-bit subsets of the registers would cause a tremendous number of false dependences. Take, for example, the following series of Uops:


uopO: MOV AL,#DATAl
uopl: MOV AH,#DATA2
uop2: ADD AL,#DATA3
uop3: ADD AH,#DATA4
Micro-ops 0 and 1 move independent data into AL and AH. Micro-ops 3 and 4 source AL and AH for the addition. If only one alias were available for the "A" register, then Uop1's pointer to AH would overwrite UopO's pointer to AL. Then when Uop2 tried to read AL, the RAT would not know the correct pointer and would have to stall until Uopl retired. Then Uop3's AH source would again be lost due to Uop2's write to AL.

The CPU would essentially be serialized, and performance would be diminished.
To prevent this, two integer register banks are maintained in the RAT. For 32-bit and l6-bit RAT accesses, data are read only from the low bank, but data are written into both banks simultaneously. For 8-bit RAT accesses, however, only the appropriate high or low bank is read or written, according to whether it was a high byte or low byte access. Thus, the high and low byte registers use different rename entries, and both can be renamed independently. Note that the high bank only has four array entries because four of the integer registers (namely, EBP, ESP, EOI, ESI) cannot have 8-bit accesses, per the Intel Architecture specification.

The RAT physical source (PSrc) designators point to locations in the ROB array where data may currently be found. Data do not actually appear in the ROB until after the Uop generating the data has executed and written back on one of the writeback busses. Until execution writeback of a PSrc, the ROB entry contains junk.

Each RAT entry has an RRF bit to select one of two address spaces, the RRF or the ROB . If the RRF bit is set, then the data are found in the real register file; the physical address bits are set to the appropriate entry of the RRF. If the RRF bit is clear, then the data are found in the ROB, and the physical address points to the correct position in the ROB. The 6-bit physical address field can access any of the ROB entries. If the RRF bit is set, the entry points to the real register file; its physical address field contains the pointer to the appropriate RRF register. The busses are arranged such that the RRF can source data in the same way that the ROB can.




#### 7.3.4.2  Basic RAT Operation. 
To rename logical sources (LSrc's), the six
sources from the three IO-issued Uops are used as the indices into the RAT's integer array. Each entry in the array has six read ports to allow all six LSrc's to each read any logical entry in the array.
After the read phase has been completed, the array must be updated with new physical destinations (POst's) from the allocator associated with the destinations of the current Uops being processed. Because of possible intracycle destination dependences, a priority write scheme is employed to guarantee that the correct POst is written to each array destination.

The priority write mechanism gives priority in the following manner:
Highest:

Current Uop2' s physical destination
Current Uopl ' s physical destination
Current UopO' s physical destination

Lowest:

Any of the retiring Uops physical destinations

Retirement is the act of removing a completed Uop from the ROB and committing its state to the appropriate permanent architectural state in the machine. The ROB informs the RAT that the retiring Uop's destination can no longer be found in thethe retiring PDst is found in the array, the matching entry (or entries) is reset to point to the RRF.

The retirement mechanism requires the RAT to do three associative matches of each array PSrc against all three retirement pointers that are valid in the current cycle. For all matches found, the corresponding array entries are reset to point to the RRF. Retirement has lowest priority in the priority writeback mechanism; logically, retirement should happen before any new flOps write back. Therefore, if any flOps want to write back concurrently with a retirement reset, then the PDst writeback would happen last.

Resetting the floating-point register rename apparatus is more complicated, due to the Intel Architecture FP register stack organization. Special hardware is provided to remove the top-of-stack (TOS) offset from FP register references. In addition, a retirement FP RAT (RfRAT) table is maintained, which contains nonspeculative alias information for the floating-point stack registers. It is updated only upon flOP retirement. Each RfRA T entry is 4 bits wide: a I-bit retired stack valid and a 3-bit RRF pointer. In addition, the RfRAT maintains its own nonspeculative TOS pointer. The reason for the RfRAT's existence is to be able to recover from mispredicted branches and other events in the presence of the FXCH instruction.

The FXCH macro-op swaps the floating-point TOS register entry with any stack entry (including itself, oddly enough). FXCH could have been implemented as three MOV flOps, using a temporary register. But the Pentium processor-optimized floating-point code uses FXCH extensively to arrange data for its dual execution units. Using three flOps for the FXCH would be a heavy performance hit for the P6 processors on Pentium processor-optimized FP code, hence the motivation to implement FXCH as a single flOP.

P6 processors handle the FXCH operation by having the FP part of the RAT (fRAT) merely swap its array pointers for the two source registers. This requires extra write ports in the fRAT but obviates having to swap 80+ bits of data between any two stack registers in the RRF. In addition, since the pointer swap operation would not require the resources of an execution unit, the FXCH is marked as "completed" in the ROB as soon as the ROB receives it from the RAT. So the FXCH effectively takes no RS resources and executes in zero cycles.

Because of any number of previous FXCH operations, the fRAT may speculatively swap any number of its entries before a mispredicted branch occurs. At this point, all instructions issued down this branch are stopped. Sometime later, a signal will be asserted by the ROB indicating that all flOps up to and including the branching flOP have retired. This means that all arrays in the CPU have been reset, and macroarchitectural state must be restored to the machine state existing at the time of the mispredicted branch. The trick is to be able to correctly undo the effects of the speculative FXCHs. The fRAT entries cannot simply be reset to constant RRF values, as integer rename references are, because any number of retired FXCHs may have occurred, and the fRAT must forevermore remember the retired FXCH mappings. This is the purpose of the retirement fRAT: to "know" what to reset the FP entries to when the front end must be flushed.being referenced in the RAT, then at retirement that RAT entry reverts to pointing into the retirement register file. This implies that the retirement of Uops must take precedence over the table read. This operation is performed as a bypass after the table read in hardware. This way, the data read from the table will be overridden by the most current Uop retirement information.

The integer retirement override mechanism requires doing an associative match of the integer arrays' PSrc entries against all retirement pointers that are valid in the current cycle. For all matches found, the corresponding array entries are reset to point to the RRF.
Retirement overrides must occur, because retiring PSrc' s read from the RAT will no longer point to the correct data. The ROB array entries that are retiring during the current cycle cannot be referenced by any current Uop (because the data will now be found in the RRF).


### 7.3.4 #### 7.3.4.4  New POst Overrides. 
Micro-op logical source references are used as
indices into the RAT's multiported integer array, and physical sources are output by the array. These sources are then subject to retirement overrides. At this time, the RAT also receives newly allocated physical destinations (POst's) from the allocator. Priority comparisons of logical sources and destinations from the 10 are used to gate out either PSrc's from the integer array or POst's from the allocator as the actual renamed Uop physical sources. Notice that source 0 is never overridden because it has no previous Uop in the cycle on which to be dependent. A block diagram of the RAT's override hardware is shown in Figure 7.13.
Suppose that the following Uops are being processed:

Notice that a Uopl source relies on the destination reference of UopO. This means that the data required by Uopl are not found in the register pointed to by the RAT, but rather are found at the new location provided by the allocator. The PSrc information in the RAT is made stale by the allocator PDst of UopO and must be overridden before the renamed Uop physical sources are output to the RS and to the ROB. Also notice that a Uop2 source uses the same register as was written by both UopO and Uop!. The new PDst override control must indicate that the PDst of Uopl (not UopO) is the appropriate pointer to use as the override for Uop2's source.

Note that the Uop groups can be a mixture of both integer and floating-point operations. Although there are two separate control blocks to perform integer and FP overrides, comparison of the logical register names sufficiently isolates the two classes of Uops. It is naturally the case that only like types of sources and destinations can override each other. (For example, an FP destination cannot override an integer source.) Therefore, differences in the floating-point overrides can be handled independently of the integer mechanism.

The need for floating-point overrides is the same as for the integer overrides.
Retirement and concurrent issue of Uops prevent the array from being updated with the newest information before those concurrent Uops read the array. Therefore, PSrc information read from the RAT arrays must be overridden by both retirement overrides and new POst overrides.
Floating-point retirement overrides are identical to integer retirement overrides except that the value to which a PSrc is overridden is not determined by the logical register source name as in the integer case. Rather, the retiring logical register destination reads the RtRA T for the reset value. Depending on which retirement Uop content addressable memory (CAM) matched with this array read, the retirement override control must choose between one of the three RtRA T reset values. These reset values must have been modified by any concurrent retiring FXCHs as well.




#### 7.3.4.5  RATStalis. 
The RAT can stall in two ways, internally and externally.
The RAT generates an internal stall if it is unable to completely process the current set of Uops, due to a partial register write, a flag mismatch, or other microarchitectural conditions. The allocator may also be unable to process all Uops due to an RS or ROB table overflow; this is an external stall to the RAT.

Partial Write Stalls. When a partial-width write (e.g., AX, AL, AH) is followed by a larger-width read (e.g., EAX), the RAT must stall until the last partial-width write of the desired register has retired. At this point, all portions of the register have been reassembled in the RRF, and a single PSrc can be specified for the required data.

The RAT performs this function by maintaining the size information (8, 16, or 32 bits) for each register alias. To handle the independent use of 8-bit registers, two entries and aliases (H and L) are maintained in the integer array for each of the registers EAX, EBX, ECX, and EOX. (The other macroregisters cannot be partially written, as per the Intel Architecture specification.) When 16- or 32-bit writes occur, both entries are updated. When 8-bit writes occur, only the corresponding entry (H or L, not both) is updated.

Thus when an entry is targeted by a logical source, the size information read from the array is compared to the requested size information specified by the !-top.
If the size needed is greater than the size available (read from array), then the RAT stalls both the instruction decoder and the allocator. In addition, the RAT clears the "valid bits" on the !-top causing the stall (and any !-tops younger than it is) until the partial write retires; this is the in-order pipe, and subsequent !-tops cannot be allowed to pass the stalling !-top here.

Mismatch Stalls. Since reading and writing the flags are common occurrences and are therefore performance-critical, they are renamed just as the registers are.
There are two alias entries for flags, one for arithmetic flags and one for floatingpoint condition code flags, that are maintained in much the same fashion as the other integer array entries. When a !-top is known to write the flags, the POst granted for the !-top is written into the corresponding flag entry (as well as the destination register entry). When subsequent !-tops use the flags as a source, the appropriate flag entry is read to find the POst where the flags live.

In addition to the general renaming scheme, each !-top emitted by the 10 has associated flag information, in the form of masks, that tell the RAT which flags the !-top touches and which flags the !-top needs as input. In the event a previous but not yet retired !-top did not touch all the flags that a current !-top needs as input, the RAT stalls the in-order machine. This informs the 10 and allocator that no new !-tops can be driven to the RAT because one or more of the current !-tops cannot be issued until a previous flag write retires.




### 7.3.5  Allocator
For each clock cycle, the allocator assumes that it will have to allocate three reorder buffer, reservation station, and load buffer entries and two store buffer entries.
The allocator generates pointers to these entries and decodes the !-tops coming from the 10 unit to determine how many entries of each resource are really needed and which RS dispatch port they will be dispatched on.
Based on the !-top decoding and valid bits, the allocator will determine whether or not resource needs have been met. If not, then a stall is asserted and !-top issue is frozen until sufficient resources become available through retirement of previous !-tops.
The first step in allocation is the decoding of the !-tops that are delivered by the ID. Some !-tops need an LB or SB entry; all !-tops need an ROB entry.


#### 7.3.5.1  ROB Allocation. 
The ROB entry addresses are the physical destinations or POst's which were assigned by the allocator. The POst's are used to directly address the ROB. This means if the ROB is full, the allocator must assert a stall signal early enough to prevent overwriting valid ROB data.
The ROB buffer is treated as a circular buffer by the allocator. In other words, entry addresses are assigned sequentially from 0 until the highest address, and then wraparound back to O. A three-or-none allocation policy is used: every cycle, at least three ROB entries must be available or the allocator will stall. This means ROB allocation is independent of the type of Uop and does not even depend on the Uop' s validity. The three-or-none policy simplifies allocation.

At the end of the cycle, the address of the last ROB entry allocated is preserved and becomes the new allocation starting point. Note that this does depend on the real number of valid Uops. The ROB also uses the number of valid Uops to determine where to stop retiring.



#### 7.3.5.2  MOB Allocation. 
All Uops have a load buffer ID and a store buffer ID (together known as a MOB ID, or MBID) stored with them. Load Uops will have a newly allocated LB address and the last SB address that was allocated. Nonload Uops (store or any other Uop) have MBID with LBID = 0 and the SBID (or store color) of the last store allocated.

The LB and SB are treated as circular buffers, as is the ROB. However, the allocation policy is slightly different. Since every Uop does not need an LB or SB entry, it would be a big performance hit to use a three-or-none policy (or two-ornone for SB) and stall whenever the LB or SB has less than three free entries.

Instead we use an all-or-none policy. This means that stalling will occur only when not all the valid MOB Uops can be allocated.
Another important part of MOB allocation is the handling of entries containing senior stores. These are stores that have been committed or retired by the CPU but are still actually awaiting completion of execution to memory. These store buffer entries cannot be deallocated until the store is actually performed to memory.



#### 7.3.5.3  RS Allocation. 
The allocator also generates write enable bits which are used by the RS directly for its entry enables. If the RS is full, a stall indication must be given early in order to prevent the overwrite of valid RS data. In fact if the RS is full, the enable bits will all be cleared and thus no entry will be enabled for writing. If the RS is not full but a stall occurs due to some other resource conflict, the RS invalidates data written to any RS entry in that cycle (i.e., data get written but are marked as invalid).

The RS allocation works differently from the ROB or MOB circular buffer model. Since the RS dispatches Uops out of order (as they become data-ready), its free entries are typically interspersed with used or allocated entries, and so a circular buffer model does not work. Instead, a bitmap scheme is used where each RS entry maps to a bit of the RS allocation pool. In this way, entries may be drawn or replaced from the pool in any order. The RS searches for free entries by scanning from location 0 until the first three free entries are found.

Some Uops can dispatch to more than one port, and the act of committing a given Uop to a given port is called binding. The binding of Uops to the RS functional unit interfaces is done at allocation. The allocator has a load-balancing algorithmThis is referred to as a static binding with load balancing of ready Uops to an execution interface.




## 7.4 ### 7.4.1 The Out-of-Order Core
Reservation Station

The reservation station (RS) is basically a place for Uops to wait until their operands have all become ready and the appropriate execution unit has become available. In each cycle, the RS determines execution unit availability and source data validity, performs out-of-order scheduling, dispatches Uops to execution units, and controls data bypassing to RS array and execution units. All entries of the RS are identical and can hold any kind of Uops.

The RS has 20 entries. The control portion of an entry (uop, entry valid, etc.) can be written from one of three ports (there are three ports because the P6 microarchitecture is of superscalar order 3.). This information comes from the allocator and RAT. The data portion of an entry can be written from one of six ports (three ROB and three execution unit writebacks). CAMs control the snarfing of valid writeback data into Uop Src fields and data bypassing at the execution unit (EU) interfaces. The CAMs, EU arbitration, and control information are used to determine data validity and EU availability for each entry (ready bit generation).

The scheduler logic uses this ready information to schedule up to five Uops. The entries that have been scheduled for dispatch are then read out of the array and driven to the execution unit.
During pipe stage 31 , the RS determines which entries are, or will be, ready for dispatch in stage 32. To do this, it is necessary to know the availability of data and execution resources (EU/AGU units). This ready information is sent to the scheduler.



#### 7.4.1.1  Scheduling. 
The basic function of the scheduler is to enable the dispatching of up to five Uops per clock from the RS. The RS has five schedulers, one for each execution unit interface. Figure 7.14 shows the mapping of the functional units to their RS ports.
The RS uses a priority pointer to specify where the scheduler should begin its scan of the 20 entries. The priority pointer will change according to a pseudoFIFO algorithm. This is used to reduce stale entry effects and increase performance in the RS.


#### 7.4.1.2  Dispatch. 
The RS can dispatch up to five Uops per clock. There are two EU and two AGU interfaces and one store data (STD) interface. Figure 7.14 shows the connections of the execution units to the RS ports. Before instruction dispatch time, the RS determines whether or not all the resources needed for a particular Uop to execute are available, and then the ready entries are scheduled. The RS then dispatches all the necessary Uop information to the scheduled functional unit. Once a Uop has been dispatched to a functional unit and no cancellation has Note: Only one source shown per RS port.

occurred due to a cache miss, the entry can be deallocated for use by a new Uop.
Every cycle, deallocation pointers are used to signal the allocator about the availability of all 20 entries in the RS .



#### 7.4.1.3  Data Writeback. 
It is possible that source data will not be valid at the time the RS entry is initially written. The Uop must then remain in the RS until all its sources are valid. The content addressable memories (CAMs) are used to compare the writeback physical destination (POst) with the stored physical sources (PSrc).

When a match occurs, the corresponding write enables are asserted to snarf the needed writeback data into the appropriate source in the array.


#### 7.4.1.4  Cancellation. 
Cancellation is the inhibiting of a Uop from being scheduled, dispatched, or executed due to a cache miss or possible future resource conflict.
All canceled Uops will be rescheduled at a later time unless the out-of-order machine is reset.
There are times when writeback data are invalid, e.g., when the memory unit detects a cache miss. In this case, dispatching Uops that are dependent on the writeback data need to be canceled and rescheduled at a later time. This can happen because the RS pipeline assumes cache accesses will be hits, and schedules dependent Uops based on that assumption.




## 7.5 Retirement



### 7.5.1  The Reorder Buffer
The reorder buffer (ROB) participates in three fundamental aspects of the P6 microarchitecture: speculative execution, register renaming, and out-of-order execution. In some ways, the ROB is similar to the register file in an in-order machine, but with additional functionality to support retirement of speculative operations and register renaming.

The ROB supports speculative execution by buffering the results of the execution units (EUs) before committing them to architecturally visible state. This allows most of the microengine to fetch and execute instructions at a maximum rate by assuming that branches are properly predicted and that no exceptions occur. If a branch is mispredicted or if an exception occurs in executing an instruction, the microengine can recover simply by discarding the speculative results stored in the ROB . The microengine can also restart at the proper instruction by examining the committed architectural state in the ROB. A key function of the ROB is to control retirement or completion of Uops.

The buffer storage for EU results is also used to support register renaming.
The EUs write result data only into the renamed register in the ROB. The retirement logic in the ROB updates the architectural registers based upon the contents of each renamed instance of the architectural registers. Micro-ops which source an architectural register obtain either the contents of the actual architectural register or the contents of the renamed register. Since the P6 microarchitecture is superscalar, different Uops in the same clock which use the same architectural register may in fact access different physical registers.

The ROB supports out-of-order execution by allowing EUs to complete their Uops and write back the results without regard to other Uops which are executing simultaneously. Therefore, as far as the execution units are concerned, Uops complete out of order. The ROB retirement logic reorders the completed Uops into the original sequence issued by the instruction decoder as it updates the architectural state during retirement.

The ROB is active in three separate parts of the processor pipeline (refer to Figure 7.4): the rename and register read stages, the execute/writeback stage, and the retirement stages.
The placement of the ROB relative to other units in the P6 is shown in the block diagram in Figure 7.1. The ROB is closely tied to the allocator (ALL) and registerspeculative operations and register renaming. The actual renaming of architectural registers in the ROB is managed by the RAT. Both the allocator and the RAT function within the in-order part of the P6 pipeline. Thus, the rename and register read (or ROB read) functions are performed in the same sequence as in the program flow.

The ROB interface with the reservation station (RS) and the EUs in the out-oforder part of the machine is loosely coupled in nature. The data read from the ROB during the register read pipe stage consist of operand sources for the Uop. These operands are stored in the RS until the Uop is dispatched to an execution unit. The EUs write back Uop results to the ROB through the five writeback ports (three full writeback ports, two partial writebacks for STO and STA). The result writeback is out of order with respect to Uops issued by the instruction decoder. Because the results from the EUs are speculative, any exceptions that were detected by the EUs mayor may not be "real." Such exceptions are written into a special field of the Uop. If it turns out that the Uop was misspeculated, then the exception was not "real" and will be flushed along with the rest of the Uop. Otherwise, the ROB will notice the exceptional condition during retirement of the Uop and will cause the appropriate exception-handling action to be invoked then, before making the decision to commit that Uop's result to architectural state.

The ROB retirement logic has important interfaces to the micro-instruction sequencer (MS) and the memory ordering buffer (MOB). The ROBIMS interface allows the ROB to signal an exception to the MS, forcing the micro-instruction sequencer to jump to a particular exception handler microcode routine. Again, the ROB must force the control flow change because the EUs report events out of order with respect to program flow. The ROBIMOB interface allows the MOB to commit memory state from stores when the store Uop is committed to the machine state.




#### 7.5.1.1  ROB Stages in the Pipeline. 
The ROB is active in both the in-order and
out-of-order sections of the P6 pipeline. The ROB is used in the in-order pipe in pipe stages 21 and 22. Entries in the reorder buffer which will hold the results of the speCUlative Uops are allocated in pipe stage 21. The reorder buffer is managed by the allocator and the retirement logic as a circular buffer. If there are unused entries in the reorder buffer, the allocator will use them for the Uops being issued in the clock. The entries used are signaled to the RAT, allowing it to update its renaming or alias tables. The addresses of the entries used (POst's) are also written into the RS for each Uop. The POst is the key token used by the out-of-order section of the machine to identify Uops in execution; it is the actual slot number in the ROB. As the entries in the ROB are allocated, certain fields in them are written with data from fields in the Uops. This information can be written either at allocation time or with the results written back by the EUs. To reduce the width of the RS entries as well as to reduce the amount of information which must be circulated to the EUs or memory subsystem, any Uop information required to retire a Uop which is determined strictly at decode time is written into the ROB at allocation time.

In pipe stage 22, immediately following entry allocation, the sources for the Uops are read from the ROB. The physical source addresses, PSrc's, are delivered by the RAT based upon the alias table update performed in pipe stage 21. A source may reside in one of three places: in the committed architectural state (retirement register file), in the reorder buffer, or from a writeback bus. (The RRF contains both architectural state and microcode visible state. Subsequent references to RRF state will call them macrocode and microcode visible state). Source operands read from the RRF are always valid, ready for execution unit use. Sources read from the ROB mayor may not be valid, depending on the timing of the source read with respect to writebacks of previous Uops which updated the entries read. If the source operand delivered by the ROB is invalid, the RS will wait until an EU writes back to a PDst which matches the physical source address for a source operand in order to capture (or bypass at the EU) the valid source operand for a given Uop.

An EU writes back destination data into the entry allocated for the Uop, along with any event information, in pipe stage 83. (Event refers to exceptions, interrupts, microcode assists, and so on.) The writeback pipe stage is decoupled from the rename and register read pipe stages because the Uops are issued out of order from the RS . Arbitration for use of writeback busses is determined by the EUs along with the RS. The ROB is simply the terminus for each of the writeback busses and stores whatever data are on the busses into the writeback PDst's signaled by the EUs.

The ROB retirement logic commits macrocode and microcode visible state in pipe stages 92 and 93. The retirement pipe stages are decoupled from the writeback pipe stage because the writebacks are out of order with respect to the program or microcode order. Retirement effectively reorders the out-of-order completion of Uops by the EUs into an in-order completion of Uops by the machine as a whole. Retirement is a two-clock operation, but the retirement stages are pipelined. If there are allocated entries in the reorder buffer, the retirement logic will attempt to deallocate or retire them. Retirement treats the reorder buffer as FIFO in deallocating the entries, since the Uops were originally allocated in a sequential FIFO order earlier in the pipeline. This ensures that retirement follows the original program source order, in terms of allowing the architectural state to be modified.

The ROB contains all the P6 macrocode and microcode state which may be modified without serialization of the machine. (Serialization limits to one the number of Uops which may flow through the out-of-order section of the machine, effectively making them execute in order.) Much of this state is updated directly from the speculative state in the reorder buffer. The extended instruction pointer (EIP) is the one architectural register which is an exception to this norm. The EIP requires a significant amount of hardware in the ROB for each update. The reason is the number of Uops which may retire in a clock varies from zero to three.

The ROB is implemented as a multiported register file with separate ports for allocation time writes of Uop fields needed at retirement, EU writebacks, ROB reads of sources for the RS, and retirement logic reads of speculative result data.
The ROB has 40 entries. Each entry is 157 bits wide. The allocator and retirement logic manage the register file as FIFO. Both source read and destination writeback functions treat the reorder buffer as a register file.

The RRF contains both the macrocode and microcode visible state. Not all such processor state is located in the RRF, but any state which may be renamed is there. Table 7.1 gives a listing of the registers in the RRF.
Retirement logic generates the addresses for the retirement reads performed in each clock. The retirement logic also computes the retirement valid signals indicating which entries with valid writeback data may be retired.
The IP calculation block produces the architectural instruction pointer as well as several other macro- and micro-instruction pointers. The macro-instruction pointer is generated based on the lengths of all the macro-instructions which may retire, as well as any branch target addresses which may be delivered by the jump execution unit.

When the ROB has determined that the processor has started to execute operations down the wrong path of a branch, any operations in that path must not be allowed to retire. The ROB accomplishes this by asserting a "clear" signal at the point just before the first of these operations would have retired. All speculative operations are then flushed from the machine. When the ROB retires an operation that faults, it clears both the in-order and out-of-order sections of the machine in pipe stages 93 and 94.




#### 7.5.1.2  Event Detection. 
Events include faults, traps, assists, and interrupts.
Every entry in the reorder buffer has an event information field. The executionfield for the three entries that are candidates for retirement. The event information field tells the retirement logic whether there is an exception and whether it is a fault or a trap or an assist. Interrupts are signaled directly by the interrupt unit. The jump unit marks the event information field in case of taken or mispredicted branches.

If an event is detected, the ROB clears the machine of all Uops and forces the MS to jump to a microcode event handler. Event records are saved to allow the microcode handler to properly repair the result or invoke the correct macrocode handler. Macro- and micro-instruction pointers are also saved to allow program resumption upon termination of the event handler.




## 7.6 Memory Subsystem

The memory ordering buffer (MOB) is a part of the memory subsystem of the P6.
The MOB interfaces the processor's out-of-order engine to the memory subsystem. The MOB contains two main buffers, the load buffer (LB) and the store address buffer (SAB). Both of these buffers are circular queues with each entry within the buffer representing either a load or a store micro-operation, respectively. The SAB works in unison with the memory interface unit's (MIU) store data buffer (SDB) and the DCache's physical address buffer (PAB) to effectively manage a processor store operation. The SAB, SDB, and PAB can be viewed as one buffer, the store buffer (SB).

The LB contains 16 buffer entries, holding up to 16 loads. The LB queues up load operations that were unable to complete when originally dispatched by the reservation station (RS). The queued operations are redispatched when the conflict has been removed. The LB maintains processor ordering for loads by snooping external writes against completed loads. A second processor's write to a speculatively read memory location forces the out-of-order engine to clear and restart the load operation (as well as any younger Uops).

The SB contains 12 entries, holding up to 12 store operations. The SB is used to queue up all store operations before they dispatch to memory. These stores are then dispatched in original program order, when the 000 engine signals that their state is no longer speculative. The SAB also checks all loads for store address conflicts. This checking keeps loads consistent with previously executed stores still in the SB.

The MOB resources are allocated by the allocator when a load or store operation is issued into the reservation station. A load operation decodes into one Uop and a store operation is decoded into two Uops: store data (STD) and store address (ST A). At allocation time, the operation is tagged with its eventual location in the LB or SB, collectively referred to as the MOB ID (MBID). Splitting stores into two distinct Uops allows any possible concurrency between generation of the address and data to be stored to be expressed.

The MOB receives speculative LD and STA operations from the reservation station. The RS provides the opcode, while the address generation unit (AGU) calculates and provides the linear address for the access. The DCache either executes these operations immediately, or they are dispatched later by the MOB. In either case they are written into one of the MOB arrays. During memory operations, the data translation lookaside buffer (DTLB) converts the linear address to a physical address or signals a page miss to the page miss handler (PMH). The MOB will also perform numerous checks on the linear address and data size to determine if the operation can continue or if it must block.

In the case of a load, the data cache unit is expected to return the data to the core. In parallel, the MOB writes address and status bits into the LB, to signal the operation's completion. In the case of a STA, the MOB completes the operation by writing a valid bit (AddressDone) into the SAB array and to the reorder buffer.

This indicates that the address portion of the store has completed. The data portion of the store is executed by the SDB. The SDB will signal the ROB and SAB when the data have been received and written into the buffer. The MOB will retain the store information until the ROB indicates that the store operation is retired and committed to the processor state. It will then dispatch from the MOB to the data cache unit to commit the store to the system state. Once completed, the MOB signals deallocation of SAB resources for reuse by the allocator. Stores are executed by the memory subsystem in program order.



### 7.6.1 Memory Access Ordering

Micro-op register operand dependences are tracked explicitly, based on the register references in the original program instructions. Unfortunately, memory operations have implicit dependences, with load operations having a dependency on any previous store that has address overlap with the load. These operations are often speCUlative inside the MOB, both the stores and loads, so that system memory access may return stale data and produce incorrect results.

To maintain self-consistency between loads and stores, the P6 employs a concept termed store coloring. Each load operation is tagged with the store buffer ID (SBID) of the store previous to it. This ID represents the relative location of the load compared to all stores in the execution sequence. When the load executes in the memory subsystem, the MOB will use this SBID as a beginning point for analyzing the load against all older stores in the buffer, while also allowing the MOB to ignore younger stores.

Store coloring is used to maintain ordering consistency between loads and stores of the same processor. A similar problem occurs between processors of a multiprocessing system. If loads execute out of order, they can effectively make another processor's store operations appear out of order. This results from a younger load passing an older load that has not been performed yet. This younger load reads old data, while the older load, once performed, has the chance of reading new data written by another processor. If allowed to commit to state, these loads would violate processor ordering. To prevent this violation, the LB watches (snoops) all data writes on the bus. If another processor writes a location that was speculatively read, the speculatively completed load and subsequent operations will be cleared and re-executed to get the correct data.



### 7.6.2  Load Memory Operations
Load operations issue to the RS from the allocator and register allocation table (RAT). The allocator assigns a new load buffer ID (LBID) to each load that issues into the RS. The allocator also assigns a store color to the load, which is the SBID of the last store previously allocated. The load waits in the RS for its data operands to become available. Once available, the RS dispatches the load on port 2 to the AGU and LB. Assuming no other dispatches are waiting for this port, the LB bypasses this operation for immediate execution by the memory subsystem. The AGU generates the linear address to be used by the DTLB, MOB, and DCU. As the DTLB does its translation to the physical address, the DCU does an initial data lookup using the lower-order 12 bits. Likewise, the SAB uses the lower-order 12 bits along with the store color SBID to check potential conflicting addresses of previous stores (previous in program order, not time order). Assuming a DTLB page hit and no SAB conflicts, the DCU uses the physical address to do a final tag match and return the correct data (assuming no miss or block). This completes the load operation, and the RS, ROB, and MOB write their completion status.

If the SAB noticed an address match, the SAB would cause the SDB to forward SDB data, ignoring the DCU data. If a SAB conflict existed but the addresses did not match (a false conflict detection), then the load would be blocked and written into the LB. The load will wait until the conflicting store has left the store buffer.



### 7.6.3  Basic Store Memory Operations
Store operations are split into two micro-ops, store data (STD) followed by a store address (ST A). Since a store is represented by the combination of these operations, the allocator allocates a store buffer entry only when the STD is issued into the RS. The allocation of a store buffer entry reserves the same location in the SAB, the SDB, and the PAB. When the store's source data become available, the RS dispatches the STD on port 4 to the MOB for writing into the SDB . As the STA address source data become available, the RS dispatches the STA on port 3 to the AGU and SAB. The AGU generates the linear address for translation by the DTLB and for writing into the SAB. Assuming a DTLB page hit, the physical address is written into the PAB. This completes the STA operation, and the MOB and ROB update their completion status.

Assuming no faults or mispredicted branches, the ROB retires both the STD and ST A. Monitoring this retirement, the SAB marks the store (STD/ST A pair) as the committed, or senior, processor state. Once senior, the MOB dispatches these operations by sending the opcode, SBID, and lower 12 address bits to the DCU.

The DCU and MIU use the SBID to access the physical address in the PAB and store data in the SDB, respectively, to complete the final store operation.


### 7.6.4  Deferring Memory Operations
In general, most memory operations are expected to complete three cycles after dispatch from the RS (which is only two clocks longer than an ALU operation).
However, memory operations are not totally predictable as to their translation and availability from the Ll cache. In cases such as these, the operations require other resources, e.g., oeu fill buffers on a pending cache miss, that may not be available. Thus, the operations must be deferred until the resource becomes available.

The MOB load buffer employs a general mechanism of blocking load memory operation until a later wakeup is received. The blocking information associated with each entry of the load buffer contains two fields: a blocking code or type and a blocking identifier. The block code identifies the source of the block (e.g., address block, PMH resource block). The block identifier refers to a specific ID of a resource associated with the block code. When a wakeup signal is received, all deferred memory operations that match the blocking code and identifier are marked "ready for dispatch." The load buffer then schedules and dispatches one of these ready operations in a manner that is very similar to RS dispatching.

The MOB store buffer uses a restricted mechanism for blocking STA memory operations. The operations remain blocked until the ROB retirement pointers indicate that STA Uop is the oldest nonretired operation in the machine. This operation will then dispatch at retirement with the write to the oeu occurring simultaneously with the dispatch of the STA. This simplified mechanism for stores was used because STAs are rarely blocked.




## 7.6  Page Faults
The OTLB translates the linear addresses to physical addresses for all memory load and store address Uops. The OTLB does the address translation by performing a lookup in a cache array for the physical address of the page being accessed. The OTLB also caches page attributes with the physical address. The OTLB uses this information to check for page protection faults and other paging-related exceptions.

The OTLB stores physical addresses for only a subset of all possible memory pages. If an address lookup fails, the OTLB signals a miss to the PMH. The PMH executes a page walk to fetch the physical address from the page tables located in physical memory. The PMH then looks up the effective memory type for the physical address from its on-chip memory type range registers and supplies both the physical address and the effective memory type to the OTLB to store in its cache array.

(These memory type range registers are usually configured at processor boot time.) Finally, the OTLB performs the fault detection and writeback for various types of faults including page faults, assists, and machine check architecture errors for the Oeu. This is true for data and instruction pages. The OTLB also checks for I/O and data breakpoint traps, and either writes back (for store address Uops) or passes (for loads and I/O Uops) the results to the oeu which is responsible for supplying the data for the ROB writeback.




## 7.7 Summary

The design described in this chapter began as the brainchild of the authors of this chapter, but also reflects the myriad contributions of hundreds of designers, microcoders, validators, and performance analysts. Subject only to the economics that rule Intel's approach to business, we tried at all times to obey the prime directive:

Make choices that maximize delivered performance, and quantify those choices wherever possible. The out-of-order, speculative execution, superpipelined, superscalar, micro-dataflow, register-renaming, glueless multiprocessing design that we described here was the result. Intel has shipped approximately one billion P6-based microprocessors as of 2002, and many of the fundamental ideas described in this chapter have been reused for the Pentium 4 processor generation.

Further details on the P6 microarchitecture can be found in Colwell and Steck [1995] and Papworth [1996].



## 7.8 Acknowledgments

The design of the P6 rnicroarchitecture was a collaborative effort among a large group of architects, designers, validators, and others. The rnicroarchitecture described here benefited enormously from contributions from these extraordinarily talented people. They also contributed some of the text descriptions found in this chapter.

Thank you, one and all.
We would also like to thank Darrell Boggs for his careful proofreading of a draft of this chapter.

## REFERENCES

Colwell, Robert P., and Randy Steck: "A 0.6 11m BiCMOS microprocessor with dynamic execution," Proc. Int. Solid State Circuits Conference, San Francisco, CA 1995, pp. 176-177.

Lee, J., and A. J. Smith: "Branch predictions and branch target buffer design," IEEE Computer, January 1984,21 , 7, pp. 6-22.

Pap worth, David B.: "Tuning the Pentium Pro microarchitecture," IEEE Micro, August 1996, pp. 8-15.

Yeh, T.-Y., and Y. N. Patt: "Two-level adaptive branch prediction," The 24th ACMIIEEE Int. Symposium and Workshop on Microarchitecture, November 1991, pp. 51-61.

