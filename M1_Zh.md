# 1处理器设计
约翰保罗沉

欢迎来到当代微处理器设计 在30多年的相对短暂的生命周期中,微处理器经历了惊人的进步.它的表现以每18个月翻一番的惊人速度得到改善.在过去的三十年中,微处理器一直负责激励和促进计算机系统的一些主要创新.这些创新包括嵌入式微控制器,个人计算机,高级工作站,手持和移动设备,应用程序和文件服务器,用于Internet的Web服务器,低成本超级计算机和大型计算集群.目前,移动,台式机和服务器市场每年销售超过1亿个微处理器.包括嵌入式微处理器和微控制器,

微处理器是指令集处理器（ISP）.ISP执行来自预定义指令集的指令.微处理器的功能完全由其能够执行的指令集表征.在微处理器上运行的所有程序都在该指令集中进行编码.该预定义指令集也称为指令集架构（ISA）.ISA充当软件和硬件之间或程序和处理器之间的接口.在处理器设计方法方面,ISA是设计的规范,而微处理器或ISP是设计的实现.与所有形式的工程设计一样,微处理器设计本质上是一个创造性的过程,涉及微妙的权衡,需要良好的直觉和聪明的见解.

本书侧重于微体系结构层面的当代超标量微处理器设计.它以系统的方式呈现现有和提出的微体系结构技术,并提供基本原理和见解,希望培养能够为下一代微处理器的有效设计做出贡献的新微架构.


## 1.1微处理器的发展

第一个微处理器Intel 4004于1971年推出.4004是一个4位处理器,由大约2300个晶体管组成,时钟频率刚刚超过100千赫兹（kHz）.它的主要应用是建立计算器.2001年是微处理器诞生三十周年.高端微处理器包含多达1亿个晶体管,时钟频率达到2千兆赫（GHz）,现在是超级计算机系统和功能强大的客户端和服务器系统的构建模块.在几年内,微处理器的时钟接近10 GHz,每个微处理器将包含数亿个晶体管.

微处理器三十年的历史讲述了计算机行业技术进步的一个非常了不起的故事; 见表1.1.微处理器的发展几乎遵循着名的摩尔定律,由Gordon Moore在1965年观察到,可以集成在单个硅片上的器件数量将大约每18到24个月翻一番.在短短30多年的时间里,微处理器芯片中的晶体管数量增加了四个数量级以上.在同一时期,微处理器的性能提高了五个数量级以上.在过去的二十年中,微处理器性能每18个月翻一番,或者每十年增加100倍.这种惊人的性能提升是任何其他行业所无法比拟的.


表1.1
微处理器发展的惊人数十年

|| 1970-1980 | 1980-1990 | 1990-2000 | 2000-2010 
|  -  |  -  |  -  |  -  |  - 
|晶体管数量| 2K-100K | lOOK-1M | 1M-100M | 100M- 2B 
|时钟频率| 0.1-3 MHz | 3-30 MHz | 30 M Hz-1 GHz | 1-1 5G Hz
|指令/周期| 0.1 | 0.1-0.9 | 0.9-1.9 | 1.9-2.9

在其存在的三十年中,微处理器在计算机行业最关键的进步中发挥了重要作用.在第一个十年期间,4位微处理器的出现迅速导致了8位微处理器的推出.
这些窄比特宽度的微处理器发展成为自包含的微控制器,这些微控制器大量生产并部署在从洗衣机,电梯到喷气发动机的众多嵌入式应用中.8位微处理器也成为了一种名为个人计算机（PC）的新型流行计算平台的核心,并迎来了PC时代的计算机.

20世纪80年代的十年见证了32位微处理器的架构和微体系结构的重大进步.指令集设计问题成为学术和工业研究人员关注的焦点.已经认识到具有促进有效硬件实现并且可以利用编译器优化的指令集架构的重要性.指令流水线和快速缓存存储器成为标准的微体系结构技术.推出了基于32位微处理器的强大科学和工程工作站.这些工作站反过来成为后续几代功能更强大的微处理器设计的主力军.

在20世纪90年代,微处理器成为最强大,最受欢迎的计算机形式.最快的微处理器的时钟频率超过了最快的超级计算机.个人计算机和工作站成为生产力和通信的无处不在的重要工具.
设计了极具侵略性的微架构技术,以实现前所未有的微处理器性能水平.能够实现极高时钟频率并维持每个周期执行多个指令的深度流水线机器变得流行.引入了无序的指令执行和积极的分支预测技术,以避免或减少管道停顿的数量.到第三个十年的微处理器结束时,几乎所有形式的计算平台,从个人手持设备到主流台式机和服务器计算机,再到功能最强大的并行和集群计算机,都基于微处理器的构建模块.

我们现在正进入微处理器的第四个十年,这种势头没有减弱的迹象.大多数技术人员都认为,摩尔定律将继续统治至少10至15年.到2010年,我们可以预计微处理器将包含超过10亿个时钟频率大于10 GHz的晶体管.我们还可以期待在许多领域实现新的创新.目前对指令级并行（ILP）的关注将扩展到包括线程级并行（TLP）以及内存级并行（MLP）.历史上属于大型系统的架构特性（例如,处理器和内存层次结构）将在单个芯片上实现.许多传统的“宏观架构”问题现在将成为微架构问题.

本书的目的是在微体系结构层面介绍微处理器设计的基本原理.过去三十年中开发和部署的主要技术以全面的方式呈现.本书试图将大量知识编入系统框架.可能看起来相当复杂且难以破译的概念和技术被提炼为直观且富有洞察力的格式.还强调了研究人员最近提出的一些创新技术.我们希望本书能够在生产新一代微处理器设计师方面发挥作用,这些设计师将帮助撰写第四个十年微处理器的历史.


## 1.2指令集处理器设计

本书的重点是设计指令集处理器.指令集处理器的关键是指令集架构,它指定了指令集处理器必须实现的功能.ISA在指令集处理器设计中起着几个关键作用.

### 1.2.1数字系统设计

任何工程设计都以规范开始,目的是获得良好的设计或实施.规范是对所需内容的行为描述,并回答“它做了什么？”的问题.实现是对结果设计的结构描述,并回答了“它是如何构建的？”的问题.通常,设计过程涉及两个基本任务:合成和分析.综合尝试根据规范找到实现.分析检查实现以确定它是否以及如何满足规范.综合是一项更具创造性的任务,可以搜索可能的解决方案并执行各种权衡和设计优化,以获得最佳解决方案.分析的关键任务对于确定设计的正确性和有效性至关重要; 它经常使用仿真工具来执行设计验证和性能评估.典型的设计过程可能需要多次遍历分析 - 合成循环,以便达到最终的最佳设计; 见图1.1.

在数字系统设计中,规范非常严格,设计优化依赖于强大的软件工具的使用.组合逻辑电路的规范采用布尔函数的形式,指定输入和输出变量之间的关系.该实现通常是优化的两级AND-OR设计或逻辑门的多级网络.优化尝试减少逻辑门的数量和设计中使用的逻辑电平的数量.对于顺序电路设计,规范采用状态机描述的形式,包括状态变量的规范以及输出和下一状态函数.优化目标包括减少状态数量和相关组合逻辑电路的复杂性.逻辑最小化和状态最小化软件工具是必不可少的.逻辑和状态机仿真工具用于辅助分析任务.这些工具可以验证设计的逻辑正确性,并确定关键延迟路径,从而确定状态机的最大时钟速率.

微处理器的设计过程更复杂,更简单.微处理器设计的规范是指令集架构,它指定了微处理器必须能够执行的一组指令.实现是使用硬件描述语言（HDL）描述的实际硬件设计.HDL的原语可以是逻辑门和触发器,也可以是更复杂的模块,如解码器和多路复用器,也可以是整个功能模块,如加法器和乘法器.设计被描述为这些原语的示意图或互连组织.

设计现代高端微处理器的过程通常涉及两个主要步骤:微体系结构设计和逻辑设计.微体系结构设计涉及开发和定义实现目标性能的关键技术.通常,性能模型用作分析工具来评估这些技术的有效性.性能模型以时钟周期粒度精确地模拟机器的行为,并且能够量化执行基准程序所需的机器周期数.

微体系结构设计的最终结果是对微处理器组织的高级描述.该描述通常使用寄存器传输语言（RTL）来指定机器组织中的所有主要模块以及这些模块之间的交互.在逻辑设计步骤期间,通过结合实现细节来连续地改进RTL描述,以最终产生实际硬件设计的HDL描述.RTL和HDL描述都可能使用相同的描述语言.例如,Verilog就是这样一种语言.本书的主要焦点是微体系结构设计.

### 1.2.2架构,实现和实现

在Blaauw和Brooks [1997]的经典计算机体系结构教科书中,作者定义了三个基本和不同的抽象层次:架构,实现和实现.架构指定处理器的功能行为.实现是执行体系结构的逻辑结构或组织.实现是体现实现的物理结构.

体系结构也称为指令集体系结构.它指定了表征指令集处理器的功能行为的指令集.必须将所有软件映射到该指令集或在该指令集中编码,以便由处理器执行.每个程序都被编译成该指令集中的一系列指令.一些众所周知的体系结构的示例是IBM 360,DEC VAX,Motorola 68K,PowerPC和Intel IA32.与体系结构相关联的属性包括汇编语言,指令格式,寻址模式和编程模型.这些属性都是ISA的一部分,并且在编译器或程序员看到的情况下暴露给软件.

实现是体系结构的特定设计,它也被称为微体系结构.架构在ISA的生命周期中可以有许多实现.架构的所有实现都可以执行在该ISA中编码的任何程序.上面列出的体系结构的一些众所周知的实现的示例是IBM 360/91,VAX 111780,Motorola 68040,
PowerPC 604和Intel P6.与实现相关联的属性包括管道设计,高速缓存存储器和分支预测器.实现或微体系结构功能通常在硬件中实现,并且对软件隐藏.开发这些功能是微处理器设计人员或微架构的工作.

实现的实现是设计的特定物理实施例.对于微处理器,该物理实施例通常是芯片或多芯片封装.对于给定的实现,可以存在该实现的各种实现.这些实现可以在时钟频率,高速缓冲存储器容量,总线接口,制造技术,封装等方面变化和不同.与实现相关联的属性包括管芯尺寸,物理形状因数,功率,冷却和可靠性.这些属性是芯片设计者和使用该芯片的系统设计者所关注的问题.
本书的主要重点是现代微处理器的实现.与架构和实现相关的问题也很重要.架构作为实现的规范.架构的属性可以显着影响设计复杂性和实现的设计工作.必须在设计过程中考虑实现的属性,例如芯片尺寸和功率,并将其用作设计目标的一部分.

### 1.2.3指令集架构

指令集架构起着非常关键的作用,并且被定义为软件和硬件之间或程序和机器之间的契约.通过将ISA作为合同,可以独立开发程序和机器.可以开发针对ISA的程序,而无需了解实际的机器实现.类似地,可以设计实现ISA的机器,而不用担心将在它们上运行什么程序.为特定ISA编写的任何程序都应该能够在任何实现相同ISA的机器上运行.IBM S / 360系列计算机首次引入了在ISA的多个实现中维护相同ISA的概念[Amdahl等,1964].

拥有ISA还可确保软件的可移植性.为特定ISA编写的程序可以在同一ISA的所有实现上运行.通常给定IS A,将在该ISA的生命周期内开发许多实现,或者可以同时开发提供不同级别的成本和性能的多个实现.只需要为该ISA开发一次程序,然后它就可以在所有这些实现上运行.这种程序可移植性显着降低了软件开发的成本并延长了软件的使用寿命.不幸的是,同样的好处也使得迁移到新的ISA变得非常困难.成功的ISA,或更具体的IS与大型软件安装基础一样,倾向于保持一段时间.两个例子是IBM 360/370和Intel IA32.

除了作为软件开发人员或编译器的目标参考之外,ISA还作为处理器设计者的规范.微处理器设计从ISA开始,并产生符合此规范的微架构.
必须针对ISA验证每个新的微体系结构,以确保它执行ISA指定的功能要求.这对于确保现有软件可以在新的微架构上正确运行非常重要.

自计算机问世以来,已经开发和使用了各种各样的ISA.它们在操作和操作数的指定方式上有所不同.通常,ISA定义一组称为汇编指令的指令.每条指令指定一个操作和一个或多个操作数.每个ISA唯一地定义汇编语言.汇编语言程序构成一系列汇编指令.IS已根据每条指令中可明确指定的操作数的数量进行区分,例如两个地址或三地址体系结构.一些早期的ISA使用累加器作为隐式操作数.在基于累加器的体系结构中,累加器用作隐式源操作数和目标.其他早期的IS假设操作数存储在堆栈中[last in,首先输出（LIFO）]结构和操作在堆栈的顶部一个或两个条目上执行.大多数现代IS假定操作数存储在多个寄存器文件中,并且所有算术和逻辑操作都在存储在寄存器中的操作数上执行.设计特殊指令,例如加载和存储指令,以在寄存器文件和主存储器之间移动操作数.一些传统的ISA允许操作数直接来自寄存器文件和主存储器.被设计为在寄存器文件和主存储器之间移动操作数.一些传统的ISA允许操作数直接来自寄存器文件和主存储器.被设计为在寄存器文件和主存储器之间移动操作数.一些传统的ISA允许操作数直接来自寄存器文件和主存储器.

由于重新编译或重新开发软件的惯性,ISA倾向于非常缓慢地发展.通常,在软件开发人员愿意支付重新编译其现有应用程序的开销之前,需要增加两倍的性能.虽然现有ISA的新扩展可能会不时发生,以适应新兴的应用程序,但推出全新的ISA是一项艰巨的任务.为新的ISA开发有效的编译器和操作系统可能需要10年以上的时间.ISA存在的时间越长,基于该ISA的软件安装基数越大,更换ISA就越困难.一个可能的例外可能是某些特殊应用领域,其中专门的新ISA可能能够提供显着的性能提升,

与IS A创新的冰川蠕变不同,每隔3到5年就可以开发出新的微架构.在20世纪80年代,人们普遍对ISA的设计感兴趣,并就ISA的最佳功能构成了热烈的争论.然而,自20世纪90年代以来,重点已经转移到实施和创新的微体系结构技术,这些技术适用于大多数（如果不是全部）ISA.过去几十年中主导微处理器领域的少数ISA很可能会在未来十年继续这样做.另一方面,我们可以期待在未来十年中看到与这些IS As截然不同且具有创新性的微体系结构.

### 1.2.4动态静态接口

到目前为止,我们已经讨论了ISA发挥的两个关键作用.首先,它提供了软件和硬件之间的契约,这有利于程序和机器的独立开发.其次,ISA用作微处理器设计的规范.所有实现都必须满足要求并支持ISA中指定的功能.除了这两个关键角色之外,每个ISA还有第三个角色.每个ISA的定义中固有的是一个接口的关联定义,它将编译时静态完成的内容与运行时动态完成的内容分开.该接口被Yale Patt称为动态静态inteiface（DSI）,如图1.2所示[Melvin and Patt,1987].

DSI是将ISA作为软件和硬件之间的契约的直接结果.传统上,在编译时在静态域中完成的所有任务和优化都涉及软件和编译器,并且被认为是在OSI之上.相反,在运行时在动态域中完成的所有任务和优化都涉及硬件,并被视为低于DSI.所有体系结构功能都在ISA中指定,因此在静态域中暴露给DSI上方的软件.另一方面,微体系结构的所有实现功能都在DSI之下,并在运行时在动态域中运行; 通常这些都是静态域中的软件和编译器完全隐藏的.如前所述,

设计ISA的一个关键问题是OSI的放置.在顶部的高级语言编写的应用程序和底部机器的实际硬件之间,可能存在可能放置DSI的不同级别的抽象.DSI的位置与决定放置在DSI上方的内容以及放置在DSI下方的内容相关.
例如,可以通过编译器在DSI上方执行的优化以及在微架构中的DSI下执行的优化来实现性能.理想情况下,DSI应放置在实现静态技术和动态技术之间最佳协同的水平,即利用编译器复杂性和硬件复杂性的最佳组合来获得所需的性能.由于不断发展的硬件技术和编译器技术,这种DSI布局成为一项真正的挑战.

在ISA设计的历史中,已经提出了DSI的许多不同的位置,并且一些已经导致商业上成功的ISA.DSI可能放置的概念图如图1.3所示.这个数字不是非常严格,而只是为了说明DSI可以放在不同的水平.例如,Mike Flynn建议将DSI置于DSI之下并执行所有操作,以便用高级语言编写的程序可以直接由可执行语言机器执行[Flynn和Hoevel,1983].复杂指令集计算机（CISC）ISA将DSI置于传统汇编语言或宏代码级别.相反,精简指令集计算机（RISC）ISA降低DSI并期望通过编译器执行DSI之上的更多优化.降低DSI有效地暴露并提升了CISC ISA中微架构特征到ISA级别的能力.这样做的目的是降低硬件复杂性,从而实现更快的机器[Colwell et al.,1985].

DSI在架构和实现之间提供了重要的分离.违反这种分离可能会成为问题.随着ISA的发展和扩展的增加,DSI的位置被隐式转移.通过将先前的实现特性提升到体系结构级别来降低DSI有效地将部分原始微体系结构暴露给软件.这可以促进编译器的优化,从而降低硬件复杂性.
但是,硬件技术变化很快,实施必须适应和发展才能利用技术变革.随着实现风格和技术的改变,一些较旧的技术或微体系结构特征可能变得无效或甚至不合需要.如果其中一些旧功能被提升为ISA级别,那么它们将成为ISA的一部分,并且将存在已安装的软件库或包含这些功能的遗留代码.由于所有未来的实现必须支持整个ISA以确保所有现有代码的可移植性,因此不幸的后果是所有未来的实现必须继续支持先前已经提升的ISA功能,即使它们现在无效甚至是不合需要的.真正的国际检索单位已经犯了这样的错误.从这些错误中吸取的教训是,必须以纪律严明的方式保持严格的架构和微体系结构分离.理想情况下,体系结构或ISA应该只包含表达软件算法的功能或语义所必需的功能,而用于促进更好的程序性能的所有功能应该降级到实现或微体系结构域.

本书的重点不是ISA设计,而是微架构技术,几乎完全强调性能.ISA功能可以影响设计工作量和实现高性能所需的设计复杂性.然而,我们的观点是,在当代高端微处理器设计中,微架构,而不是ISA,是微处理器性能的主要决定因素.因此,本书的重点是实现高性能的微架构技术.还有其他重要的设计目标,例如功率,成本和可靠性.然而,历史上性能受到了最多的关注,并且在提高性能的技术方面有大量知识.正是这本书正在试图编纂这一知识体系.

## 1.3处理器性能原理

新型前沿微处理器的主要设计目标是性能.每一代新一代微体系结构都力求显着改善上一代的性能.近年来,降低功耗已成为另一个可能同样重要的设计目标.但是,对更高性能的需求将始终存在,处理器性能将继续成为关键的设计目标.

### 1.3.1处理器性能方程

在20世纪80年代,一些研究人员独立发现或制定了一个明确定义处理器性能的方程式,并清晰地描述了有助于处理器性能的基本因素.这个等式已经被称为处理器性能的铁律,并在中显示
公式（1.1）.首先,处理器性能等式表明处理器的性能是根据执行特定程序（时间/程序）所需的时间来衡量的.其次,这种时间/程序或执行时间的度量可以表示为三个术语的乘积:指令/程序,周期/指令和时间周期.第一项表示需要为特定程序执行的动态指令总数; 该术语也称为指令计数.第二项平均表示（对程序的整个执行进行平均）执行每条指令消耗了多少个机器周期; 通常,该术语表示为CPI（每个指令的周期）.第三项表示每个机器循环的时间长度,即机器的循环时间.

程序的执行时间越短,性能越好.查看公式1.1,我们可以得出结论,通过降低此公式中三个项中任何一个项的大小,可以提高处理器性能.如果可以减少指令计数,则执行的指令将会减少,执行时间也会减少.如果CPI降低,那么平均每条指令将消耗更少的机器周期.如果可以减少循环时间,那么每个循环将消耗更少的时间并且总体执行时间减少.从这个等式可能看来,提高性能是非常微不足道的.不幸的是,它并不那么简单.这三个术语并非都是独立的,它们之间存在复杂的相互作用.任何一个术语的减少都可能会增加其他两个术语的数量.三个术语之间的关系不容易表征.提高性能成为一个真正的挑战,涉及细微的权衡和微妙的平衡行为.正是这一挑战使处理器设计变得迷人,有时更像是一门艺术而非科学.第l.3.2节将更仔细地研究提高处理器性能的不同方法.

### 1.3.2处理器性能优化

可以说所有性能优化技术都归结为减少处理器性能方程中的三个项中的一个或多个.一些技术可以减少一个术语,而其他两个技术保持不变.例如,当编译器执行消除目标代码中冗余和无用指令的优化时,可以减少指令计数而不影响CPI或循环时间.作为另一个例子,当使用更快的电路技术或更先进的制造工艺来减少信号传播延迟时,可以潜在地减少机器周期时间而不影响指令计数或CPI.这种类型的性能优化技术总是令人满意的,并且如果成本不高,则应该采用这种技术.

减少其中一个术语的其他技术可以同时增加一个或两个其他术语.对于这些技术,只有当一个术语的减少不会被其他术语的增加所淹没时,才能获得性能提升.我们可以通过查看处理器性能方程中三个项中每个项的减少来检查这些技术.

有许多方法可以减少指令数量.首先,指令集可以包括更复杂的指令,每个指令执行更多的工作.执行的指令总数可能会显着减少.  例如,RISC ISA中的程序可能需要两倍于CISC ISA中的程序.  虽然指令计数可能下降,但执行单元的复杂性可能增加,导致循环时间的潜在增加.  如果使用更深的流水线操作来避免增加循环时间,那么更高的分支误预测惩罚可能导致更高的CPI.  其次,某些编译器优化可能导致执行的指令更少.  例如,展开循环可以减少执行的循环结束指令的数量.  然而,这可能导致静态代码大小的增加,这又会影响指令高速缓存命中率,这反过来又会增加CPI.  另一个类似的例子是函数调用的内嵌.  通过消除调用和返回,执行的指令更少,但代码大小可以显着扩展.  第三,最近研究人员提出通过微体系结构技术动态消除冗余计算.  他们观察到,在程序执行期间,频繁地使用相同的数据集重复执行相同的计算.  因此,可以缓冲并直接使用较早计算的结果,而无需重复相同的计算[Sodani和Sohi,1997].  这种计算重用技术可以减少指令计数,但是可能潜在地增加硬件实现中的复杂性,这可能导致周期时间的增加.  我们看到减少指令数可能会导致CPI和/或周期时间的增加.  最近,研究人员提出通过微体系结构技术动态消除冗余计算.  他们观察到,在程序执行期间,频繁地使用相同的数据集重复执行相同的计算.  因此,可以缓冲并直接使用较早计算的结果,而无需重复相同的计算[Sodani和Sohi,1997].  这种计算重用技术可以减少指令计数,但是可能潜在地增加硬件实现中的复杂性,这可能导致周期时间的增加.

降低CPI的愿望激发了许多建筑和微架构技术.RISC的关键动机之一是降低每条指令的复杂性,以减少处理每条指令所需的机器周期数.正如我们已经提到的,这带来了增加指令数的开销.降低CPI的另一个关键技术是指令流水线.流水线处理器可以重叠多个指令的处理.与非流水线设计相比,假设循环时间相同,流水线设计可以显着降低CPI.较浅的管道,即管道阶段较少的管道,可以产生比较深管道更低的CPI,但代价是增加循环时间.使用高速缓冲存储器来减少平均存储器访问等待时间（就时钟周期数而言）也将降低CPI.当采用条件分支时,由于必须从非顺序位置获取下一条指令,因此可能导致循环.分支预测技术可以减少这种停滞周期的数量,从而导致CPI的降低.但是,添加分支预测器可能会增加循环时间,因为在获取管道阶段会增加复杂性,或者如果需要更深的流水线来维持相同的循环时间,甚至可以增加CPI.超标量处理器的出现aI10使处理器流水线同时处理每个管道阶段中的多个指令.通过在每个机器周期中维持多个指令的执行,可以显着降低CPI.
当然,每个管段的复杂性可能增加,导致循环时间或管道深度的潜在增加,这又可以增加CPI.

缩短周期时间的关键微体系结构技术是流水线技术.
流水线操作有效地将处理指令的任务划分为多个阶段.每个管道级的延迟（就信号传播延迟而言）决定了机器周期时间.通过采用更深的管道,可以减少每个管段的延迟,从而减少循环时间.近年来,积极的流水线技术一直是用于实现高端微处理器时钟频率显着增加的主要技术.从表1.1中可以看出,在最近十年中,大部分性能提升都是由于时钟频率的增加.

通过更深的流水线提高时钟频率有一个缺点.随着管道越来越深入,CPI可以通过三种方式上升.首先,随着管道的前端变得更深,获取和执行之间的管道级数增加.这增加了分支被错误预测时产生的惩罚周期数,从而导致CPI增加.其次,如果流水线太深以至于原始算术逻辑单元（ALU）操作需要多个周期,则两个相关指令之间的必要等待时间（即使使用结果转发硬件）将是多个周期.第三,随着时钟频率随着更深的中央处理单元（CPU）流水线而增加,存储器的等待时间在时钟周期数方面可以显着增加.这可能会增加内存操作的平均延迟,从而增加总体CPI.最后,流水线操作中存在硬件和延迟开销,这可能导致性能提升的收益递减.这种通过更深层次流水线获得更高频率的技术已经有十多年的历史了.目前尚不清楚在必要的复杂性和功耗变得令人望而却步之前,我们能够进一步推动它.

从这个讨论中可以得出结论,实现性能改进并不是一项简单的任务.它需要有趣的权衡,涉及许多有时非常微妙的问题.业内最有才华的微架构和处理器设计人员似乎都拥有直觉和洞察力,使他们能够比其他人做出更好的权衡.本书的目标或者也许是梦想,不仅要传授超标量处理器设计的概念和技术,还要传授精湛的微架构的直觉和见解.

### 1.3.3性能评估方法

在现代微处理器设计中,硬件原型设计是不可行的; 大多数设计师使用模拟器进行性能投影,并确保在设计过程中的功能正确性.通常使用两种类型的模拟器:功能模拟器和性能模拟器.功能模拟器在体系结构（ISA）级别对机器进行建模,并用于验证程序的正确执行.功能模拟器实际上解释或执行程序的指令.性能模拟器对设计的微体系结构进行建模,并用于测量执行程序所需的机器周期数.
通常,性能模拟器不关心指令执行的语义正确性,而只涉及指令执行的时序.

性能模拟器可以是跟踪驱动的,也可以是执行驱动的; 如图1.4所示.跟踪驱动的性能模拟器处理预生成的跟踪,以确定执行跟踪中的指令的循环计数.跟踪捕获执行的动态指令序列,并且可以以三种不同的方式生成; 见图1.4（a）.一种方法是通过软件检测,它在运行时将特殊指令插入程序中,这样当在物理系统上执行检测程序时,插入的指令将产生动态执行跟踪.另一种方法是通过硬件仪器.其中包括放置特殊的硬件探针来监视系统总线,并在系统上执行程序时记录实际的执行跟踪.
软件工具可以显着增加代码大小和程序执行时间.硬件仪器需要监控硬件,并且受到监控硬件的缓冲能力的严重限制.第三种跟踪生成方法使用功能模拟器来模拟程序的执行.在模拟期间,钩子嵌入在模拟器中以记录动态执行轨迹.对于所有三种方法,一旦生成了跟踪,就可以将它们存储起来,以供跟踪驱动的性能模拟器随后重复使用.

执行驱动的性能模拟器克服了跟踪驱动的性能模拟器的一些限制; 见图1.4（b）.执行驱动的性能模拟器不是使用预生成的跟踪,而是与功能模拟器连接,两个模拟器协同工作.在模拟期间,功能模拟器执行指令并将与执行的指令相关联的信息传递给性能模拟器.然后,性能模拟器跟踪这些指令的时序及其在流水线阶段的移动.它能够向功能模拟器发出指令,以检查模拟状态,然后从检查点状态恢复.检查点功能允许模拟推测指令,例如分支预测之后的指令.更具体地说,执行驱动的模拟可以模拟错误推测的指令,例如错误预测的分支之后的指令,通过管道.在跟踪驱动仿真中,预生成的跟踪仅包含执行的实际（非预测）指令,并且跟踪驱动的仿真器无法考虑错误推测路径上的指令以及它们与其他（非推测）指令的潜在争用资源.
执行驱动的模拟器还减少了存储长迹线的需要.大多数调制解调器性能模拟器采用执行驱动的范例.功能模拟器支持最先进的执行驱动性能模拟器,能够执行全系统仿真,即模拟应用程序和操作系统指令,内存层次结构,甚至输入/输出设备.

在性能模拟器中微体系结构模型的实际实现可以在明确建模的机器资源的数量和细节方面变化很大.一些性能模型仅仅是循环计数器,其假设无限的资源并且仅考虑指令间依赖性来简单地计算执行迹线所需的总循环数.其他人明确地模拟了机器的组织及其所有组件模块.这些性能模型实际上模拟了指令在各个流水线阶段的移动,包括在每个机器周期中分配有限的机器资源.虽然许多性能模拟器声称“周期精确”,但他们用来建模和跟踪每个机器周期中的活动的方法可能完全不同.

虽然在微处理器的早期设计阶段严重依赖性能模拟器,但验证性能模拟器的准确性是一项极其困难的任务.通常,性能模型或模拟器在设计的早期阶段实现,并用于对各种微体系结构特征进行初始权衡.在此阶段,没有可用于验证性能模型的参考.随着设计的进展和设计的RTL模型的开发,RTL模型可以作为参考来验证性能模型的准确性.但是,使用RTL模型的模拟非常慢,因此只能使用非常短的迹线.在整个设计过程中,规则对于同时发展性能模型和RTL模型以确保性能模型跟踪RTL模型中所做的所有更改至关重要.对性能模型进行硅后验证也很重要,这样它就可以作为下一代设计的良好起点.学术研究中使用的大多数性能模拟器从未经过验证.这些模拟器可能非常复杂,就像所有大型软件一样,可能包含许多难以消除的错误.很多研究论文中使用未经验证的性能模型发布的大部分性能数据很可能是完全错误的.Black对于更严格的处理器模拟器验证令人信服[Black and Shen,1998].

除了验证其准确性的困难之外,与性能模拟器相关的另一个问题是经常需要的极长的模拟时间.大多数现代性能评估涉及模拟许多基准测试和总共数十到数百亿条指令.在设计的早期阶段,性能模拟器被广泛用于支持许多权衡的探索,这需要在仿真模型中使用不同的参数集进行许多模拟运行.对于具有相当详细的复杂机器模型的执行驱动的性能模拟器,四到五个数量级的减速因子是相当普遍的.换句话说,要模拟目标机器的单个机器周期,即正在建模的机器,可能需要执行10,主机上有000到100,000个机器周期.即使使用大量模拟机,大量的模拟运行有时也需要很长时间才能完成.

## 1.4指令级并行处理

指令级并行处理可以非正式地定义为多个指令的并发处理.传统的顺序处理器一次执行一条指令.在处理下一条指令之前完成前导指令.在某种程度上,流水线处理器通过重叠多个指令的处理来实现指令级并行处理的形式.与管道阶段一样多的指令可以在任何时间同时在飞行中.传统的顺序（CISC）处理器可能需要平均大约10个机器周期来处理每条指令,即CPI = 10.使用流水线（RISC）处理器,即使每条指令仍然需要多个周期才能完成,通过重叠处理管道中的多个指令,

使用标量流水线处理器,在每个机器周期中仍然存在获取和启动最多一条指令进入管道的限制.有了这个限制,可以实现的最佳CPI就是一个; 或者相反,标量处理器的最佳可能吞吐量是每个周期一个指令（lPC）.更积极的指令级并行处理形式是可能的,其涉及在每个机器周期中将多个指令提取和启动到更宽的流水线处理器中.虽然20世纪80年代采用CPI = 1作为单片微处理器的设计目标,但20世纪90年代的目标是将CPI降低到1以下,或者实现IPC的吞吐量大于1.能够将IPC大于一的处理器称为超标量处理器.

## 1.4.1从标量到超标量

标量处理器是流水线处理器,设计用于在每个机器周期获取和发出最多一条指令.超标量处理器是那些旨在每个机器周期获取和发出多个指令的处理器.本小节介绍了从标量到超标量处理器实现的基础和动机.

#### 1.4.1.1处理器性能. 

在1.3.1节中,我们介绍了处理器性能的铁律,如公式（1.1）所示.该等式实际上表示作为指令计数,平均CPI和时钟周期时间的乘积的性能的倒数.我们可以重写该等式,直接将性能表示为指令计数的倒数,平均fPC（I PC = lICPI）和时钟频率的乘积,如公式（1.2）所示.看看这个等式,我们看到可以通过增加IPC,增加频率或减少指令数来提高性能.

指令计数由三个因素决定:指令集架构,编译器和操作系统.ISA和编码到每条指令中的工作量可以强烈影响为程序执行的指令总数.编译器的有效性也会强烈影响执行的指令数.由应用程序调用的操作系统功能有效地增加了在执行程序时执行的指令总数.

平均IPC（每个周期的指令）反映了处理器实现的平均指令吞吐量,并且是微架构有效性的关键指标.
历史上,IPC的反转,即CPI（每指令周期数）,已用于指示处理每条指令所需的平均机器周期数.
在标量流水线处理器时代,CPI的使用很受欢迎.由于各种形式的管道停顿造成的性能损失可以清楚地表述为不同的CPI开销.当时,标量流水线处理器的最终性能目标是将平均CPI降低到1.随着我们进入超标量域,使用IPC变得更加方便.超标量处理器的新性能目标是实现大于1的平均IPC.本书中介绍的大部分微体系结构技术都是针对IPC的改进.

频率受制造技术和电路技术的强烈影响.通过减少每个管道级中的逻辑门级数量,增加流水线级的数量也可以促进更高的时钟频率.传统管道在每个管道阶段最多可以有20级逻辑门; 大多数现代管道只有10个或更少的水平.为了在超标量设计中实现高IPC,必须使管道更宽,以允许在每个管道级中同时处理多个指令.管道的扩大增加了每个管道级的硬件复杂性和信号传播延迟.因此,对于更宽的管道,为了保持相同的频率,可能需要更深的管道.在使管道更宽并使其更深入之间存在复杂的权衡.

#### 1.4.1.2并行处理器性能. 
当我们考虑并行处理指令以提高处理器性能时,重新审视通常被称为Amdahl定律的并行处理的经典观察是很有见地的[Amdahl,1967].传统的超级计算机是并行处理器,可执行标量和向量计算.在标量计算期间,仅使用一个处理器.在向量计算期间,所有N个处理器用于对阵列数据执行操作.由这种并行机器执行的计算可以如图l.5所示,其中N是机器中处理器的数量,h是机器在标量计算中花费的时间的分数.相反,1  -  h是机器在矢量计算中花费的时间的一部分.
Amdahl定律的一个表述是并行机器的效率E是通过N个处理器的总体利用率或N个处理器忙碌的时间部分来衡量的.效率E可以建模为

随着处理器N的数量变得非常大,效率E接近1-h,这是机器在矢量计算中花费的时间的一部分.随着N变大,在矢量计算中花费的时间量变得越来越小并且接近零.因此,当N变得非常大时,效率E接近零.这意味着几乎所有的计算时间都采用标量计算,并且进一步增加N对减少总体执行时间的影响非常小.

该相同原理的另一种表述基于在矢量计算模式中可以完成的工作量,或者程序的可矢量化.如图l.5所示,frepresents可以并行化以在向量计算模式下运行的程序部分.因此,1-f表示必须顺序执行的程序部分.如果T是运行程序所需的总时间,则相对加速比S可以表示为

其中T是（1-j）的总和,执行顺序部分所需的时间,以及fi N,执行程序的可并行化部分所需的时间.当N变得非常大时,该和的第二项接近于零,并且总执行时间由执行顺序部分所需的时间量决定.这通常被称为顺序瓶颈; 也就是说,在顺序执行或标量计算上花费的时间成为通过利用并行性可以实现多少整体性能改进的限制.随着N增加或机器并行性增加,性能将变得越来越敏感并且由程序的顺序部分决定.

随着处理器数量的增加,并行处理器的效率会迅速下降.此外,由于程序的可矢量化（即,可并行化的程序的分数）从100％略微下降,因此效率下降率增加.类似地,当f（程序的可矢量化性能）从100％下降到非常小的时候,总体加速下降得非常快.因此,整体性能改进对程序的可矢量化非常敏感; 或者换句话说,由于并行处理的整体加速由程序的顺序部分强烈决定,因为机器并行性增加.

#### 1.4.1.3流水线处理器性能. 
Harold Stone提出可以为流水线处理器开发类似于并行处理器的性能模型[Stone,1987].流水线处理器的典型执行配置文件如图1.6（a）所示.机器并行性参数N现在是管道的深度,即管道中的级数.此执行配置文件分为三个阶段.第一阶段是管道填充阶段,在此期间N个指令的第一序列进入管道.第二阶段是管道满阶段,在此期间管道已满并表示管道的稳定状态.这假设没有管道中断,因此代表完美的管道执行配置文件.第三阶段是管道排水阶段,

出于建模目的,我们可以通过将管道填充阶段期间完成的一些工作移动到管道排放阶段,将图1.6（a）的执行配置文件修改为图1.6（b）的执行配置文件.工作总量保持不变; 也就是说,两个配置文件中的区域是相等的.流水线级数是N,所有N个流水线级使用的时间部分是g,1-g是仅使用一个流水线级的时间部分.基本上1-g可以看作只有一条指令通过管道的时间的一小部分; 也就是说,管道中没有重叠的指令.

与理想化的流水线执行配置文件不同,实际的流水线执行配置文件必须考虑停顿周期.这可以如图1.7（a）所示完成.而不是在整个执行期间保持在流水线的完整阶段,这种稳定状态被流水线停顿中断.由于管道满相中断,每个失速有效地引起新的管道排放阶段和新的管道填充阶段,如图1.7（a）所示.可以对该执行轮廓执行类似的修改,以通过将在两个管道填充阶段中完成的部分工作移动到两个管道排放阶段来产生图1.7（b）的修改的轮廓.现在,图1（b）的修改后的配置文件类似于并行处理器的执行配置文件,如图1.5所示.
由于执行配置文件的相似性,我们现在可以借用并行处理器的性能模型并将其应用于管道式处理器.现在,N不是处理器的数量,而是管道阶段的数量,或者是可能的最大加速.现在,参数g成为管道填充时的一小部分,参数1-g现在表示管道停止时的一小部分时间.现在可以获得加速S.

注意,g,管道满的时间部分,类似于f,即并行处理器模型中程序的可矢量性.因此,Amdahl定律可以类似地应用于流水线处理器.由于g从100％略微下降,流水线处理器的加速或性能可能会很快下降.换句话说,通过流水线操作可以获得的实际性能增益可以通过一小部分失速周期而大大降低.
随着流水线N的程度增加,失速循环的比例将变得越来越破坏管道处理器可以实现的实际加速.流水线处理器中的停顿周期现在是关键的对手,类似于并行处理器的顺序瓶颈.本质上,停顿周期构成了流水线处理器的顺序瓶颈.

公式（1.5）是基于Amdahl并行处理器定律的流水线处理器的简单性能模型.在该模型中假设每当流水线停止时,流水线中只有一条指令,或者它实际上变为顺序非流水线处理器.这意味着当管道停止时,不允许重叠指令; 这实际上相当于将流水线停顿N个周期以允许导致失速的指令完全遍历流水线.然而,我们知道,通过巧妙地设计管道,例如使用转发路径,来解决导致管道停滞的危险,所产生的惩罚周期数不一定是N,并且很可能小于N.在这一观察中,对方程模型的改进（1.


公式（1.6）是公式（1.5）的推广,并为流水线处理器性能提供了精确的模型.在此模型中,gi表示管道中有i个指令的时间部分.换句话说,gi表示管道在（N-i）惩罚周期停滞的时间部分.当然,gN是管道满的时间的一部分.

该流水线处理器性能模型通过将其应用于第2章中的六级TYP流水线来说明.注意,TYP流水线具有一个周期的负载惩罚和四个周期的分支惩罚.根据来自的统计数据
在第2章中介绍的IBM研究中,负载和分支指令的典型百分比分别为25％和20％.假设TYP流水线的设计偏向于未采用的分支,只有66.6％的分支指令（实际采用的那些）将导致分支惩罚.因此,只有13％的指令（分支）将产生四周期惩罚,25％的指令（负载）将导致一个周期的惩罚.其余的说明
（62％）将不会受到惩罚.TYP管道的性能可以如公式（1.7）所示建模.


六级TYP流水线处理器的最终性能是顺序或非流水线处理器的4.5倍.请注意,TYP是一个六级管道,理论加速电位为6.基于我们的公式（1.6）模型的实际加速比为4.5,如公式（1.7）所示,可视为有效度TYP管道的管道衬里.基本上,六级TYP处理器表现为具有4.5个流水线级的完美流水线.
6和4.5之间的差异反映了潜在（峰值）管道并行性与实现的（实际）管道并行性之间的差异.

#### 1.4.1.4超标量提案. 
我们现在重申Amdahl定律来模拟并行处理器的性能:


该模型给出了并联系统的性能或加速比非并联系统的性能或加速.机器并行度由N（机器中处理器的数量）测量,并反映系统可以同时执行的最大任务数.然而,参数f是反映程序并行性的程序的可矢量化性.该模型的配方受到包含标量单元和矢量单元的传统超级计算机的影响.由N个处理器组成的向量单元通过一次执行N个任务来执行程序的可向量化部分.然后,程序的不可向量部分以顺序方式在标量单元中执行.

程序的不可归属部分必须按顺序执行的假设过于悲观并且不是必需的.如果对于程序的不可向量部分可以实现一些甚至低的并行度,则可以显着地缓和顺序瓶颈的严重影响.图1.8说明了这个原理.这个图来自Agerwala和Cocke [1987]共同撰写的IBM技术报告,它将加速作为一个函数关闭,程序的可引导性,对于N的几个值,即机器的最大并行度.
以N = 6为例.以加速为例

检查图1.8中的等式（1.9）的曲线,我们看到加速等于6 iff是100％,即完全可矢量化.当f从100％下降时,加速很快就会下降; 当f变为0％时,加速为1; 也就是说,没有获得加速.随着N的值越来越高,这种加速下降率变得越来越差,并且当f接近0％时,无论N的值如何,所有加速都接近1.现在假设可以实现2的最小并行度.程序的不可归属部分.加速现在变成了

检查图1.8中的等式（L10）的曲线,我们看到它也以6的加速开始,当fis为100％时,但当fis从100％降低时,比等式（1.9）的曲线下降得更慢.实际上,该曲线越过方程（1.8）的曲线,当f =约75％时N = 100.这意味着对于不超过75％的情况,最大并行度仅为6的系统更有利,即N = 6,但对于不可采用部分,最小并行度为2,而最大并行度为N的系统则更为有利. = 100,顺序执行不可归属部分.程序的可矢量化是涉及应用程序算法,编程语言,编译器和体系结构的复杂函数.除了主要涉及数值计算的科学应用之外,大多数用于通用计算的程序往往没有很高的可矢量化性.可以肯定地说,大多数通用程序只有75％,而对于许多人来说,显着更少.

设计超标量处理器的一个主要动机是开发通用处理器,该处理器可以为广泛的应用程序实现一些（可能相对于向量化的低）并行度.目标是确保可以为程序的所有部分实现某种程度的指令级并行性,以便缓和顺序瓶颈的严重影响.当然,高度可矢量化的程序将通过并行性继续实现良好的加速.注意,即使在高值关闭时,公式（1.10）的曲线总是高于公式（1.9）的曲线,并且在较低值关闭时高于其他曲线的大值为N超标量处理器的目标是实现广义指令级并行性和随后的所有类型应用程序的加速,

### 1.4.2指令级并行的限制

在等式（1.10）中,可以为程序的分数实现6阶的并行性,并且对于程序的剩余1-f分数可以实现2阶的并行性.加速S可以被视为整个程序可以实现的聚合并行度.例如,如果参数f为50％且峰值并行度N为6,则加速度或聚合度的并行度为

等式（1.11）的含义是,对于整个程序有效地实现了3的整体或聚合并行度.在指令级应用该结果,我们看到等式（l.11）表示一次可以同时执行三条指令的平均值.对于传统的向量计算,可以同时执行的操作的数量很大程度上取决于向量或数组的大小,或者基本上是数据集大小.对于通用非结构化程序,关键问题是,可以实现什么样的指令级并行度？

指令级并行性可以非正式地定义为可以通过并发执行多个指令来实现的并行度的聚合度（通过指令的数量来衡量）.近三十年来已经研究了ILP的可能限制.已经进行了许多实验研究,其在所声称的ILP限度上产生了广泛不同的结果.下表按ILP程度的增加顺序提供了报告限值的样本列表.

|研究| ILP限制
|  -  |  - 
| Weiss和Smith,1984 | 1.58
| Sohi和Vajapeyam,1987 | 1.81
| Tjaden和Flynn,1970 | 1.86
| Tjaden和Flynn,1973 | 1.96
| Uht和Wedig,1986 | 2.0
| Smith et a.,1989 | 2.0
| Jouppi和Wall,1989 | 2.4
|约翰逊,1991 | 2.5
| Acosta等,1986 | 2.79
| Wedig,1982 | 3.0
| Butler et a.,1991 | 5.8
| Melvin和Patt,1991 | 6
| Wall,1991 | 7
| Kuck et a.,1972 | 8
| Riseman和Foster,1972年| 51
| Nicolau和Fisher,1984年| 90

这个清单肯定不是详尽无遗的,但清楚地说明了研究结果的多样性和可能的不一致性.其中大多数都是极限研究,提出了各种理想化的假设.真正的挑战是如何在现实设计中实现这些ILP水平.就时间顺序而言,所谓的限制也不是单调的.在20世纪90年代的十年间,关于ILP限制的争论取代了RISC VS. CISC关于20世纪80年代的争论[Colwell et al.,1985].关于ILP限制的这一新辩论仍未解决.

#### 1.4.2.1弗林的瓶颈. 
最早由Tjaden和Flynn于1970年在斯坦福大学完成的研究之一得出结论,大多数项目的ILP小于2.这个限制被非正式地称为Flynn的瓶颈.本研究主要关注可在基本块边界内找到的指令级并行性.由于交叉基本块边界涉及交叉控制依赖性,这可能取决于运行时数据,因此假设必须顺序执行基本块.由于大多数基本块的尺寸较小,通常发现的平行度小于2.这个结果或Flynn的瓶颈已经被其他几项研究所证实.

1972年的一项研究证实了这一结果,是Riseman和Foster [1972].然而,他们扩展了他们的研究,以检查如果可以克服某种控制依赖性可以实现的ILP程度.该研究报告了如果可以克服各种数量的控制依赖性,可以实现不同程度的并行性.如果可以克服的控制依赖性的数量是无限的,则ILP的限制大约为51.该研究强调了控制依赖性对ILP限制的强烈影响.

#### 1.4.2.2费舍尔的乐观主义. 

另一方面是Nicolau和Fisher于1984年在耶鲁大学进行的一项研究.该研究暗示了许多程序中几乎无限量的ILP.本研究中使用的基准测试往往更具数字性,测量的一些并行性是由于阵列型数据集导致的数据并行性.假设能够同时执行许多指令的理想化机器模型.虽然在这项研究中做出了一些理想化的假设,但它确实提供了一个令人耳目一新的乐观前景,即由于弗林的瓶颈而可以对抗悲观情绪所获得的ILP数量.我们非正式地将这个声称的ILP限制称为费舍尔的乐观主义.

最初这种乐观主义受到了极大的怀疑.许多后续事件在某种程度上证明了这项研究的正确性.首先,开发了称为VLIW（超长指令字）处理器的原型机器模型以及支持编译器[Fisher,1983].随后,成立了一家商业企业（Multiflow,Inc.）,开发了一台真实的VLIW机器,从而生产出Multiflow TRACE计算机.TRACE机器由功能强大的VLIW编译器支持,该编译器采用跟踪调度（由Josh Fisher等人开发）来提取指令级并行性[Fisher,1981].Multiflow,Inc.取得了相当的成功,最终安装了100多台机器.更重要的是,短命的商用TRACE机器是第一个达到平均IPC大于1的通用单处理器.尽管TRACE机器实现的ILP实际水平远远低于Nicolau和Fisher早先在1984年公布的限值,但它们确实证实了有大量ILP可以收获超过先前接受的2限制的说法.


## 1.4.2.3促成因素.
许多关于ILP极限的研究采用不同的实验方法并做出不同的假设.三个关键因素促成了广泛的实验结果:使用的基准,假设的机器模型和采用的编译技术.每项研究都采用自己的一套基准,结果往往受到所选基准的强烈影响.最近,标准性能评估公司（SPEC）基准套件已被广泛采用,大多数处理器和计算系统制造商为其系统提供SPEC等级.虽然制造商有严格的指导方针来报告其产品的SPEC评级（参见www.spec.org）,但研究人员仍然对SPEC评级的使用非常不一致.

导致ILP极限混淆和争议的第二个关键因素是关于机器模式的各种研究所做出的假设.大多数极限研究都假设理想化的机器模型.例如,通常不考虑高速缓冲存储器或假设具有100％命中率且具有一个周期等待时间.一些模型假设无限大小的机器具有无限的寄存器文件.通常假设所有操作和功能单元类型都有一个周期的延迟.其他研究使用更现实的机器模型,这些通常导致更悲观,可能不必要的悲观限制.当然,在所使用的指令集架构中也存在大量不一致性.有些是虚构的架构,有些则使用现有的架构.

最后,关于所使用的编译技术的假设是多种多样的.许多研究不包括对编译器的任何考虑; 其他人假设无限强大的编译器.通常,这些研究基于在真实机器上收集的动态痕迹.基于这样的跟踪的仿真结果不仅取决于所选择的基准和架构,而且还强烈依赖于用于生成目标代码的编译器.编制技术对ILP极限的潜在贡献是一个持续的研究领域.目前,全能编译器的假定功能与现有商用编译器的功能之间存在巨大差距.许多人预计在编译领域可以预期会有更多进步.

从目前为止所做的研究中得出的最安全的结论可能是ILP的实际限制超出了目前机器的实际限制.有更多更好的研究空间.任何特定限制的假设可能为时过早.随着更强大和有效的微体系结构的设计和更积极的编译技术的开发,以前做出的假设可能不得不改变,以前声称的限制可能需要向上调整.


## 1.4.3指令级并行机器

指令级并行性被称为与其他形式的粗粒度并行性相关的细粒度并行性,涉及多个程序片段或计算任务的并发处理.设计用于利用通用ILP的机器被称为ILP机器,并且通常是在功能单元级具有机器资源并行性的单处理器.Norm Jouppi在1989年提出了ILP机器的分类[Jouppi和Wall,1989].
ILP机器根据许多参数进行分类.
*操作延迟（OL）.直到指令结果可供后续指令使用的机器周期数.使用的参考指令是一个简单的指令,代表指令集中的大多数指令.操作等待时间是执行这种指令所需的机器周期数.
*机器并行（MP）.机器可以支持的最大同时执行指令数.非正式地,这是在任何时候可以同时在管道中飞行的最大指令数.
*发布延迟（IL）.发出两条连续指令之间所需的机器周期数.参考指令再次是简单的指令.在本上下文中,发布意味着向管道中发起新指令.
*问题并行性（IP）.每个机器周期中可以发出的最大指令数.

在Jouppi的分类中,标量流水线处理器用作基线机器.该分类还使用通用的四阶段指令流程进行说明.这些阶段是
1. IF（取指令）
2. DE（指令解码）
3. EX（执行）
4. WB（回写）

EX阶段用作确定操作等待时间的参考.
用作基线机器的标量流水线处理器被定义为OL = 1循环且IL = 1循环的机器.该基线机器及其指令处理配置文件如图1.9所示,可以在每个周期向管道发出一条新指令,典型指令需要一个机器周期才能执行.相应的MP等于k,即流水线中的级数; 在图1.9中MP = 4. IP等于每个周期一条指令.请注意,所有这四个参数都是机器的静态参数,并没有考虑依赖于正在执行的程序的动态行为.

当我们讨论ILP机器的性能或加速时,该基线机器用作参考.在本章的前面部分,我们提到了流水线处理器可以通过顺序非流水线处理器获得的加速,该加速不会与多个指令的处理重叠.这种加速形式仅限于在标量处理器领域内进行比较,并侧重于（标量）流水线处理器相对于（标量）非流水线处理器可以获得的增加的吞吐量.从处理ILP机器的第3章开始,所提到的加速形式是与标量流水线处理器相比的ILP机器的性能,该处理器用作新的参考机器.


## 1.4.3.1超流水线机器. 
超级管道机器相对于基线机器定义,并且是具有比基线机器更高的流水线度的机器.在超流水线机器中,机器循环时间短于基线机器的时间,并且被称为次循环时间.
超级流水线机的循环时间是基线循环时间的11m,或者相当于基线循环中有m个次循环.超流水线机的特征在于OL = 1循环= m次循环且IL = 1次循环.换句话说,简单指令仍需要一个基线周期,等于m个次循环,以便执行,但机器可以在每个次循环中发出新指令.因此,IP = 1指令/次循环= m指令/循环,MP = m X k.超级流水线机的指令处理配置文件如图1.10所示.

超流水线机是一种管道式机器,其中流水线的程度超出了简单指令的操作延迟所决定的程度.
基本上,超流水线操作涉及将执行阶段流水线化为多个阶段.“管道不足”的机器无法像执行时那样快速地发出指令.另一方面,超流水线机器发出指令的速度比执行速度快.m度的超级流水线机,即需要m个小周期来执行简单操作的机器,可以比基线机器的性能提高m倍.从技术上讲,需要多个周期来执行简单操作的传统流水线计算机应归类为超流水线.例如,在CDC 6600 [Thornton,1964]和CRA Y-1 [Russell,1978]中执行定点加法的延迟是三个周期,并且可以在每个周期中发布新指令.
因此,这些都是超级流水线的机器.
在某种程度上,超流水线机器的分类在某种程度上是人为的,因为它取决于基线周期的选择和简单操作的定义.超级流水线机的关键特性是指令的结果不适用于下一个m-1指令.因此,超流水线处理器可以简单地视为更加流畅的流水线处理器,对转发路径的放置有一些限制.在标准流水线处理器中,隐含的假设是转发路径的源和目的地可以分别是任何流水线级的输出和输入.如果超级流水线机被视为具有mxk阶段的深度流水线机器,然后,无法访问某些阶段的输出以进行转发,并且某些阶段的输入无法接收转发的数据.其原因在于,为了数据转发的目的,在不可中断的意义上,需要多个次循环和多个流水线阶段来完成的一些操作是基本操作.这实际上是流水线和超流水线机器之间的关键区别.在本书之外的本节之外,没有特别处理超流水线机作为与流水线机不同的独立处理器类.在为数据转发目的而不可中断的意义上.这实际上是流水线和超流水线机器之间的关键区别.在本书之外的本节之外,没有特别处理超流水线机作为与流水线机不同的独立处理器类.在为数据转发目的而不可中断的意义上.这实际上是流水线和超流水线机器之间的关键区别.在本书之外的本节之外,没有特别处理超流水线机作为与流水线机不同的独立处理器类.

64位MIPS R4000处理器是首批声称为“超流水线”的处理器之一.在内部,R4000在其管道中有八个物理级,如图1.11所示,物理机器周期时间为10纳秒（ns）[Bashteen et al.,1991,Mirapuri等,1992].但是,该芯片需要50MHz时钟输入,并具有片上时钟倍频器.因此,R4000使用20 ns作为其基线周期,并且相对于具有20 ns周期时间的四级基线机器,它被认为是2级超流水线.每个基线周期有两个小周期.在R4000的情况下,多周期基本操作是高速缓存访​​问操作.例如,前两个物理阶段（IF和IS）需要执行I-cache访问,类似地,DF和DS物理阶段是D-cache访问所必需的.这些是不可中断的操作; 没有数据转发可能涉及IF和IS级之间的缓冲器或DF和DS级之间的缓冲器.高速缓存访​​问,这里被认为是“简单”操作,是流水线的,需要两个（次要）周期的操作延迟.整个管道的问题延迟是一个（次要）周期; 也就是说,每10 ns就可以发出一条新指令.R4000可能比基线四级管道的速度提高2倍.是流水线的,需要两个（次要）周期的操作延迟.整个管道的问题延迟是一个（次要）周期; 也就是说,每10 ns就可以发出一条新指令.R4000可能比基线四级管道的速度提高2倍.是流水线的,需要两个（次要）周期的操作延迟.整个管道的问题延迟是一个（次要）周期; 也就是说,每10 ns就可以发出一条新指令.R4000可能比基线四级管道的速度提高2倍.


## 1.4.3.2超标量机器. 
超标量机器是基线标量流水线机器的扩展,其特征在于OL = 1个循环,IL = 1个循环,以及IP = n指令/循环.机器周期与基线周期相同; 没有小周期.在一个循环中执行简单操作.
在每个循环中,可以发出多个指令.超标量由问题并行度n确定,即每个周期中可以发出的最大指令数.超标量机的指令处理配置文件如图1.12所示.与标量流水线处理器相比,n级的超标量机器可被视为具有n个管道或管道,其在能够在每个流水线级而不是一个流水线级中携带n个指令的意义上宽n倍.超标量机器具有MP = n X k.已经表明,相同程度的超流水线机和超标量机具有相同的机器并行性并且可以实现大致相同的性能水平.

没有理由说超标量机器也不能超流水线.
问题等待时间可以减少到（基线）周期的11m,同时在每个（次要）周期中保持n个指令的问题并行性.总问题并行性或吞吐量将是每（基线）周期的nxm指令.得到的机器并行性将变为MP = n X m X k,其中n是超标量度,m是超流水线度,k是基线机器的流水线度.或者,机器并行度可以被视为MP = nx（mxk）,表示具有m×k个流水线级的超标量机器.这样的机器可以等同地被视为具有超标量n的mxk级的更加流水线的处理器,而不必调用繁琐的术语“超标量 - 超级流水线”机器; 我们不会.


## 1.4.3.3非常长的指令字机器. 
与超标量机相似的是Josh Fisher [Fisher,1983]称为VLIW（超长指令字）机器的另一类ILP机器.这两类机器的意图和性能目标非常相似; 关键的区别在于动态静态接口（DSI）的放置或通过硬件机制在运行时完成的内容的划分以及在编译时通过软件方式完成的操作.VLIW机器的指令处理配置文件如图1.13所示.

与超标量机器不同,VLIW机器的IF和DE级不需要被复制以支持n个单独指令的同时处理,即提取和解码.在超标量机器中,在运行时决定将哪n条指令发布到执行阶段.对于VLIW机器,这种指令发布决定是在编译时进行的,并且要同时发布到执行阶段的n个指令由编译器确定并作为非常长的指令字适当地存储在程序存储器中.

超标量和VLIW机器代表两种不同的方法来实现相同的最终目标,即通过指令级并行处理实现高处理器性能.这两种方法通过不同的历史路径和不同的视角发展而来.有人提出这两种方法是非常协同的,并且有很强的动机去追求这两种方法的潜在整合.本书侧重于微体系结构中实现的动态技术; 因此,我们不会深入探讨
VLIW的功能依赖于积极的编译时技术.



## 1.5摘要

微处理器对计算机行业产生了无与伦比的影响.在微处理器（30年以上）的生命周期中发生的变化是惊人的.微处理器现已进入第四个十年.推测未来十年我们对微处理器的期望是非常有趣的.

虽然这是过去几十年的时尚,但指令集架构（IS A）设计不再是一个非常有趣的话题.我们已经学到了很多关于如何设计优雅且可扩展的ISA的知识.但是,代码兼容性和软件安装基础对于确定ISA的寿命更为重要.已经充分证明,微架构技术可以克服任何ISA缺陷.此外,随着便携式字节码和动态即时（JIT）编译的出现,ISA的含义以及随之而来的动态静态接口（DSI）的放置将变得非常模糊.

在未来十年,微架构将成为行动的所在.随着芯片集成密度接近芯片上的10亿个晶体管,许多传统（宏）架构特性（如存储器子系统,多个处理器和输入/输出子系统）将成为片上问题,从而成为有效的微体系结构问题.传统的系统级架构将成为芯片级设计的一部分.我们可以期待在一个芯片上看到多个处理器,高速缓存存储器层次结构,主存储器控制器（甚至可能是主存储器）,输入/输出设备和网络接口设备的集成.

我们可以期待看到许多新的创新微体系结构技术.当我们接近并可能超过IO-GHz时钟速度时,我们需要重新思考微架构设计的许多基础知识.简单的ALU操作可能需要多个周期.复杂的分支预测器最多可能需要10个周期.主内存延迟将超过1000个周期.遍历整个芯片可能需要数十个时钟周期.我们目前认为非常积极的流水线将被视为相当基本的.

未来的微处理器将成为需要利用各种形式的并行性的单芯片计算系统.这些系统需要超越指令级并行性才能在工作负载中获得线程级并行（TLP）.也许最重要的是在能够处理许多同时存储器访问时追求存储器级并行（MLP）.由于主内存延迟比CPU周期时间慢三个数量级,我们需要找到交换内存带宽的巧妙方法,以减轻长内存延迟对整体性能的严重负面影响.主要挑战将是数据的移动,而不是对数据执行的操作.

**参考**

Acosta,R.,J.Kilestrup和H. Torng:“提高多功能单元处理器性能的指令发布方法”,IEEE Trans.on Computers,C35,9,1986,pp.815-828.

Agerwala,T.和J. Cocke:“高性能精简指令集处理器”,技术报告,IBM计算机科学,1987年.

Amdahl,G.:“实现大规模计算能力的单处理器方法的有效性”,AFlPS Con！Proc.,1967,pp.483-485.

Amdahl,G.,G.Blaauw和FP Brooks,Jr.:“IBM Systeml360的架构”,IBM Journal of Research and Development,8,1964,pp.87-101.

Bashteen,A.,1.Lui和J. Mullan:“MIPS架构的超流水线方法”,Proc.COMPCON Spring 91,1991,pp.325-333.

Blaauw,G.和FP Brooks,Jr.:Computer Architecture:Concepts and Evolution.Reading,MA:Addison-Wesley,1997.

Black,B.和JP Shen:“微处理器性能模型的校准”,计算机,31,5,1998,第59-65页.

巴特勒,M.,T.-Y.Yeh,Y.Patt,M.Alsup,H.Scales和M. Shebanow:“指令级并行度大于2,”Proc.第18届国际 Symposium on Computer Architecture,1991,pp.276-286.

Colwell,R.,C.Hitchcock,E.Jensen,HB Sprunt和C. Kollar:“指令集及其后:计算机,复杂性和争议,”IEEE计算机.1985年8月18日,第8-19页.

Fisher,J.:“跟踪调度:一种全局微码压缩技术.IEEE Trans.on Computers.” C-30,7,1981,pp.478-490.

Fisher,JA:“非常长的指令字架构和ELI-512,”技术报告YLU 253,耶鲁大学,1983.

Flynn,M.和L. Hoevel:“执行架构:DELtran实验,”iEEE Trans.在计算机上.C-32,2,1983,pp.156-175.

Johnson,M.:超标量微处理器设计.Englewood Cliffs,NJ:Prentice Hall,1991.

Jouppi,NP和DW Wall:“超标量和超流水线机器的可用指令级并行性”,Proc.第三国际 能够！编程语言和操作系统的架构支持（ASPLOS-lll）.1989年,第272-282页.

Kuck,D.,Y.Muraoka和S. Chen:“关于可在Fortran类程序中同时执行的操作数量及其产生的加速,”IEEE Tran s.在计算机上.C-21,1972,p~1293-131Q

Melvin,S.和Y. Patt:“通过硬件和软件技术的结合利用细粒度的并行性”,Proc.181h Int.计算机体系结构研讨会.1991年,第287-296页.

Melvin,SW和Y. Patt:“动态/静态界面的澄清”,Proc.第20届夏威夷国际 能够！关于系统科学.1987年,第218-226页.

Mirapuri,S.,M.Woodacre和N. Vasseghi:“MIPS R4000处理器”,IEEE Micro,12,2,1992,pp.10-22.

Nicolau,A.和1. Fisher:“测量可用于很长指令字架构的并行性”,IEEE Transactions on Computers,C-33,1984,pp.968-976.

Riseman,EM和CC Foster:“通过条件跳跃抑制潜在的并行性”,IEEE Transactions on Computers,1972,pp.1405-1411.

Russell,RM:“Cray-I计算机系统”,ACM通讯,21,I,1978,pp.63-72.

Smith,MD,M.Johnson和MA Horowitz:“对多指令问题的限制”,Proc.三是可以！编程语言和操作系统的架构支持（ASPLOS-lll）.1989年,第290-302页.

Sodani,A.和GS Sohi:“动态指令重用”,Proc.第24届年度国际 Symposium on Computer Architecture,1997,pp.194-205.

Sohi,G.和S. Vajapeyam:“用于高性能,可中断流水线处理器的指令问题逻辑”,Proc.第14届年度国际 计算机体系结构研讨会,1987年,第27-34页.

Stone,H.:高性能计算机体系结构.Reading,MA:Addison-Wesley,1987.

Thornton,JE:“Control Data 6600中的并行操作”,AFlPS Proc.FlCC,第2部分,26,1964年,第33-40页.

Tjaden,G.和M. Flynn:“使用排序矩阵表示并发性”,IEEE

跨.在计算机上.C-22,8,1973,pp.752-761.

Tjaden,GS和MJ Flynn:“检测和并行执行独立指令”,IEEE Transactions on Computers,C 19,10,1970,pp.889-895.

Uhl,A.和R. Wedig:“从串行指令流中硬件提取低级并发”,Proc.诠释.骗局！on Parallel Processing,1986,pp.729- 736.

Wall,D.:“指令级并行的限制”,Proc.第4届国际 骗局！on Architectural Support for Programming Languages and Operating Systems,1991,pp.176-188.

Wedig,R.:直接执行语言指令流中的并发检测.博士论文,斯坦福大学,1982年.

Weiss,S.和1. Smith:“流水线超级计算机中的指令问题逻辑”,Proc.第11届计算机体系结构年度研讨会,1984年,第110-118页.


**家庭作业问题**

P1.1使用万维网的资源,列出SPECINT2000,SPECFP2000和TPC-C的前五个报告基准测试结果.

P1.2图表SPECINT2000与两个不同处理器系列（例如,AMD Athlon和HP PA-RISC）的处理器频率之间的频率与www.spec.org上公布的频率一样多.评论频率的性能扩展,指出任何异常并建议可能的解释.

P1.3解释架构,实现和实现之间的差异.解释每个如何与处理器性能相关,如公式（1.1）所示.

P1.4随着硅技术的发展,实现约束和权衡会发生变化,这会影响动态静态接口（DSI）的布局和定义.解释为什么在引入该体系结构时构建分支延迟槽[如在数百万指令/秒（MIPS）体系结构中）是合理的事情,但今天不太有吸引力.

P1.5很多时候,特定代的实现问题最终决定了指令集架构的权衡.讨论至少一个历史实现约束,解释为什么CISC指令集在20世纪70年代是一个明智的选择.

P1.6程序的运行时间由每个程序的指令,每个指令的周期和时钟频率的乘积决定.假设类似MIPS的RISC指令集的以下指令组合:15％存储,25％负载,15％分支,35％整数运算,5％整数移位和5％整数乘法.鉴于加载指令需要两个周期,存储需要一个周期,分支需要四个周期,整数ALU指令需要一个周期,整数乘法需要十个周期,计算总体CPI.  

P1.7给出问题6的参数,考虑一个强度降低优化,它将乘以编译时常数转换为a
一系列的转变和补充.对于该指令混合,可以将50％的乘法转换为平均长度为3个指令的移位相加序列.假设固定频率,计算每个程序的指令变化,每个指令的周期和整个程序加速.


P1.8 Pentium 4处理器等最新处理器不实现单轮转换.给定问题7的情形,假设强度减少引入的s = 50％的附加指令是移位,并且现在移位需要四个周期来执行.重新计算每条指令的周期和整个程序的加速.强度减少仍然是一个很好的优化？

P1.9给出问题8的假设,求解收支平衡比率s
（转移的附加指令的百分比）.也就是说,找到程序性能与没有强度降低的基线情况相同的s（如果有）的值（问题6）.

P1.10考虑到问题8的假设,假设您正在设计Pentium 4处理器上的移位单元.您已经得出结论,移位单元有两种可能的实现方案:频率为2 GHz的四周期移位延迟,或1.9 GHz的双周期移位延迟.
假设管道的其余部分可以在2 GHz运行,因此双循环移位器将整个处理器的频率设置为1.9 GHz.
哪个选项可以提供更好的整体性能？

P1.11使用Amdahl定律,为具有4,8,16和32个处理器的系统计算85％可矢量化程序的加速比.构建用于运行此类应用程序的系统的合理数量的处理器是什么？

P1.12使用Amdahl定律,计算具有16,64,256和1024个处理器的系统98％可矢量化的程序的加速比.构建用于运行此类应用程序的系统的合理数量的处理器是什么？

P1.13对第1.4.2节研究列表中显示的每个ILP限值重新绘制第23页图1.8中的图表.您可以从您创建的图表中得出什么结论？

P1.14通过阅读相关论文并解释为什么极限如此不同来比较和对比这两个ILP极限研究:Jouppi和Wall [1989] vs. Wall [1991].

P1.15 1995年,IBM AS / 400系列计算机从CISC指令集转换为RISC指令集.由于指令集更简单,给定技术生成的可实现时钟频率和CPI指标显着提高.但是,出于同样的原因,每个程序的指令数量也明显增加.  
给定以下参数,计算此转换发生的总体性能改进.此外,假设其他两个因子保持不变,计算此转换的收支平衡时钟频率,每个指令的收支平衡周期以及收支平衡代码扩展比率.

P1.16 MIPS（每秒百万条指令）通常用于衡量计算机系统性能,直到20世纪80年代.解释为什么它可能是衡量处理器性能的一个非常糟糕的指标.在任何情况下,它都是衡量绩效的有效方法吗？如果是,请描述这些情况.

P1.17 MFLOPS（每秒数百万次浮点运算）通常被用来衡量计算机系统的性能,直到20世纪80年代.
解释为什么它可能是衡量处理器性能的一个非常糟糕的指标.在任何情况下,它都是衡量绩效的有效方法吗？如果是,请描述这些情况.

**术语和流行语**
这些问题类似于电视上的“危险游戏”.显示答案,您将提供最正确的问题.对于每个答案,可能有不止一个适当的问题; 你需要提供最好的一个.

P1.18 A:基本块内的指令级并行性通常上限为2.
问:_ _ _ _ _ _ _ _ _ _ _ _ _ _ _是什么？

P1.19 A:它会显着缩短机器周期时间,但会增加分支惩罚.
问:_ _ _ _ _ _ _ _ _ _ _ _ _ _ _是什么？

P1.20答:描述当程序执行的某些部分不可并行化时可实现的加速.
问:Whatis _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _？

P1.21 A:Flynn瓶颈的广泛使用解决方案.
问:什么是_ _ _ _ _ _ _ _ _ _ _ _ _ _ _？

P1.22 A:描述计算机系统性能的最佳方式.
问:什么是_ _ _ _ _ _ _ _ _ _ _ _ _ _ _？

P1.23 A:指定寄存器的数量,可用的寻址模式和指令操作码.
问:什么是_ _ _ _ _ _ _ _ _ _ _ _ _ _ _？

P1.24 A:这决定了处理器的配置和功能单元的数量.
问:Whatis _ _ _ _ _ _ _ _ _ _ _ _ _ _ _？

P1.25答:这是一种处理器,它严重依赖于编译器静态调度独立指令.
问:什么是_ _ _ _ _ _ _ _ _ _ _ _ _ _ _？

P1.26 A:这是一种处理器,在指令开始执行后的两个或多个周期之前,指令的结果不可用.
问:什么是_ _ _ _ _ _ _ _ _ _ _ _ _ _ _？

P1.27 A:这是一种尝试同时执行多条指令的处理器.
问:什么是_ _ _ _ _ _ _ _ _ _ _ _ _ _ _？

P1.28答:这项重要的研究表明,如果只能以某种方式克服控制依赖性,那么指令级并行性就很丰富.
问:什么是_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _？

P1.29答:这是一种在没有编译器的帮助下执行高级语言的处理器.
问:什么是_ _ _ _ _ _ _ _ _ _ _ _ _ _ _？

P1.30答:这种处理器模拟方法需要大量存储空间.
问:什么是_ _ _ _ _ _ _ _ _ _ _ _ _ _ _？
